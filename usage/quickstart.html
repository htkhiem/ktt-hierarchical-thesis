<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Quickstart &mdash; KTT Hierarchical Classification System 0.3a documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="CLI usage" href="commands.html" />
    <link rel="prev" title="Installation" href="installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> KTT Hierarchical Classification System
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Usage</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="installation.html">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="installation.html#downloading">Downloading</a></li>
<li class="toctree-l3"><a class="reference internal" href="installation.html#setting-up-dependencies">Setting up dependencies</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Quickstart</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#data-preparation">Data preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-a-model">Training a model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#exporting-the-trained-model">Exporting the trained model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#serving-up-a-bento">Serving up a Bento</a></li>
<li class="toctree-l3"><a class="reference internal" href="#shipping-bentos-in-a-container">Shipping Bentos in a container</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="commands.html">CLI usage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="commands.html#adapters">Adapters</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../indepth/index.html">System design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../indepth/adapters.html">Data adapters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../indepth/adapters.html#intermediate-format-specification">Intermediate format specification</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../indepth/adapters.html#parquet-schema">Parquet schema</a></li>
<li class="toctree-l4"><a class="reference internal" href="../indepth/adapters.html#hierarchy-json-schema">Hierarchy JSON schema</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../indepth/adapters.html#theory">Theory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../indepth/adapters.html#the-sql-adapter">The SQL adapter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../indepth/adapters.html#the-flatfile-adapter">The flatfile adapter</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../indepth/training.html">Training stage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../indepth/training.html#the-process">The process</a></li>
<li class="toctree-l3"><a class="reference internal" href="../indepth/training.html#classes">Classes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../indepth/training.html#common-classes">Common classes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../indepth/training.html#pytorch-utilities">PyTorch utilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../indepth/training.html#scikit-learn-utilities">Scikit-learn utilities</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../indepth/exporting.html">Exporting your models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../indepth/exporting.html#onnx-exporting">ONNX exporting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../indepth/exporting.html#bentoml-exporting">BentoML exporting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../indepth/exporting.html#packaging">Packaging</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../encoders/index.html">Encoders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../encoders/distilbert.html">DistilBERT</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../encoders/distilbert.html#api">API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../encoders/sklearn_text.html">Scikit-learn text feature extractors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../encoders/sklearn_text.html#api">API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../models/index.html">Prebuilt models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../models/tfidf_lsgd.html">Tf-idf + Leaf SGD</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../models/tfidf_lsgd.html#api">API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/tfidf_lsgd.html#configuration-schema">Configuration schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/tfidf_lsgd.html#default-tuning-configuration">Default tuning configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/tfidf_lsgd.html#theory">Theory</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../models/tfidf_hsgd.html">Tf-idf + Hierarchy SGD</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../models/tfidf_hsgd.html#api">API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/tfidf_hsgd.html#configuration-schema">Configuration schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/tfidf_hsgd.html#default-tuning-configuration">Default tuning configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/tfidf_hsgd.html#theory">Theory</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../models/db_bhcn.html">DB-BHCN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../models/db_bhcn.html#api">API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_bhcn.html#configuration-schema">Configuration schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_bhcn.html#default-tuning-configuration">Default tuning configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_bhcn.html#checkpoint-schema">Checkpoint schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_bhcn.html#theory">Theory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../models/db_bhcn.html#id1">DB-BHCN</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../models/db_bhcn_awx.html">DB-BHCN+AWX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../models/db_bhcn_awx.html#api">API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_bhcn_awx.html#configuration-schema">Configuration schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_bhcn_awx.html#default-tuning-configuration">Default tuning configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_bhcn_awx.html#checkpoint-schema">Checkpoint schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_bhcn_awx.html#theory">Theory</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../models/db_ahmcnf.html">DistilBERT + Adapted HMCN-F</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../models/db_ahmcnf.html#api">API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_ahmcnf.html#configuration-schema">Configuration schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_ahmcnf.html#default-tuning-configuration">Default tuning configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_ahmcnf.html#checkpoint-schema">Checkpoint schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_ahmcnf.html#theory">Theory</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../models/db_achmcnn.html">DistilBERT + Adapted C-HMCNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../models/db_achmcnn.html#api">API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_achmcnn.html#configuration-schema">Configuration schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_achmcnn.html#default-tuning-configuration">Default tuning configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_achmcnn.html#checkpoint-schema">Checkpoint schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_achmcnn.html#theory">Theory</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../models/db_linear.html">DistilBERT + Linear</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../models/db_linear.html#api">API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_linear.html#configuration-schema">Configuration schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_linear.html#checkpoint-schema">Checkpoint schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="../models/db_linear.html#theory">Theory</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../dev-encoder/index.html">Developing new encoders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../dev-encoder/index.html#where-encoders-come-in">Where encoders come in</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev-encoder/index.html#adding-encoders">Adding encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev-encoder/index.html#implementing-preprocessors">Implementing preprocessors</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../dev/intro.html">Developing new models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../dev/intro.html#frameworks">Frameworks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev/intro.html#general-model-folder-structure">General model folder structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev/intro.html#the-model-itself">The model itself</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev/intro.html#checkpointing">Checkpointing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev/intro.html#preprocessing-needs">Preprocessing needs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev/intro.html#exporting">Exporting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../dev/intro.html#onnx">ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../dev/intro.html#export-bento-resources"><code class="docutils literal notranslate"><span class="pre">export_bento_resources</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../dev/intro.html#the-service-implementation">The service implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dev/intro.html#the-service-configuration-files">The service configuration files</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dev/intro.html#the-reference-dataset">The reference dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dev/intro.html#the-export-bento-resources-method">The <code class="docutils literal notranslate"><span class="pre">export_bento_resources</span></code> method</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../dev/intro.html#specifying-your-hyperparameters-optional">Specifying your hyperparameters (optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev/intro.html#registering-your-model-with-the-rest-of-the-system">Registering your model with the rest of the system</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../dev/intro.html#the-model-lists">The model lists</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../dev/intro.html#test-run-your-model">Test-run your model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../dev/intro.html#grafana-dashboard-design-optional">Grafana dashboard design (optional)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../dev/intro.html#testing-automatic-dashboard-provisioning">Testing automatic dashboard provisioning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../dev/intro.html#framework-specific-guides">Framework-specific guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../dev/pytorch/add_model.html">Implementing a model with PyTorch+DistilBERT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../dev/pytorch/add_model.html#the-model">The model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dev/pytorch/add_model.html#pytorch-model-module-structure">PyTorch model module structure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dev/pytorch/add_model.html#pytorch-utilities">PyTorch utilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dev/pytorch/add_model.html#the-process">The process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dev/pytorch/add_model.html#registering-testing-conclusion">Registering, testing &amp; conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../dev/sklearn/add_model.html">Implementing a model with Scikit-learn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../dev/sklearn/add_model.html#the-model">The model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dev/sklearn/add_model.html#scikit-learn-utilities">Scikit-learn utilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dev/sklearn/add_model.html#the-process">The process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dev/sklearn/add_model.html#registering-testing-conclusion">Registering, testing &amp; conclusion</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/index.html">Advanced guides</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../advanced/dvc.html">Using DVC with our system</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced/gpu.html">Inferencing with GPUs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../advanced/gpu.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/gpu.html#gpu-based-inference-using-bentos">GPU-based inference using Bentos</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/gpu.html#gpu-based-inference-for-dockerised-services">GPU-based inference for Dockerised services</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../advanced/gpu.html#without-monitoring-capabilities">Without monitoring capabilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../advanced/gpu.html#with-monitoring-capabilities">With monitoring capabilities</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../advanced/tuning.html">Automatic hyperparameter tuning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../advanced/tuning.html#cli-usage">CLI usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/tuning.html#tune-configuration-format">Tune configuration format</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../ref.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">KTT Hierarchical Classification System</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Usage</a> &raquo;</li>
      <li>Quickstart</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/usage/quickstart.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="quickstart">
<h1>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this heading"></a></h1>
<p>This guide will help you get started with training and exporting your first model based on an example dataset to an online inference system. Your resulting model can be used by a hypothetical e-commerce platform to give on-the-fly hierarchical product categorisation hints as a poster types their product name. It assumes that you have successfully downloaded the latest version of the system and installed all dependencies without error. If you have not done so, please refer to the previous page for instructions.</p>
<section id="data-preparation">
<h2>Data preparation<a class="headerlink" href="#data-preparation" title="Permalink to this heading"></a></h2>
<p>There are currently two ways to get data into the system:</p>
<blockquote>
<div><ul class="simple">
<li><p>Connecting an SQL database</p></li>
<li><p>Reading CSV, JSON, Parquet, Arrow or Feather files</p></li>
</ul>
</div></blockquote>
<p>The SQL approach is more advanced, so for this quickstart guide, we will instead use a flatfile. Bundled in the repository is an example dataset derived from <a class="reference external" href="https://www.kaggle.com/datasets/promptcloud/walmart-product-details-2020">this CC0 dataset on Kaggle</a>, stored as <code class="docutils literal notranslate"><span class="pre">datasets/Walmart_30k.parquet</span></code>. Although it had been cleaned up to a degree, it is still in its original schema and thus serves as a close example to flatfiles you would encounter in the wild. A peek at the file (using any Parquet-compatible tool, such as Python’s <code class="docutils literal notranslate"><span class="pre">pandas</span></code>) shows how the data inside are organised:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>idx                                                title                                        description  List Price  Sale Price            Brand                                           category
<span class="m">0</span>         La Costena Chipotle Peppers, <span class="m">7</span> OZ <span class="o">(</span>Pack of <span class="m">12</span><span class="o">)</span>  La Costena Chipotle Peppers, <span class="m">7</span> OZ <span class="o">(</span>Pack of <span class="m">12</span><span class="o">)</span>...       <span class="m">31</span>.93       <span class="m">31</span>.93  La Costeï¿½ï¿½a  <span class="o">[</span>Food, Meal Solutions, Grains <span class="p">&amp;</span> Pasta, Canned ...
<span class="m">1</span>      Equate Triamcinolone Acetonide Nasal Allergy S...  Compare to Nasacort Allergy 24HR active ingred...       <span class="m">10</span>.48       <span class="m">10</span>.48           Equate  <span class="o">[</span>Health, Equate, Equate Allergy, Equate Sinus ...
<span class="m">2</span>      AduroSmart ERIA Soft White Smart A19 Light Bul...  The Soft White ERIA A19 bulb <span class="o">(</span>2700K<span class="o">)</span> can be co...       <span class="m">10</span>.99       <span class="m">10</span>.99  AduroSmart ERIA  <span class="o">[</span>Electronics, Smart Home, Smart Energy and Lig...
<span class="m">3</span>      <span class="m">24</span><span class="s2">&quot; Classic Adjustable Balloon Fender Set Chro...  Lowrider Fender Set 24&quot;</span> Classic Adjustable Chr...       <span class="m">38</span>.59       <span class="m">38</span>.59         lowrider  <span class="o">[</span>Sports <span class="p">&amp;</span> Outdoors, Bikes, Bike Accessories, B...
<span class="m">4</span>      Elephant Shape Silicone Drinkware Portable Sil...   This is a kind of fine quality silicone cup l...        <span class="m">5</span>.81        <span class="m">5</span>.81           Anself  <span class="o">[</span>Baby, Feeding, Sippy Cups: Alternatives to Pl...
...                                                  ...                                                ...         ...         ...              ...                                                ...
<span class="m">29201</span>                                      McCain Smiles  Add a wholesome side to your dinnertime meal w...        <span class="m">0</span>.00        <span class="m">0</span>.00           McCain            <span class="o">[</span>Food, Frozen Foods, Frozen Vegetables<span class="o">]</span>
<span class="m">29202</span>  Shock Sox Fork Seal Guards <span class="m">29</span>-36mm Fork Tube <span class="m">4</span>...  Shock Sox are a wraparound, neoprene sleeve th...       <span class="m">33</span>.25       <span class="m">33</span>.25        Shock Sox  <span class="o">[</span>Sports <span class="p">&amp;</span> Outdoors, Bikes, Bike Components, Bi...
<span class="m">29203</span>                          Princes Gooseberries 300g    Gooseberries <span class="k">in</span> syrup Princes Gooseberries 300g        <span class="m">8</span>.88        <span class="m">8</span>.88          Princes  <span class="o">[</span>Food, Meal Solutions, Grains <span class="p">&amp;</span> Pasta, Canned ...
<span class="m">29204</span>  Create Ion Grace <span class="m">3</span>/4 Inches Straight Hair Iron...  Create ion grace straight is a <span class="m">3</span>/4 inches wide...       <span class="m">50</span>.00       <span class="m">24</span>.50       Create Ion  <span class="o">[</span>Beauty, Hair Care, Hair Styling Tools, Flat I...
<span class="m">29205</span>  Green Bell Takuminowaza Two Way Ear Pick Brass...  Green bell ear wax remover <span class="m">2</span>-way screw <span class="p">&amp;</span> spoon...        <span class="m">6</span>.00        <span class="m">4</span>.20     Takuminowaza  <span class="o">[</span>Beauty, Here <span class="k">for</span> Every Beauty, Featured Shops...

<span class="o">[</span><span class="m">29206</span> rows x <span class="m">6</span> columns<span class="o">]</span>
</pre></div>
</div>
<p>Since our model should be able to suggest which category to put a product into as the user types the product name, we will use the <code class="docutils literal notranslate"><span class="pre">title</span></code> column as our input to the model, and <code class="docutils literal notranslate"><span class="pre">category</span></code> as our training labels. Note how the <code class="docutils literal notranslate"><span class="pre">category</span></code> column is a list of strings, ordered by hierarchical depth (from the coarsest to the most detailed categorisation level). This is the common style that KTT uses. JSON files will use their own list syntax, while CSV files can accept different delimiters to split a single string into separate categories. Formats that natively support list datatypes for cells, such as Apache Arrow, Feather and Parquet, are directly supported and are most preferrable.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In addition, they are much lighter in size and significantly faster to parse as well as having additional capabilities such as out-of-core reading, so we highly recommend using them for your data storage outside of our system to lower storage costs (especially on services such as Amazon S3) and ease the data preparation process.</p>
</div>
<p>To input this flatfile into the system, we invoke the <em>flatfile adapter</em>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> adapters
python adapter_flat.py -v -t title -c category -d <span class="m">2</span> --dvc ../datasets/Walmart_30k.parquet Walmart
</pre></div>
</div>
<p>An explanation of what these options and arguments do:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-v</span></code> is the verbose argument. With this, the adapter prints more information about its process, which helps with understanding what it does.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-t</span></code> specifies the column to use as the model’s input. As we have previously discussed, we are using the <code class="docutils literal notranslate"><span class="pre">title</span></code> column. If left unspecified, <code class="docutils literal notranslate"><span class="pre">title</span></code> is also the default column name KTT uses. Of course, if you don’t specify it and the flatfile does not have a <code class="docutils literal notranslate"><span class="pre">title</span></code> column, or it has one but the column is something else entirely and not what we need, expect some errors or poor performance.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-c</span></code> likewise specifies the column name to use as classes (labels). It defaults to <code class="docutils literal notranslate"><span class="pre">classes</span></code> if left unspecified. Here, we want to use the <code class="docutils literal notranslate"><span class="pre">category</span></code> column, so of course we must specify it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-d</span></code> is the hierarchical depth to search to. By default, the adapter runs for two levels. This must not exceed the <em>minimum</em> depth of the dataset, i.e. the length of the shortest list in the label column.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--dvc</span></code> tells the adapter to also add the resulting intermediate dataset to the Data Version Control system. With this, you can later add a remote of your choosing, push the dataset there and safely delete the local copy to save disk space. Training scripts will automatically pull them from said remote when needed.</p></li>
<li><p>The first argument is the path to the flatfile. <cite>Walmart_30k.parquet</cite> is bundled in <cite>datasets</cite>.</p></li>
<li><p>The second argument is the name of the resulting intermediate dataset.</p></li>
</ul>
</div></blockquote>
<p>After running the above commands, a new folder (<code class="docutils literal notranslate"><span class="pre">datasets/Walmart</span></code>) will be created, containing three Parquet files and a JSON file named <code class="docutils literal notranslate"><span class="pre">hierarchy.json</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As a quickstart guide, we won’t delve too deeply into the specifics, but here are the main tasks an adapter performs:</p>
<ol class="arabic simple">
<li><p>Read the flatfile or SQL data into memory, then rename columns and reformat the <cite>classes</cite> column if necessary.</p></li>
<li><p>Build a list of pairwise-different labels on each level.</p></li>
<li><p>Reconstruct the hierarchy from relationships found in the flatfile or corresponding SQL table.</p></li>
<li><p>Generate metadata for specific models.</p></li>
<li><p>CV-split the dataset into a training set, a validation set and a test set. This is done using random sampling.</p></li>
<li><p>Write the three sets into a new folder within <code class="docutils literal notranslate"><span class="pre">datasets</span></code> as Parquet files (irrespective of input format) and the hierarchical metadata as a JSON file.</p></li>
</ol>
</div>
</section>
<section id="training-a-model">
<h2>Training a model<a class="headerlink" href="#training-a-model" title="Permalink to this heading"></a></h2>
<p>Having generated a compatible model and the necessary metadata, we can now train a model on it. To keep everything lightweight for a quickstart guide, we will use a small CPU-based model called Tfidf + Hierarchical SGD (internal identifier <code class="docutils literal notranslate"><span class="pre">tfidf_hsgd</span></code>). This model is capable of fully hierarchical classification and trains very quickly, albeit with limited accuracy for small datasets.</p>
<p>From <code class="docutils literal notranslate"><span class="pre">./</span></code>, run the following command to train it:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python train.py -m tfidf_hsgd Walmart
</pre></div>
</div>
<p>An explanation, again:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-m</span></code> specifies which model to train. Here we use the internal identifier of the above model.</p></li>
<li><p>The one and only argument specifies the (internal) dataset name to train on. We have previously named our dataset <code class="docutils literal notranslate"><span class="pre">Walmart</span></code> (to differentiate it from the flatfile, which was named <code class="docutils literal notranslate"><span class="pre">Walmart_30k</span></code>, so we’ll use that name here.</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Both the dataset-name argument and the <code class="docutils literal notranslate"><span class="pre">-m</span></code> option accept comma-separated lists of models and datasets. In other words, you can tell the training script to train on multiple datasets at once, train multiple models at once, or train multiple models, each on multiple datasets!</p>
</div>
<p>Once the command finishes, a <code class="docutils literal notranslate"><span class="pre">tfidf_hsgd</span></code> instance will have been trained on <code class="docutils literal notranslate"><span class="pre">Walmart</span></code> and saved in the <code class="docutils literal notranslate"><span class="pre">weights/tfidf_hsgd/Walmart</span></code> directory.</p>
</section>
<section id="exporting-the-trained-model">
<h2>Exporting the trained model<a class="headerlink" href="#exporting-the-trained-model" title="Permalink to this heading"></a></h2>
<p>With a trained model under our belt, we can export it into some sort of API server. Our goal is to have a minimal inference server set up by the end of this guide, so we will take advantage of the preset BentoML-powered inference system in KTT. Every bundled model in KTT has been prepared for usage by BentoML through special build scripts and service files.</p>
<p>Run the following command from from <code class="docutils literal notranslate"><span class="pre">.\</span></code> to export the newly trained model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python export.py -m <span class="s1">&#39;tfidf_hsgd&#39;</span> -b Walmart
</pre></div>
</div>
<p>This command will then look for the latest saved instance of <code class="docutils literal notranslate"><span class="pre">tfidf_hsgd</span></code> trained on the <code class="docutils literal notranslate"><span class="pre">Walmart</span></code> dataset - note how the <code class="docutils literal notranslate"><span class="pre">-m</span></code> option once again present in this command and the argument is the dataset name. The additional <code class="docutils literal notranslate"><span class="pre">-b</span></code> argument tells the script to generate a BentoService and copy the necessary supporting data along. The resulting service will be located in the <code class="docutils literal notranslate"><span class="pre">build</span></code> folder.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Unlike the other six models, <code class="docutils literal notranslate"><span class="pre">tfidf_hsgd</span></code> does not support exporting to other formats than BentoML. As such, the <code class="docutils literal notranslate"><span class="pre">-b</span></code> flag MUST always be specified when exporting this model.</p>
</div>
</section>
<section id="serving-up-a-bento">
<h2>Serving up a Bento<a class="headerlink" href="#serving-up-a-bento" title="Permalink to this heading"></a></h2>
<p>It’s Bento(ML) time! KTT’s BentoML inference pipelines relies on packaged systems known as BentoServices. These are the model graph themselves, plus the code needed to feed data in and extract data out of the model (i.e. a REST-to-model-to-REST routine), a lot of supporting files for peripheral subsystems such as a live performance monitoring dashboard (optional), and a version-frozen list of all dependencies.</p>
<p>As above, each and every bundled model in the system has their own Bento pipeline implemented. As such, in order to serve our trained model as a REST API, run the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bentoml serve build/tfidf_hsgd_Walmart/inference
</pre></div>
</div>
<p>The model will be served as a REST API at <code class="docutils literal notranslate"><span class="pre">localhost:5000</span></code> with the <code class="docutils literal notranslate"><span class="pre">/predict</span></code> endpoint. You can use the supplied <code class="docutils literal notranslate"><span class="pre">test.py</span></code> test script in <code class="docutils literal notranslate"><span class="pre">onnx/bentoml</span></code> to send a single request to it and check the results.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> onnx/bentoml
python test.py
</pre></div>
</div>
<p>Or, if you prefer to send requests to it yourself, simply POST in the following format:</p>
<blockquote>
<div><ul class="simple">
<li><p>Content-Type: <code class="docutils literal notranslate"><span class="pre">application/json</span></code></p></li>
<li><p>Data: a JSON string with a single field <code class="docutils literal notranslate"><span class="pre">text</span></code> containing the textual input to be classified. For example: <code class="docutils literal notranslate"><span class="pre">&quot;{</span> <span class="pre">\&quot;text\&quot;:</span> <span class="pre">\&quot;Classify</span> <span class="pre">this</span> <span class="pre">string\&quot;</span> <span class="pre">}&quot;</span></code>.</p></li>
</ul>
</div></blockquote>
</section>
<section id="shipping-bentos-in-a-container">
<h2>Shipping Bentos in a container<a class="headerlink" href="#shipping-bentos-in-a-container" title="Permalink to this heading"></a></h2>
<p>Having a BentoService online should be enough if you only plan on running it directly on the computer that trained it, or another that you are sure has had all dependencies correctly installed. However, this is hard to maintain, especially as libraries may change over time, causing breakages. Furthermore, downloading all dependencies over and over again is not a small task, and certain libraries may even become no longer available on the cloud for you to download (in extreme cases that is). Furthermore, KTT provides additional monitoring capabilities for its live inference systems that would be much, much more easily run as a single <code class="docutils literal notranslate"><span class="pre">docker-compose</span></code> network instead of separate manually-started processes (although the monitoring part isn’t within the scopes of this Quickstart guide).</p>
<p>As such, it is preferrable that we find a way to keep an offline backup of such dependencies, frozen to the exact version used to train and export the model. This is where Dockerisation comes in.</p>
<p>First, ensure that you have Docker correctly installed (and its daemon running) on your local system and that your usee account has the necessary privileges. Then, Dockerising a BentoService is a one-command affair:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker image build ./build/tfidf_hsgd_Walmart_005
</pre></div>
</div>
<p>This might take a while as Docker builds a Debian-based system with our model. Once it’s done, check the list of images on your system and note down the Image ID of the newly-built Bento container.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>❯ docker images
REPOSITORY             TAG                                IMAGE ID       CREATED       SIZE
tfidf_hsgd_Walmart_005 ................                   fbbf4a810b58   ...           ...
</pre></div>
</div>
<p>Here the Image ID is <code class="docutils literal notranslate"><span class="pre">fbbf4a810b58</span></code>. We can now fire the image up:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run -p <span class="m">5000</span>:5000 fbbf4a810b58
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">-p</span> <span class="pre">5000:5000</span></code> argument forwards the host’s port 5000 to the container’s corresponding port. This allows requests from the outside to be directed to the container, and the container’s response to be in turn directed back to the outside. You can test this using the same test script we have mentioned above.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Dockerisation process is a bit different for BentoServices built with monitoring capabilities enabled. Since they use multiple Docker containers, KTT will also generate a <code class="docutils literal notranslate"><span class="pre">docker-compose.yaml</span></code> file for them. Simply navigate to the built service’s folder (where the <code class="docutils literal notranslate"><span class="pre">docker-compose.yaml</span></code> file is) and hit <code class="docutils literal notranslate"><span class="pre">docker-compose</span> <span class="pre">up</span></code>.</p>
</div>
<p>If all goes well, congratulations! You now have a fully self-contained Docker image of your newly-trained hierarchical classification model.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="commands.html" class="btn btn-neutral float-right" title="CLI usage" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Huynh Thien Khiem, Voong Xay Tac, Huynh Truong Tu.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>