{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "q8ssvaYmaBia"
   },
   "outputs": [],
   "source": [
    "### Dataset configuration\n",
    "# The parquet folder. It should be located inside datasets/.\n",
    "DATASET_NAME   = 'Arts_Crafts_and_Sewing.parquet'\n",
    "# The input text column\n",
    "TEXT_COL_NAME  = 'title'\n",
    "# Which column to use as labelled classes. It should be a column of lists of strings.\n",
    "CLASS_COL_NAME = 'category'\n",
    "# How many hierarchical levels to work on. Note that the dataset must also have at least this many levels for every example.\n",
    "DEPTH = 4\n",
    "\n",
    "### Checkpoint configuration\n",
    "# Whether to train from scratch or to load a checkpoint\n",
    "TRAIN_FROM_SCRATCH=True\n",
    "# If training from scratch, train this many times before averaging test set results. Train/val/test split is kept static.\n",
    "TRAIN_REPEATS = 4\n",
    "# Checkpoint iteration to load if not training from scratch\n",
    "LOAD_ITERATION=1\n",
    "# Last or best results from that iteration?\n",
    "LOAD_BEST=True\n",
    "\n",
    "### System configuration\n",
    "# Will try to use your NVIDIA GPU if one is available. Set to False to force CPU computation\n",
    "PREFER_GPU         = True\n",
    "# If you don't have the huggingface transformers library installed, flip this to True.\n",
    "# You only need to do this once. Once DistilBERT has been downloaded, it will be cached in your system's default user cache folder.\n",
    "# Once it is cached, please set this to False to avoid redownloads.\n",
    "INSTALL_DISTILBERT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9r_iHMmx75DM"
   },
   "source": [
    "# Import common libraries\n",
    "And also set up a few things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "shaFdRkD74o1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import logging\n",
    "\n",
    "# Set up GPU if available\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() and PREFER_GPU else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TO5DolJKZfNv",
    "outputId": "f788701e-7f29-4391-cb82-fd2d60c3acfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTb90c5tRJsf"
   },
   "source": [
    "# Import data\n",
    "Here we'll finally be using the randomly-sampled 750k-row subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8e3fhFSRPPw",
    "outputId": "f62876fc-11c1-4a35-8534-aa4e27db8d07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [Sewing, Trim & Embellishments, Appliques & Decorative Patches, Decorative Patches]\n",
      "title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You Son of a Bitch! 1987 Embroidered Patch\n",
      "description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The patch features the sweaty masculine handshake with the text \"You Son of a Bitch!\" 1987 and is easy to apply  simply sew on or attach using the iron-on backing.\n",
      "brand                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Honchosfx\n",
      "feature        [You son of a bitch patch - exclusive to Honcho-SFX, Embroidered patches with an original design. Ideal for attaching to jackets or backpacks., Easy to apply with iron on backing, attach it to your clothes and bags including jeans, jacket or cap., Classic retro design, Horror movie patches make a great gift for movie fans!, <span class=\"a-text-bold\">Package Dimensions:\\n                    </span>\\n                    <span>4.5 x 3.6 x 0.2 inches</span>, <span class=\"a-text-bold\">Shipping Weight:\\n                    </span>\\n                    <span>0.32 ounces (<a href='https://www.amazon.com/gp/help/seller/shipping.html/ref=dp_pd_shipping?_encoding=UTF8&seller=A2XHYW6QDA3R9T&asin=6665560953'>View shipping rates and policies</a>)</span>, <span class=\"a-text-bold\">ASIN:\\n                    </span>\\n                    <span>6665560953</span>, , <span class=\"a-text-bold\">Date first listed on Amazon:\\n                    </span>\\n                    <span>May 6, 2016</span>, <span class=\"a-text-bold\">\\n                    Average Customer Review:\\n                </span>\\n                \\n\\n\\n\\n\\n<style type=\"text/css\">\\n    /* \\n    * Fix for UDP-1061. Average customer reviews has a small extra line on hover \\n    * https://omni-grok.amazon.com/xref/src/appgroup/websiteTemplates/retail/SoftlinesDetailPageAssets/udp-intl-lock/src/legacy.css?indexName=WebsiteTemplates#40\\n    */\\n    .noUnderline a:hover { \\n        text-decoration: none; \\n    }\\n</style>\\n\\n\\n\\n    \\n    \\n    \\n    \\n        \\n\\n        \\n\\n        \\n        \\n        \\n        \\n\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t        \\n\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t        \\n        \\n\\n        <div id=\"detailBullets_averageCustomerReviews\" class=\"a-spacing-none\" data-asin=\"6665560953\" data-ref=\"dpx_acr_pop_\" >\\n            \\n            \\n            \\n                \\n                \\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        <span class=\"a-declarative\" data-action=\"acrStarsLink-click-metrics\" data-acrStarsLink-click-metrics=\"{}\">\\n            \\n\\n\\n\\n\\n\\n    <span id=\"acrPopover\" class=\"reviewCountTextLinkedHistogram noUnderline\" title=\"4.9 out of 5 stars\">\\n        <span class=\"a-declarative\" data-action=\"a-popover\" data-a-popover=\"{\"max-width\":\"700\",\"closeButton\":\"false\",\"position\":\"triggerBottom\",\"url\":\"/gp/customer-reviews/widgets/average-customer-review/popover/ref=dpx_acr_pop_?contextId=dpx&asin=6665560953\"}\">\\n            <a href=\"javascript:void(0)\" class=\"a-popover-trigger a-declarative\">\\n                \\n\\n<i class=\"a-icon a-icon-star a-star-5\"><span class=\"a-icon-alt\">4.9 out of 5 stars</span></i>\\n                \\n            <i class=\"a-icon a-icon-popover\"></i></a>\\n        </span>\\n        <span class=\"a-letter-space\"></span>\\n    </span>\\n\\n\\n        </span>\\n        <span class=\"a-letter-space\"></span>\\n        \\n        \\n\\n        \\n\\n        \\n\\n        \\n        \\n        \\n        \\n        \\n        \\n        \\n            \\n            \\n                <span class=\"a-declarative\" data-action=\"acrLink-click-metrics\" data-acrLink-click-metrics=\"{}\">\\n                    <a id=\"acrCustomerReviewLink\" class=\"a-link-normal\" href=\"#customerReviews\">\\n                        <span id=\"acrCustomerReviewText\" class=\"a-size-base\">20 customer reviews</span>\\n                    </a>\\n                </span>\\n            \\n                <script type=\"text/javascript\">\\n                    P.when('A', 'ready').execute(function(A) {\\n                        A.declarative('acrLink-click-metrics', 'click', { \"allowLinkDefault\" : true }, function(event){\\n                            if(window.ue) {\\n                                ue.count(\"acrLinkClickCount\", (ue.count(\"acrLinkClickCount\") || 0) + 1);\\n                            }\\n                        });\\n                    });\\n                </script>\\n            \\n            \\n            \\n            \\n        \\n        \\n        <script type=\"text/javascript\">\\n            P.when('A', 'cf').execute(function(A) {\\n                A.declarative('acrStarsLink-click-metrics', 'click', { \"allowLinkDefault\" : true },  function(event){\\n                    if(window.ue) {\\n                        ue.count(\"acrStarsLinkWithPopoverClickCount\", (ue.count(\"acrStarsLinkWithPopoverClickCount\") || 0) + 1);\\n                    }\\n                });\\n            });\\n        </script>\\n\\n\\n                \\n            \\n        </div>]\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_parquet('../../datasets/{}'.format(DATASET_NAME))\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    print (data.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96eLOv0hMvCv"
   },
   "source": [
    "# Categorical-encode the categories\n",
    "For this notebook, we'll only be classifying the leaf level. No hierarchy yet. Also, we'll be using a linear layer in PyTorch, which necessitates us to encode these categories manually.\n",
    "\n",
    "The reason we're not using one-hot encoding is because we're about to use cross-entropy loss for this notebook. Also see corresponding link in References for why we picked this.\n",
    "\n",
    "For categorical encoding to work, the column itself must be in pandas' `category` datatype, instead of the default `object` type for non-numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8YYWA6NNUr4",
    "outputId": "44e296f1-93a6-448a-ea78-b124b62b3d2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "0         37\n",
       "1         40\n",
       "2         71\n",
       "3          8\n",
       "4         63\n",
       "        ... \n",
       "53896    114\n",
       "53897     19\n",
       "53898     37\n",
       "53899     79\n",
       "53900     63\n",
       "Name: targets, Length: 53901, dtype: int8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEVEL = DEPTH-1\n",
    "leaf_categories = data['category'].apply(lambda lst: lst[min(LEVEL, len(lst) - 1)]).astype('category')\n",
    "data['targets'] = leaf_categories.cat.codes\n",
    "\n",
    "data['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nb80Y48WZfN7"
   },
   "source": [
    "Keep a mapping between category code and category names (in strings) so we can get human-readable predictions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AasvSxmA0HIu",
    "outputId": "003f50f4-43fa-4b55-d513-c8913ffebd24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ALABAR is a registered brand', 'Accessories', 'Adhesive Removers',\n",
       "       'Adhesive Sheets & Sprays', 'Adhesive Waxing',\n",
       "       'Adults' Paint-By-Number Kits', 'Airbrush Sets', 'Angled Paintbrushes',\n",
       "       'Appliques', 'Art Glues & Pastes',\n",
       "       ...\n",
       "       'Threaders', 'Tools', 'Tools & Tool Sets',\n",
       "       'Top Quality, Detailed Embroidery', 'Transfer Paper',\n",
       "       'Undergarment Sewing', 'Use instead of detergents or washing powder',\n",
       "       'Vellum', 'Wood Stamps', 'Zippers'],\n",
       "      dtype='object', length=123)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaves = leaf_categories.cat.categories\n",
    "leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMYK-8pR0v6L"
   },
   "source": [
    "Also keep the number of leaves for later model construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zJ8mFJ2R1EpD"
   },
   "outputs": [],
   "source": [
    "leaf_count = len(leaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4sXPxkKzUK2"
   },
   "source": [
    "Now we can generate our custom-ordered, global binary encoding.\n",
    "\n",
    "$|Y_L^h|$ can easily be sliced from the global encoding by relying on the backed-up per-level class counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6K2Cm1Bq7Kl"
   },
   "source": [
    "# Data and model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRp5rd9W3rXm"
   },
   "source": [
    "## Installing DistilBERT\n",
    "Alternative to full-fat BERT, roughly matching its performance while being faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jx5V1QzS3wRX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "if not INSTALL_DISTILBERT:\n",
    "    os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "else:\n",
    "    !pip install transformers\n",
    "    \n",
    "import transformers as ppb\n",
    "tokenizer = ppb.DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "base_encoder = ppb.DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "base_encoder_state = base_encoder.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vr1iQObJQOPB"
   },
   "source": [
    "## Define our dataset adapter class\n",
    "This wraps around our data and provides a PyTorch-compatible interface.\n",
    "\n",
    "One point of interest is how we do not explicitly store per-level one-hot encodings. Here we simply store one global copy (n-hot-encoded) then slice from it when requested, saving a bit of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "I8cdh6oiQTsq"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, df, tokenizer, max_len):\n",
    "    self.tokenizer = tokenizer\n",
    "    # TODO: Make these customisable from the constructor interface\n",
    "    self.title = df['title']\n",
    "    self.labels = df['targets']\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.title)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    title = str(self.title.iloc[index])\n",
    "    title = \" \".join(title.split())\n",
    "    inputs = self.tokenizer(\n",
    "      title,\n",
    "      None, # No text_pair\n",
    "      add_special_tokens=True, # CLS, SEP\n",
    "      max_length=self.max_len, # For us it's a hyperparam. See next cells.\n",
    "      padding='max_length',\n",
    "      return_token_type_ids=True,\n",
    "      truncation=True\n",
    "      # BERT tokenisers return attention masks by default\n",
    "    )\n",
    "    return {\n",
    "      'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "      'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "      'token_type_ids': torch.tensor(inputs['token_type_ids'], dtype=torch.long),\n",
    "      'labels': torch.tensor(self.labels.iloc[index], dtype=torch.float)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZywhH4tS2Q0"
   },
   "source": [
    "Regarding that `max_len` hyperparameter, let's see the distribution of title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "LN-EM4dWS02O",
    "outputId": "c20c5dca-744d-4e14-bc99-679e8e68cb50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['title_len'] = data['title'].apply(lambda s: len(s.split()))\n",
    "data['title_len'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ33DAURTg3I"
   },
   "source": [
    "We prefer `max_len` to be a power of two that covers most of the titles. Here it seems 64 will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wpFTDAgDq_oV"
   },
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 64\n",
    "LINEAR_DROPOUT_RATE = 0.25\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-05\n",
    "TRAIN_MINIBATCH_SIZE = 32\n",
    "VAL_TEST_MINIBATCH_SIZE = 64\n",
    "TRAIN_SET_RATIO = 0.8\n",
    "VAL_SET_RATIO = 0.1\n",
    "# The rest is test set\n",
    "RANDOM_SEED = 123\n",
    "# Flip to False for faster hyperparameter tuning. If False, only 5% of the full dataset is used. \n",
    "FULL_SET = True\n",
    "PARTIAL_SET_FRAC = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vRe05MEHZ9g"
   },
   "source": [
    "CV-split our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8973_cElHYg2",
    "outputId": "db7e22e7-b868-43ec-a114-4294c462cda3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43121, 2)\n",
      "(5390, 2)\n",
      "(5390, 2)\n"
     ]
    }
   ],
   "source": [
    "small_data = None\n",
    "if not FULL_SET:\n",
    "    small_data = data.sample(frac = PARTIAL_SET_FRAC, random_state=RANDOM_SEED)\n",
    "\n",
    "train_set = None\n",
    "test_set = None\n",
    "\n",
    "COLUMNS = [TEXT_COL_NAME, 'targets']\n",
    "\n",
    "filtered = None\n",
    "if FULL_SET:\n",
    "    filtered = data[COLUMNS]\n",
    "else:\n",
    "    filtered = small_data[COLUMNS]\n",
    "\n",
    "train_set = filtered.sample(frac = TRAIN_SET_RATIO, random_state=RANDOM_SEED)\n",
    "val_test_set = filtered.drop(train_set.index)\n",
    "\n",
    "val_set = val_test_set.sample(frac = VAL_SET_RATIO / (1-TRAIN_SET_RATIO), random_state=RANDOM_SEED)\n",
    "test_set = val_test_set.drop(val_set.index)\n",
    "\n",
    "train_set = train_set.reset_index(drop=True)\n",
    "val_set = val_set.reset_index(drop=True)\n",
    "test_set = test_set.reset_index(drop=True)\n",
    "\n",
    "print(train_set.shape)\n",
    "print(val_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PXLfuJcV2aK"
   },
   "source": [
    "We can now wrap them in our Datasets, and then into PyTorch's DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_b1j_gNdV9Ux"
   },
   "outputs": [],
   "source": [
    "train_set = CustomDataset(train_set, tokenizer, MAX_LEN)\n",
    "val_set = CustomDataset(val_set, tokenizer, MAX_LEN)\n",
    "test_set = CustomDataset(test_set, tokenizer, MAX_LEN)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=TRAIN_MINIBATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=VAL_TEST_MINIBATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=VAL_TEST_MINIBATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGLkaGimW285"
   },
   "source": [
    "## Prepare the model itself\n",
    "Here we use DistilBERT as the encoding layers, followed by a dropout layer and a linear layer for leaf category classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hGFxM_q2RpkC",
    "outputId": "ec88f454-15c9-46ff-b6f7-376fc9a0473d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import reduce\n",
    "\n",
    "class DistilBERTClass(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, output_count):\n",
    "    super(DistilBERTClass, self).__init__()\n",
    "    encoder = base_encoder\n",
    "    encoder.load_state_dict(base_encoder_state)\n",
    "    self.l1 = encoder\n",
    "    self.l2 = torch.nn.Dropout(LINEAR_DROPOUT_RATE)\n",
    "    self.l3 = torch.nn.Linear(768, output_count) # DistilBERT outputs 768 values.\n",
    "    self.output_size = output_count\n",
    "\n",
    "  def forward(self, ids, mask):\n",
    "    output_1 = self.l1(ids, attention_mask = mask)[0][:,0,:]\n",
    "    output_2 = self.l2(output_1)\n",
    "    output = self.l3(output_2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfHPZdswaBY8"
   },
   "source": [
    "Now we define the loss function that we will use to fine-tune our model (DistilBERT included).\n",
    "\n",
    "For now we'll stick with one of the provided loss functions instead of building anything radical. As we are performing multiclass classification here, we should use Cross Entropy Loss (the normal one for multiclass, not BCE for binary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hXZXWUITaBF3"
   },
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.CrossEntropyLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_btMadIfe7A"
   },
   "source": [
    "## Checkpoints\n",
    "PyTorch allows us to save the best-performing model automatically so we can restart from that instead of the beginning. No reason not to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mIDVu-5Ffd6v"
   },
   "outputs": [],
   "source": [
    "import shutil, sys\n",
    "def load_checkpoint(checkpoint_fpath, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_fpath: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min\n",
    "\n",
    "def save_checkpoint(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint we want to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model (min validation lost)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFA8W-4CvOH9"
   },
   "source": [
    "# Training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CCiOYWU3ZfOS"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def get_metrics(output, targets, log_metrics = False, get_auprc = False):\n",
    "    def generate_one_hot(idx):\n",
    "      b = np.zeros(leaf_count, dtype=bool)\n",
    "      b[idx] = 1\n",
    "      return b\n",
    "\n",
    "    # Get predicted codes\n",
    "    predicted_leaf_codes = np.argmax(output, axis=1)\n",
    "\n",
    "    acc = metrics.accuracy_score(predicted_leaf_codes, targets)\n",
    "    pre = metrics.precision_score(predicted_leaf_codes, targets, average='weighted', zero_division=0)\n",
    "\n",
    "    if log_metrics:\n",
    "      logging.info('Leaf level metrics:')\n",
    "      logging.info(\"Accuracy: {}\".format(acc))\n",
    "      # Model Precision: what percentage of positive tuples are labeled as such?\n",
    "      logging.info(\"Precision: {}\".format(pre))\n",
    "\n",
    "    if get_auprc:\n",
    "      # Rectified leaf AU(PRC) due to an sklearn bug.\n",
    "      # We add one artificial example that belongs to all classes at once and a corresponding prediction\n",
    "      # full of true positives. This way each class has at least one true positive, even if the test set\n",
    "      # does not contain enough examples to cover all classes.\n",
    "      binarised_targets = np.array([generate_one_hot(code) for code in targets])\n",
    "      rectified_outputs = np.concatenate([output, np.ones((1, leaf_count))], axis=0)\n",
    "      rectified_targets = np.concatenate([binarised_targets, np.ones((1, leaf_count), dtype=bool)], axis=0)\n",
    "      auprc = metrics.average_precision_score(rectified_targets, rectified_outputs)\n",
    "      if log_metrics:\n",
    "        logging.info('Rectified leaf-level AU(PRC) score: {}'.format(auprc))\n",
    "      return np.array([acc, pre, auprc])\n",
    "    return np.array([acc, pre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZxqdEcgMvPoV"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_model(start_epochs, n_epochs, val_loss_min_input, \n",
    "                training_loader, val_loader, model,\n",
    "                checkpoint_path, best_model_path, verbose=False):\n",
    "\n",
    "  # Store validation metrics after each epoch\n",
    "  val_metrics = np.empty((2, 0), dtype=float)\n",
    "\n",
    "  optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "  # Keep min validation (test set) loss so we can separately back up our best-yet model\n",
    "  val_loss_min = val_loss_min_input\n",
    "  for epoch in range(start_epochs, n_epochs+1):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    # Put model into training mode. Note that this call DOES NOT train it yet.\n",
    "    model.train()\n",
    "    print('Epoch {}: Training'.format(epoch))\n",
    "    for batch_idx, data in enumerate(tqdm(training_loader)):\n",
    "      ids = data['ids'].to(device, dtype = torch.long)\n",
    "      mask = data['mask'].to(device, dtype = torch.long)\n",
    "      targets = data['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "      outputs = model(ids, mask)\n",
    "\n",
    "      loss = loss_fn(outputs, targets)\n",
    "\n",
    "      # PyTorch defaults to accumulating gradients, but we don't need that here\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      train_loss = train_loss + (loss.item() - train_loss) / (batch_idx + 1)\n",
    "\n",
    "    print('Epoch {}: Testing'.format(epoch))\n",
    "    \n",
    "    \n",
    "    # Switch to evaluation (prediction) mode. Again, this doesn't evaluate anything.\n",
    "    model.eval()\n",
    "\n",
    "    val_targets = np.array([], dtype=float)\n",
    "    val_outputs = np.empty((0, model.output_size), dtype=float)\n",
    "\n",
    "    # We're only testing here, so don't run the backward direction (no_grad).\n",
    "    with torch.no_grad():\n",
    "      total_loss = 0\n",
    "      batch_count = 0\n",
    "      for batch_idx, data in enumerate(tqdm(val_loader)):\n",
    "        batch_count += 1\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        total_loss += loss\n",
    "\n",
    "        val_loss = val_loss + (loss.item() - val_loss) / (batch_idx + 1)\n",
    "        \n",
    "        val_targets = np.concatenate([val_targets, targets.cpu().detach().numpy()])\n",
    "        val_outputs = np.concatenate([val_outputs, outputs.cpu().detach().numpy()])\n",
    "\n",
    "      # calculate average losses\n",
    "      #print('before cal avg train loss', train_loss)\n",
    "      if verbose:\n",
    "        print('Average minibatch loss:', total_loss / batch_count)\n",
    "    \n",
    "      val_metrics = np.concatenate([val_metrics, \n",
    "                                    np.expand_dims(get_metrics(val_outputs, val_targets), axis=1)],\n",
    "                                   axis=1)\n",
    "      train_loss = train_loss/len(training_loader)\n",
    "      val_loss = val_loss/len(val_loader)\n",
    "      # Print training/validation statistics \n",
    "      if verbose:\n",
    "        print('Avgerage training loss: {:.6f}\\nAverage validation loss: {:.6f}'.format( \n",
    "                train_loss,\n",
    "                val_loss\n",
    "                ))\n",
    "\n",
    "      # create checkpoint variable and add important data\n",
    "      checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'val_loss_min': val_loss,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "      }\n",
    "      # save checkpoint\n",
    "      best_yet = False\n",
    "      if val_loss <= val_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(val_loss_min,val_loss))\n",
    "        # save checkpoint as best model\n",
    "        best_yet = True\n",
    "        val_loss_min = val_loss\n",
    "      save_checkpoint(checkpoint, best_yet, checkpoint_path, best_model_path)\n",
    "    print('Epoch {}: Done\\n'.format(epoch))\n",
    "  return model, val_metrics\n",
    "\n",
    "# Alternative: just load from disk\n",
    "def run_model(model, loader):\n",
    "  # Switch to evaluation (prediction) mode. Again, this doesn't evaluate anything.\n",
    "  model.eval()\n",
    "\n",
    "  all_targets = np.array([], dtype=int)\n",
    "  all_outputs = np.empty((0, model.output_size), dtype=float)\n",
    "\n",
    "  # We're only testing here, so don't run the backward direction (no_grad).\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(tqdm(loader)):\n",
    "      ids = data['ids'].to(device, dtype = torch.long)\n",
    "      mask = data['mask'].to(device, dtype = torch.long)\n",
    "      targets = data['labels'].int()\n",
    "\n",
    "      outputs = model(ids, mask)\n",
    "\n",
    "      all_targets = np.concatenate([all_targets, targets.numpy()])\n",
    "      all_outputs = np.concatenate([all_outputs, outputs.cpu().detach().numpy()])\n",
    "  return {\n",
    "      'targets': all_targets,\n",
    "      'outputs': all_outputs,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "7512c7bbac2b4a8a86e6759f3bbbc2b8",
      "a36dc39df13c4fb6b06210e9f7d4e5cb",
      "bfa45769c90c4e50829b7bba9c673531",
      "56dbdd9ba90042a1a7ba7075226a6a44",
      "3ed89d90b8d042d2b62f8f24711000df",
      "5359a706b7d04c81b9919471f7f4e275",
      "255c8c0083c040a188e98fea8afed4e0",
      "a356d74e3e1e46d08524c177fdab0c42",
      "d456c732a7934f4780a4e26adebe5d82",
      "64b1d8be1d114100b7ae1cb42bcb3425",
      "ef35c644d0824d529a22bed78aac1ab6",
      "6ee5321a01df4387942623a911ad4245",
      "927b0d1b7f504f11bacd5ae4da1f66b3",
      "0ef258235434491b9d1a585639573073",
      "af533fa5914c4314aa5ff01979ba383d",
      "9807234201dd4c59978e2cb9573a5c9f",
      "ec4577be600d44a69b45cfcfa93d7b1d",
      "7c03819555b54cd981a9d3cdccfbb905",
      "d873ec6fb7b245089656551e517c8336",
      "b71e35f51d5f4495ad5e1468d701097d",
      "4a99e6fc584c4676bcbf18030f687ae3"
     ]
    },
    "id": "DcqgkF06fnkf",
    "outputId": "5d27ba2c-1e57-4d06-d696-790354f3a582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUN 0 ---\n",
      "Epoch 1: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe8c243d8684f55bedc1264ab893612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a333a47e0c6d401d8bce432abd09fa2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.008388).  Saving model ...\n",
      "Epoch 1: Done\n",
      "\n",
      "Epoch 2: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7328113627f14a52af40bff66a69c295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cfb9b053054e1da711a53c04691fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.008388 --> 0.006347).  Saving model ...\n",
      "Epoch 2: Done\n",
      "\n",
      "Epoch 3: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb7e40444874444825d3e23e667dda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb92104ceca14a81ab010e052279ddcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.006347 --> 0.005540).  Saving model ...\n",
      "Epoch 3: Done\n",
      "\n",
      "Epoch 4: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ffc4b3304f43df88d870501cd5ee64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35738882f30d428aa37748be1058a5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.005540 --> 0.005027).  Saving model ...\n",
      "Epoch 4: Done\n",
      "\n",
      "Epoch 5: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ef50b0d7724fc7a555125f9e48b9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311bce5318b243b3b1c2995f95705cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.005027 --> 0.004926).  Saving model ...\n",
      "Epoch 5: Done\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e22746936a42949023d4f0959a1ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUN 1 ---\n",
      "Epoch 1: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00525d86e443401093b2ec688969e7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fe9880fa194cce981b4b2f0cccf85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.008297).  Saving model ...\n",
      "Epoch 1: Done\n",
      "\n",
      "Epoch 2: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ba06c8e26e4f04984aae34f4bcab7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df073914d42490f803bf497e5381296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.008297 --> 0.006193).  Saving model ...\n",
      "Epoch 2: Done\n",
      "\n",
      "Epoch 3: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc48f7da54b42b8b4dd87edcb1cec49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7d1ebb0360471c94496237e277e572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.006193 --> 0.005337).  Saving model ...\n",
      "Epoch 3: Done\n",
      "\n",
      "Epoch 4: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32a26c18e5d434f9baa21be0010c49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbb02b5c59949558f8f6d71ea9414b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.005337 --> 0.004929).  Saving model ...\n",
      "Epoch 4: Done\n",
      "\n",
      "Epoch 5: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45769abe974402d81c61db56025aa8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5c6a7461384b8c8bbfb18f9d711193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.004929 --> 0.004699).  Saving model ...\n",
      "Epoch 5: Done\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b379f455a9d046a7ab22fce9be7debde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUN 2 ---\n",
      "Epoch 1: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc8b65135854b2cab286860db051925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743f33b4b59a4584ad3fb23ca9a28765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.008440).  Saving model ...\n",
      "Epoch 1: Done\n",
      "\n",
      "Epoch 2: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9254ccb3fba543e9945caac2f464c0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91c3810ec8f42afa66b3e2ae913147b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.008440 --> 0.006131).  Saving model ...\n",
      "Epoch 2: Done\n",
      "\n",
      "Epoch 3: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a9ed8d47c6482a8f91e0dc1c69af51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4025/3638738521.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mCHECKPOINT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./{}/{}_{}_current.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHECKPOINT_IDX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mBEST_CHECKPOINT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./{}/{}_{}_best.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHECKPOINT_IDX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         trained_model, val_metrics = train_model(\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Count from one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# EPOCH passes over our training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4025/3227100601.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(start_epochs, n_epochs, val_loss_min_input, training_loader, val_loader, model, checkpoint_path, best_model_path, verbose)\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder_name = 'checkpoints-avg-' + DATASET_NAME\n",
    "!mkdir $folder_name\n",
    "checkpoint_idx_path = \"{}/last_idx\".format(folder_name)\n",
    "\n",
    "# Set up current checkpoint index\n",
    "CHECKPOINT_IDX = 0\n",
    "if os.path.exists(checkpoint_idx_path):\n",
    "    idx_file = open(checkpoint_idx_path, 'r')\n",
    "    CHECKPOINT_IDX = int(idx_file.read()) + 1\n",
    "    idx_file.close()\n",
    "idx_file = open(checkpoint_idx_path, 'w')\n",
    "idx_file.write(str(CHECKPOINT_IDX))\n",
    "idx_file.close()\n",
    "\n",
    "logging.basicConfig(filename=\"{}/{}.log\".format(folder_name, CHECKPOINT_IDX), level=logging.INFO)\n",
    "\n",
    "all_test_metrics = np.zeros((TRAIN_REPEATS, 3), dtype=float)\n",
    "\n",
    "trained_model = None\n",
    "if TRAIN_FROM_SCRATCH:\n",
    "    for i in range(TRAIN_REPEATS):\n",
    "        run_header = \"--- RUN {} ---\".format(i)\n",
    "        print(run_header)\n",
    "        logging.info(run_header)\n",
    "        # Reinitialise weights\n",
    "        model = DistilBERTClass(leaf_count)\n",
    "        model.to(device)\n",
    "        \n",
    "        # Train/validate\n",
    "        CHECKPOINT_PATH = './{}/{}_{}_current.pt'.format(folder_name, CHECKPOINT_IDX, i)\n",
    "        BEST_CHECKPOINT_PATH = './{}/{}_{}_best.pt'.format(folder_name, CHECKPOINT_IDX, i)\n",
    "        trained_model, val_metrics = train_model(\n",
    "            1, # Count from one\n",
    "            EPOCHS, # EPOCH passes over our training set\n",
    "            np.Inf, \n",
    "            train_loader, \n",
    "            val_loader, \n",
    "            model, \n",
    "            CHECKPOINT_PATH,\n",
    "            BEST_CHECKPOINT_PATH,\n",
    "        )          \n",
    "        # Test\n",
    "        test_result = run_model(trained_model, test_loader)\n",
    "        test_metrics = get_metrics(test_result['outputs'], test_result['targets'], True, True)\n",
    "        all_test_metrics[i, :] = test_metrics\n",
    "    averaged = np.average(all_test_metrics, axis = 0)\n",
    "    averaged_display = '--- Average of {} runs:\\nLeaf accuracy: {}\\nLeaf precision: {}\\nLeaf AU(PRC): {}'.format(\n",
    "        TRAIN_REPEATS, averaged[0], averaged[1], averaged[2])\n",
    "    print(averaged_display)\n",
    "    logging.info(averaged_display)\n",
    "else:\n",
    "    load_path = '{}/{}_{}_{}.pt'.format(folder_name, LOAD_ITERATION, TRAIN_REPEATS - 1, 'best' if LOAD_BEST else 'current')\n",
    "    trained_model, _ = load_checkpoint(load_path, (encoder, classifier))\n",
    "    # Test\n",
    "    test_result = run_model(trained_model, test_loader)\n",
    "    get_metrics(test_result['outputs'], test_result['targets'], True, True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DB-Linear-old-avg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "255c8c0083c040a188e98fea8afed4e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ed89d90b8d042d2b62f8f24711000df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef35c644d0824d529a22bed78aac1ab6",
      "placeholder": "​",
      "style": "IPY_MODEL_64b1d8be1d114100b7ae1cb42bcb3425",
      "value": " 120406/120406 [2:07:24&lt;00:00, 15.76it/s]"
     }
    },
    "5359a706b7d04c81b9919471f7f4e275": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56dbdd9ba90042a1a7ba7075226a6a44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d456c732a7934f4780a4e26adebe5d82",
      "max": 120406,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a356d74e3e1e46d08524c177fdab0c42",
      "value": 120406
     }
    },
    "64b1d8be1d114100b7ae1cb42bcb3425": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7512c7bbac2b4a8a86e6759f3bbbc2b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bfa45769c90c4e50829b7bba9c673531",
       "IPY_MODEL_56dbdd9ba90042a1a7ba7075226a6a44",
       "IPY_MODEL_3ed89d90b8d042d2b62f8f24711000df"
      ],
      "layout": "IPY_MODEL_a36dc39df13c4fb6b06210e9f7d4e5cb"
     }
    },
    "a356d74e3e1e46d08524c177fdab0c42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a36dc39df13c4fb6b06210e9f7d4e5cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfa45769c90c4e50829b7bba9c673531": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_255c8c0083c040a188e98fea8afed4e0",
      "placeholder": "​",
      "style": "IPY_MODEL_5359a706b7d04c81b9919471f7f4e275",
      "value": "100%"
     }
    },
    "d456c732a7934f4780a4e26adebe5d82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef35c644d0824d529a22bed78aac1ab6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
