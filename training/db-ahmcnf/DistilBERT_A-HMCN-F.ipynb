{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exg8x5X50pM7"
   },
   "source": [
    "# Notebook settings\n",
    "This notebook is a universal frame for training the DistilBERT+Adapted HMCN-F model. It can take in any Parquet dataset with suitable configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37802,
     "status": "ok",
     "timestamp": 1635307768509,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "kzuN96GF0XuA",
    "outputId": "3888bf24-8177-496a-a316-b26e35e1bf70"
   },
   "outputs": [],
   "source": [
    "### Dataset configuration\n",
    "# The parquet folder. It should be located inside datasets/.\n",
    "DATASET_NAME   = 'Arts_Crafts_and_Sewing.parquet'\n",
    "# The input text column\n",
    "TEXT_COL_NAME  = 'title'\n",
    "# Which column to use as labelled classes. It should be a column of lists of strings.\n",
    "CLASS_COL_NAME = 'category'\n",
    "# How many hierarchical levels to work on. Note that the dataset must also have at least this many levels for every example.\n",
    "DEPTH = 2 \n",
    "\n",
    "### Checkpoint configuration\n",
    "# Whether to train from scratch or to load a checkpoint\n",
    "TRAIN_FROM_SCRATCH=False\n",
    "# Checkpoint iteration to load if not training from scratch\n",
    "LOAD_ITERATION=0\n",
    "# Last or best results from that iteration?\n",
    "LOAD_BEST=True\n",
    "\n",
    "### System configuration\n",
    "# Will try to use your NVIDIA GPU if one is available. Set to False to force CPU computation\n",
    "PREFER_GPU         = True\n",
    "# If you don't have the huggingface transformers library installed, flip this to True.\n",
    "# You only need to do this once. Once DistilBERT has been downloaded, it will be cached in your system's default user cache folder.\n",
    "# Once it is cached, please set this to False to avoid redownloads.\n",
    "INSTALL_DISTILBERT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9r_iHMmx75DM"
   },
   "source": [
    "# Import common libraries\n",
    "And also set up a few things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 24666,
     "status": "ok",
     "timestamp": 1635307793160,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "shaFdRkD74o1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import shutil, sys\n",
    "from sklearn import metrics\n",
    "import os\n",
    "\n",
    "# Set up GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() and PREFER_GPU else 'cpu'\n",
    "print('Using', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTb90c5tRJsf"
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13707,
     "status": "ok",
     "timestamp": 1635307806856,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "O8e3fhFSRPPw",
    "outputId": "f62876fc-11c1-4a35-8534-aa4e27db8d07",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Sewing, Trim &amp; Embellishments, Appliques &amp; De...</td>\n",
       "      <td>You Son of a Bitch! 1987 Embroidered Patch</td>\n",
       "      <td>The patch features the sweaty masculine handsh...</td>\n",
       "      <td>Honchosfx</td>\n",
       "      <td>[You son of a bitch patch - exclusive to Honch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Crafting, Paper &amp; Paper Crafts]</td>\n",
       "      <td>Origami Stars Papers Package 1H (5 packs)</td>\n",
       "      <td>With 5 packs stars folding paper, each pack ar...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Crafting, Soap Making]</td>\n",
       "      <td>Pinkie Tm Pinkie new 3D dog animal handmade so...</td>\n",
       "      <td>*2111993*21211991910000TEA2130200</td>\n",
       "      <td>Kristine Olka,MRobert M. Searns  []ACharles A....</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Crafting, Ceramics &amp; Pottery, Clay Molds]</td>\n",
       "      <td>Pinkie Tm Rabbit animal silicone soap mold for...</td>\n",
       "      <td>moldsize:L7.2xW3.7xH4.8cm(L2.83xW1.46xH1.89inc...</td>\n",
       "      <td>pinkie</td>\n",
       "      <td>[Made in 100% pure silicone,softness and comfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Crafting, Soap Making, Molds]</td>\n",
       "      <td>Pinkie Tm Female skeleton head soap DIY cold s...</td>\n",
       "      <td>moldsize:L9.5xW7.8xH3.5cm(L3.74xW3.07xH1.38inc...</td>\n",
       "      <td>pinkie</td>\n",
       "      <td>[Made in 100% pure silicone,softness and comfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Crafting, Ceramics &amp; Pottery]</td>\n",
       "      <td>Pinkie Tm DIY cactus silicone soap mold Candle...</td>\n",
       "      <td>1.2.3.4.@1/0022/0073/0134/0205/0266/0327/0388/...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Crafting, Soap Making, Molds]</td>\n",
       "      <td>Pinkie Tm honeybee bee molds,Handmade silicone...</td>\n",
       "      <td>moldsize:L8.5xW8.5xH3.3cm(L3.35xW3.35xH1.30inc...</td>\n",
       "      <td>pinkie</td>\n",
       "      <td>[Made in 100% pure silicone,softness and comfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Crafting, Ceramics &amp; Pottery, Clay Molds]</td>\n",
       "      <td>Pinkie Tm Flower Fairy Soap Mold silicone cand...</td>\n",
       "      <td>moldsize:L7.6xW7.6xH7.6cm(L2.99xW2.99xH2.99inc...</td>\n",
       "      <td>pinkie</td>\n",
       "      <td>[Made in 100% pure silicone,softness and comfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Crafting, Soap Making, Molds]</td>\n",
       "      <td>Pinkie Tm angel girl praying Handmade soap sil...</td>\n",
       "      <td>moldsize:L9.5xW7.5xH3.2cm(L3.74xW2.95xH1.25inc...</td>\n",
       "      <td>pinkie</td>\n",
       "      <td>[Made in 100% pure silicone,softness and comfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Organization, Storage &amp; Transport, Craft &amp; Se...</td>\n",
       "      <td>Disney Princess -Throw Pillows 2 Fabric Fat Qu...</td>\n",
       "      <td>What Is a Fat Quarter?\\nA fat quarter is a one...</td>\n",
       "      <td>Web Arts and Crafts Queen</td>\n",
       "      <td>[you will get 2 fat quarters for your sewing p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                category  \\\n",
       "index                                                      \n",
       "0      [Sewing, Trim & Embellishments, Appliques & De...   \n",
       "1                       [Crafting, Paper & Paper Crafts]   \n",
       "2                                [Crafting, Soap Making]   \n",
       "3             [Crafting, Ceramics & Pottery, Clay Molds]   \n",
       "4                         [Crafting, Soap Making, Molds]   \n",
       "5                         [Crafting, Ceramics & Pottery]   \n",
       "6                         [Crafting, Soap Making, Molds]   \n",
       "7             [Crafting, Ceramics & Pottery, Clay Molds]   \n",
       "8                         [Crafting, Soap Making, Molds]   \n",
       "9      [Organization, Storage & Transport, Craft & Se...   \n",
       "\n",
       "                                                   title  \\\n",
       "index                                                      \n",
       "0             You Son of a Bitch! 1987 Embroidered Patch   \n",
       "1              Origami Stars Papers Package 1H (5 packs)   \n",
       "2      Pinkie Tm Pinkie new 3D dog animal handmade so...   \n",
       "3      Pinkie Tm Rabbit animal silicone soap mold for...   \n",
       "4      Pinkie Tm Female skeleton head soap DIY cold s...   \n",
       "5      Pinkie Tm DIY cactus silicone soap mold Candle...   \n",
       "6      Pinkie Tm honeybee bee molds,Handmade silicone...   \n",
       "7      Pinkie Tm Flower Fairy Soap Mold silicone cand...   \n",
       "8      Pinkie Tm angel girl praying Handmade soap sil...   \n",
       "9      Disney Princess -Throw Pillows 2 Fabric Fat Qu...   \n",
       "\n",
       "                                             description  \\\n",
       "index                                                      \n",
       "0      The patch features the sweaty masculine handsh...   \n",
       "1      With 5 packs stars folding paper, each pack ar...   \n",
       "2                      *2111993*21211991910000TEA2130200   \n",
       "3      moldsize:L7.2xW3.7xH4.8cm(L2.83xW1.46xH1.89inc...   \n",
       "4      moldsize:L9.5xW7.8xH3.5cm(L3.74xW3.07xH1.38inc...   \n",
       "5      1.2.3.4.@1/0022/0073/0134/0205/0266/0327/0388/...   \n",
       "6      moldsize:L8.5xW8.5xH3.3cm(L3.35xW3.35xH1.30inc...   \n",
       "7      moldsize:L7.6xW7.6xH7.6cm(L2.99xW2.99xH2.99inc...   \n",
       "8      moldsize:L9.5xW7.5xH3.2cm(L3.74xW2.95xH1.25inc...   \n",
       "9      What Is a Fat Quarter?\\nA fat quarter is a one...   \n",
       "\n",
       "                                                   brand  \\\n",
       "index                                                      \n",
       "0                                              Honchosfx   \n",
       "1                                                          \n",
       "2      Kristine Olka,MRobert M. Searns  []ACharles A....   \n",
       "3                                                 pinkie   \n",
       "4                                                 pinkie   \n",
       "5                                                          \n",
       "6                                                 pinkie   \n",
       "7                                                 pinkie   \n",
       "8                                                 pinkie   \n",
       "9                              Web Arts and Crafts Queen   \n",
       "\n",
       "                                                 feature  \n",
       "index                                                     \n",
       "0      [You son of a bitch patch - exclusive to Honch...  \n",
       "1                                                     []  \n",
       "2                                                     []  \n",
       "3      [Made in 100% pure silicone,softness and comfo...  \n",
       "4      [Made in 100% pure silicone,softness and comfo...  \n",
       "5                                                     []  \n",
       "6      [Made in 100% pure silicone,softness and comfo...  \n",
       "7      [Made in 100% pure silicone,softness and comfo...  \n",
       "8      [Made in 100% pure silicone,softness and comfo...  \n",
       "9      [you will get 2 fat quarters for your sewing p...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dd.read_parquet('../../datasets/{}'.format(DATASET_NAME))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96eLOv0hMvCv"
   },
   "source": [
    "# Categorical-encode the classes\n",
    "Our implementation of HMCN-F uses ordered global-space indices. That is, in the numerical order will be all classes on the first level, THEN those on the second and so on, with each level's first index starting after the previous level's last index.\n",
    "\n",
    "For categorical encoding to work, the columns themselves must be in Dask's `category` datatype, instead of the default `object` type for non-numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1635307948128,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "AasvSxmA0HIu",
    "outputId": "003f50f4-43fa-4b55-d513-c8913ffebd24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Beading & Jewelry Making': 0, 'Crafting': 1, 'Fabric Decorating': 2, 'Knitting & Crochet': 3, 'Needlework': 4, 'Organization, Storage & Transport': 5, 'Painting, Drawing & Art Supplies': 6, 'Printmaking': 7, 'Relief & Block Printing Materials': 8, 'Scrapbooking & Stamping': 9, 'Sewing': 10}, {'Adhesive Vinyl': 0, 'Adhesives': 1, 'Albums & Refills': 2, 'Application Tools': 3, 'Art & Poster Tubes': 4, 'Art Paper': 5, 'Art Tool & Sketch Boxes': 6, 'Basket Making': 7, 'Beading Storage': 8, 'Beading Supplies': 9, 'Beads & Bead Assortments': 10, 'Boards & Canvas': 11, 'Brush & Pen Cleaners': 12, 'Candle Making': 13, 'Ceramics & Pottery': 14, 'Charms': 15, 'Chipboard': 16, 'Craft & Sewing Supplies Storage': 17, 'Craft Supplies': 18, 'Crochet Hooks': 19, 'Crochet Kits': 20, 'Crochet Patterns': 21, 'Crochet Thread': 22, 'Cross-Stitch': 23, 'Die-Cutting & Embossing': 24, 'Doll Making': 25, 'Drawing': 26, 'Drawing Paper': 27, 'Drying & Print Racks': 28, 'Easels': 29, 'Embroidery': 30, 'Embroidery Machines': 31, 'Engraving Machines & Tools': 32, 'Etching Supplies': 33, 'Fabric & Textile Paints': 34, 'Fabric Decorating Kits': 35, 'Felt Applique Kits': 36, 'Fixatives': 37, 'Flat & Vertical Files': 38, 'Floral Arranging': 39, 'Fusible Glass Supplies': 40, 'Heat Press Machines & Accessories': 41, 'Industrial Machines': 42, 'Jewelry Casting Supplies': 43, 'Jewelry Findings': 44, 'Jewelry Making Display & Packaging Supplies': 45, 'Jewelry Making Kits': 46, 'Jewelry Making Tools & Accessories': 47, 'Jewelry Patterns': 48, 'Knitting & Crochet Notions': 49, 'Knitting Kits': 50, 'Knitting Looms & Boards': 51, 'Knitting Needles': 52, 'Knitting Patterns': 53, 'Latch Hook': 54, 'Latch Hook Kits': 55, 'Leathercraft': 56, 'Metal Stamping Tools': 57, 'Mosaic Making': 58, 'Needle Cases': 59, 'Needle Felting Supplies': 60, 'Needlepoint': 61, 'Paint Brush Organizers & Holders': 62, 'Painting': 63, 'Paper & Paper Crafts': 64, 'Photo Transfer & Coloring Supplies': 65, 'Picture Framing': 66, 'Pipe Cleaners': 67, 'Polishing & Buffing': 68, 'Portfolios': 69, 'Printing Linoleum': 70, 'Printing Presses & Accessories': 71, 'Printmaking Inks': 72, 'Punch Needle & Rug Punch': 73, 'Purse Making': 74, 'Quilting': 75, 'Relief & Block Printing Materials': 76, 'Safely lifts out dirt': 77, 'Scrapbooking Embellishments': 78, 'Scrapbooking Tools': 79, 'Scratchboards & Foil Engraving': 80, 'Screen Printing': 81, 'Sculpture Supplies': 82, 'Serger & Overlock Machine Accessories': 83, 'Sergers & Overlock Machines': 84, 'Sewing Machine Parts & Accessories': 85, 'Sewing Machines': 86, 'Sewing Notions & Supplies': 87, 'Sewing Patterns & Templates': 88, 'Sewing Project Kits': 89, 'Soap Making': 90, 'Stained Glass Making': 91, 'Stamps & Ink Pads': 92, 'Stickers & Sticker Machines': 93, 'Storage & Furniture': 94, 'Storage Boxes & Organizers': 95, 'Storage Cabinets': 96, 'Suncatcher Supplies': 97, 'Tatting & Lacemaking': 98, 'Thread & Floss': 99, 'Trim & Embellishments': 100, 'Wax Molding Materials': 101, 'Weaving & Spinning': 102, 'Woodcrafts': 103}]\n",
      "\n",
      "\n",
      "[['Beading & Jewelry Making', 'Crafting', 'Fabric Decorating', 'Knitting & Crochet', 'Needlework', 'Organization, Storage & Transport', 'Painting, Drawing & Art Supplies', 'Printmaking', 'Relief & Block Printing Materials', 'Scrapbooking & Stamping', 'Sewing'], ['Adhesive Vinyl', 'Adhesives', 'Albums & Refills', 'Application Tools', 'Art & Poster Tubes', 'Art Paper', 'Art Tool & Sketch Boxes', 'Basket Making', 'Beading Storage', 'Beading Supplies', 'Beads & Bead Assortments', 'Boards & Canvas', 'Brush & Pen Cleaners', 'Candle Making', 'Ceramics & Pottery', 'Charms', 'Chipboard', 'Craft & Sewing Supplies Storage', 'Craft Supplies', 'Crochet Hooks', 'Crochet Kits', 'Crochet Patterns', 'Crochet Thread', 'Cross-Stitch', 'Die-Cutting & Embossing', 'Doll Making', 'Drawing', 'Drawing Paper', 'Drying & Print Racks', 'Easels', 'Embroidery', 'Embroidery Machines', 'Engraving Machines & Tools', 'Etching Supplies', 'Fabric & Textile Paints', 'Fabric Decorating Kits', 'Felt Applique Kits', 'Fixatives', 'Flat & Vertical Files', 'Floral Arranging', 'Fusible Glass Supplies', 'Heat Press Machines & Accessories', 'Industrial Machines', 'Jewelry Casting Supplies', 'Jewelry Findings', 'Jewelry Making Display & Packaging Supplies', 'Jewelry Making Kits', 'Jewelry Making Tools & Accessories', 'Jewelry Patterns', 'Knitting & Crochet Notions', 'Knitting Kits', 'Knitting Looms & Boards', 'Knitting Needles', 'Knitting Patterns', 'Latch Hook', 'Latch Hook Kits', 'Leathercraft', 'Metal Stamping Tools', 'Mosaic Making', 'Needle Cases', 'Needle Felting Supplies', 'Needlepoint', 'Paint Brush Organizers & Holders', 'Painting', 'Paper & Paper Crafts', 'Photo Transfer & Coloring Supplies', 'Picture Framing', 'Pipe Cleaners', 'Polishing & Buffing', 'Portfolios', 'Printing Linoleum', 'Printing Presses & Accessories', 'Printmaking Inks', 'Punch Needle & Rug Punch', 'Purse Making', 'Quilting', 'Relief & Block Printing Materials', 'Safely lifts out dirt', 'Scrapbooking Embellishments', 'Scrapbooking Tools', 'Scratchboards & Foil Engraving', 'Screen Printing', 'Sculpture Supplies', 'Serger & Overlock Machine Accessories', 'Sergers & Overlock Machines', 'Sewing Machine Parts & Accessories', 'Sewing Machines', 'Sewing Notions & Supplies', 'Sewing Patterns & Templates', 'Sewing Project Kits', 'Soap Making', 'Stained Glass Making', 'Stamps & Ink Pads', 'Stickers & Sticker Machines', 'Storage & Furniture', 'Storage Boxes & Organizers', 'Storage Cabinets', 'Suncatcher Supplies', 'Tatting & Lacemaking', 'Thread & Floss', 'Trim & Embellishments', 'Wax Molding Materials', 'Weaving & Spinning', 'Woodcrafts']]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_classes(data, original_name, depth, verbose=False):\n",
    "    \"\"\"\n",
    "    Build a list of unique class names for each level and create bidirectional mappings.\n",
    "    \"\"\"\n",
    "    cls2idx = []\n",
    "    idx2cls = []\n",
    "    for i in range(depth): \n",
    "        category_li = data[original_name].apply(\n",
    "            lambda lst: lst[i], meta=(original_name, 'object')\n",
    "        ).astype('category').cat.as_known()\n",
    "        if verbose:\n",
    "            print(category_li.cat.classes)\n",
    "        cls2idx.append(dict([\n",
    "            (category, index) \n",
    "            for (index, category) \n",
    "            in enumerate(category_li.cat.categories)\n",
    "        ]))\n",
    "        idx2cls.append(list(category_li.cat.categories))\n",
    "    return cls2idx, idx2cls\n",
    "\n",
    "cls2idx, idx2cls = preprocess_classes(data, CLASS_COL_NAME, DEPTH)    \n",
    "print(cls2idx)\n",
    "print('\\n')\n",
    "print(idx2cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4sXPxkKzUK2"
   },
   "source": [
    "Now we can generate indices to use as class labels for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4705,
     "status": "ok",
     "timestamp": 1635307994979,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "S4K8ScuazR4l",
    "outputId": "d132c6c8-20ad-4312-ca1a-3a5dac1a395f"
   },
   "outputs": [],
   "source": [
    "def class_to_index(data, original_name, cls2idx, depth):\n",
    "    data['codes'] = data[original_name].apply(\n",
    "        lambda lst: [\n",
    "            cls2idx[i][cat] \n",
    "            for (i, cat) \n",
    "            in enumerate(lst[:depth])\n",
    "        ],\n",
    "        meta=(original_name, 'object')\n",
    "    ).astype('object')\n",
    "\n",
    "class_to_index(data, CLASS_COL_NAME, cls2idx, DEPTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, binarise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>codes</th>\n",
       "      <th>codes_b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Sewing, Trim &amp; Embellishments, Appliques &amp; De...</td>\n",
       "      <td>You Son of a Bitch! 1987 Embroidered Patch</td>\n",
       "      <td>The patch features the sweaty masculine handsh...</td>\n",
       "      <td>Honchosfx</td>\n",
       "      <td>[You son of a bitch patch - exclusive to Honch...</td>\n",
       "      <td>[10, 100]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Crafting, Paper &amp; Paper Crafts]</td>\n",
       "      <td>Origami Stars Papers Package 1H (5 packs)</td>\n",
       "      <td>With 5 packs stars folding paper, each pack ar...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 64]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Crafting, Soap Making]</td>\n",
       "      <td>Pinkie Tm Pinkie new 3D dog animal handmade so...</td>\n",
       "      <td>*2111993*21211991910000TEA2130200</td>\n",
       "      <td>Kristine Olka,MRobert M. Searns  []ACharles A....</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 90]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Crafting, Ceramics &amp; Pottery, Clay Molds]</td>\n",
       "      <td>Pinkie Tm Rabbit animal silicone soap mold for...</td>\n",
       "      <td>moldsize:L7.2xW3.7xH4.8cm(L2.83xW1.46xH1.89inc...</td>\n",
       "      <td>pinkie</td>\n",
       "      <td>[Made in 100% pure silicone,softness and comfo...</td>\n",
       "      <td>[1, 14]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Crafting, Soap Making, Molds]</td>\n",
       "      <td>Pinkie Tm Female skeleton head soap DIY cold s...</td>\n",
       "      <td>moldsize:L9.5xW7.8xH3.5cm(L3.74xW3.07xH1.38inc...</td>\n",
       "      <td>pinkie</td>\n",
       "      <td>[Made in 100% pure silicone,softness and comfo...</td>\n",
       "      <td>[1, 90]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Crafting, Ceramics &amp; Pottery]</td>\n",
       "      <td>Pinkie Tm DIY cactus silicone soap mold Candle...</td>\n",
       "      <td>1.2.3.4.@1/0022/0073/0134/0205/0266/0327/0388/...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 14]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Crafting, Soap Making, Molds]</td>\n",
       "      <td>Pinkie Tm honeybee bee molds,Handmade silicone...</td>\n",
       "      <td>moldsize:L8.5xW8.5xH3.3cm(L3.35xW3.35xH1.30inc...</td>\n",
       "      <td>pinkie</td>\n",
       "      <td>[Made in 100% pure silicone,softness and comfo...</td>\n",
       "      <td>[1, 90]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Crafting, Ceramics &amp; Pottery, Clay Molds]</td>\n",
       "      <td>Pinkie Tm Flower Fairy Soap Mold silicone cand...</td>\n",
       "      <td>moldsize:L7.6xW7.6xH7.6cm(L2.99xW2.99xH2.99inc...</td>\n",
       "      <td>pinkie</td>\n",
       "      <td>[Made in 100% pure silicone,softness and comfo...</td>\n",
       "      <td>[1, 14]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Crafting, Soap Making, Molds]</td>\n",
       "      <td>Pinkie Tm angel girl praying Handmade soap sil...</td>\n",
       "      <td>moldsize:L9.5xW7.5xH3.2cm(L3.74xW2.95xH1.25inc...</td>\n",
       "      <td>pinkie</td>\n",
       "      <td>[Made in 100% pure silicone,softness and comfo...</td>\n",
       "      <td>[1, 90]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Organization, Storage &amp; Transport, Craft &amp; Se...</td>\n",
       "      <td>Disney Princess -Throw Pillows 2 Fabric Fat Qu...</td>\n",
       "      <td>What Is a Fat Quarter?\\nA fat quarter is a one...</td>\n",
       "      <td>Web Arts and Crafts Queen</td>\n",
       "      <td>[you will get 2 fat quarters for your sewing p...</td>\n",
       "      <td>[5, 17]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                category  \\\n",
       "index                                                      \n",
       "0      [Sewing, Trim & Embellishments, Appliques & De...   \n",
       "1                       [Crafting, Paper & Paper Crafts]   \n",
       "2                                [Crafting, Soap Making]   \n",
       "3             [Crafting, Ceramics & Pottery, Clay Molds]   \n",
       "4                         [Crafting, Soap Making, Molds]   \n",
       "5                         [Crafting, Ceramics & Pottery]   \n",
       "6                         [Crafting, Soap Making, Molds]   \n",
       "7             [Crafting, Ceramics & Pottery, Clay Molds]   \n",
       "8                         [Crafting, Soap Making, Molds]   \n",
       "9      [Organization, Storage & Transport, Craft & Se...   \n",
       "\n",
       "                                                   title  \\\n",
       "index                                                      \n",
       "0             You Son of a Bitch! 1987 Embroidered Patch   \n",
       "1              Origami Stars Papers Package 1H (5 packs)   \n",
       "2      Pinkie Tm Pinkie new 3D dog animal handmade so...   \n",
       "3      Pinkie Tm Rabbit animal silicone soap mold for...   \n",
       "4      Pinkie Tm Female skeleton head soap DIY cold s...   \n",
       "5      Pinkie Tm DIY cactus silicone soap mold Candle...   \n",
       "6      Pinkie Tm honeybee bee molds,Handmade silicone...   \n",
       "7      Pinkie Tm Flower Fairy Soap Mold silicone cand...   \n",
       "8      Pinkie Tm angel girl praying Handmade soap sil...   \n",
       "9      Disney Princess -Throw Pillows 2 Fabric Fat Qu...   \n",
       "\n",
       "                                             description  \\\n",
       "index                                                      \n",
       "0      The patch features the sweaty masculine handsh...   \n",
       "1      With 5 packs stars folding paper, each pack ar...   \n",
       "2                      *2111993*21211991910000TEA2130200   \n",
       "3      moldsize:L7.2xW3.7xH4.8cm(L2.83xW1.46xH1.89inc...   \n",
       "4      moldsize:L9.5xW7.8xH3.5cm(L3.74xW3.07xH1.38inc...   \n",
       "5      1.2.3.4.@1/0022/0073/0134/0205/0266/0327/0388/...   \n",
       "6      moldsize:L8.5xW8.5xH3.3cm(L3.35xW3.35xH1.30inc...   \n",
       "7      moldsize:L7.6xW7.6xH7.6cm(L2.99xW2.99xH2.99inc...   \n",
       "8      moldsize:L9.5xW7.5xH3.2cm(L3.74xW2.95xH1.25inc...   \n",
       "9      What Is a Fat Quarter?\\nA fat quarter is a one...   \n",
       "\n",
       "                                                   brand  \\\n",
       "index                                                      \n",
       "0                                              Honchosfx   \n",
       "1                                                          \n",
       "2      Kristine Olka,MRobert M. Searns  []ACharles A....   \n",
       "3                                                 pinkie   \n",
       "4                                                 pinkie   \n",
       "5                                                          \n",
       "6                                                 pinkie   \n",
       "7                                                 pinkie   \n",
       "8                                                 pinkie   \n",
       "9                              Web Arts and Crafts Queen   \n",
       "\n",
       "                                                 feature      codes  \\\n",
       "index                                                                 \n",
       "0      [You son of a bitch patch - exclusive to Honch...  [10, 100]   \n",
       "1                                                     []    [1, 64]   \n",
       "2                                                     []    [1, 90]   \n",
       "3      [Made in 100% pure silicone,softness and comfo...    [1, 14]   \n",
       "4      [Made in 100% pure silicone,softness and comfo...    [1, 90]   \n",
       "5                                                     []    [1, 14]   \n",
       "6      [Made in 100% pure silicone,softness and comfo...    [1, 90]   \n",
       "7      [Made in 100% pure silicone,softness and comfo...    [1, 14]   \n",
       "8      [Made in 100% pure silicone,softness and comfo...    [1, 90]   \n",
       "9      [you will get 2 fat quarters for your sewing p...    [5, 17]   \n",
       "\n",
       "                                                 codes_b  \n",
       "index                                                     \n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "6      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "7      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "8      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9      [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "# C-HMCNN needs global-space indices. As such we need to offset the level codes.\n",
    "# We still make use of the local-space code above to increase commonality with other models.\n",
    "def index_to_binary(data, index_col_name, offsets, sz, verbose=False):\n",
    "    if verbose:\n",
    "        print('Using offsets:', offsets)\n",
    "    \n",
    "    def generate_binary(codes):\n",
    "        b = np.zeros(sz, dtype=int)\n",
    "        indices = np.array(codes, dtype=int) + offsets[:-1]\n",
    "        if verbose:\n",
    "            print(codes, offsets, indices)\n",
    "        b[indices] = 1\n",
    "        return b.tolist()\n",
    "    \n",
    "    data[index_col_name + '_b'] = data[index_col_name].apply(\n",
    "        lambda lst: generate_binary(lst),\n",
    "        meta=(index_col_name + '_b', 'object')\n",
    "    )\n",
    "    \n",
    "level_sizes = [*map(lambda lst: len(lst), idx2cls)]\n",
    "level_offsets = np.array(reduce(lambda acc, elem: acc + [acc[-1] + elem], level_sizes, [0]))\n",
    "index_to_binary(data, 'codes', level_offsets, sum(level_sizes), verbose=False)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyrIcY8O3Pjl"
   },
   "source": [
    "We can try recovering category names from this encoding to see if it is still in the original hierarchical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1635308025470,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "_-Pvksp33XHj",
    "outputId": "b6f190b6-d420-4ba1-9688-9e1e2d4e1dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: index\n",
      "3    [Crafting, Ceramics & Pottery, Clay Molds]\n",
      "Name: category, dtype: object\n",
      "Retrieved: ['Crafting', 'Ceramics & Pottery']\n"
     ]
    }
   ],
   "source": [
    "def retrieve_classes(codes, idx2cls):\n",
    "    return [ idx2cls[i][code] for (i, code) in enumerate(codes) ]\n",
    "\n",
    "print('Original:', data.loc[3].compute()['category'][0:DEPTH])\n",
    "\n",
    "print('Retrieved:', retrieve_classes(data['codes'].loc[3].compute().iloc[0], idx2cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Smg58QeJ6jK-"
   },
   "source": [
    "# Hierarchy generation\n",
    "In this model, the hierarchical error penalty is simply $L_H = \\lambda \\times max(Y_{child} - Y_{parent})$. As such, we need to keep track of each node's parent and vectorise the calculation.\n",
    "\n",
    "For now I'll be implementing this as simple arrays of category codes (in the global categorical space). We can then use these arrays of codes as vectorised indices to pull out $Y_{parent}$s and have our loss function somewhat vectorised too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1004,
     "status": "ok",
     "timestamp": 1635308148041,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "nDMbz01-BORD"
   },
   "outputs": [],
   "source": [
    "# TODO: Bring the above code into this thing's constructor entirely.\n",
    "from functools import reduce\n",
    "class PerLevelHierarchy:\n",
    "    # level_sizes is a list of (distinct) class counts per hierarchical level.\n",
    "    #   Its length dictates the maximum hierarchy construction depth.\n",
    "    #   (that is, our above code)\n",
    "    # classes is the list of distinct classes, in the order we have assembled.\n",
    "    def __init__(self, data, cls2idx):\n",
    "        self.levels = [ len(d.keys()) for d in cls2idx ] # TODO: Rename to level_sizes\n",
    "        self.classes = reduce(lambda acc, elem: acc + elem, [ list(d.keys()) for d in cls2idx ], [])\n",
    "        # Where each level starts in a global n-hot category vector\n",
    "        # Its last element is coincidentally the length, which also allows us\n",
    "        # to simplify the slicing code by blindly doing [offset[i] : offset[i+1]]\n",
    "        self.level_offsets = reduce(lambda acc, elem: acc + [acc[len(acc) - 1] + elem], self.levels, [0])\n",
    "        # Use -1 to indicate 'undiscovered'\n",
    "        self.parent_of = [-1] * len(self.classes)\n",
    "        for lst in data['codes']:\n",
    "            # First-level classes' parent is root, but here we set them to themselves.\n",
    "            # This effectively zeroes out the hierarchical loss for this level.\n",
    "            self.parent_of[lst[0]] = lst[0]\n",
    "            for i in range(1, len(self.levels)):\n",
    "                child_idx = lst[i] + self.level_offsets[i]\n",
    "                parent_idx = lst[i-1] + self.level_offsets[i - 1]\n",
    "                if self.parent_of[child_idx] == -1:\n",
    "                    self.parent_of[child_idx] = parent_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1635308149130,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "zSI6Ket7Gj8v",
    "outputId": "58a86d5f-6ac5-40e8-dc63-024ebb6f64a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 10,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 10,\n",
       " 7,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 10,\n",
       " 10,\n",
       " 0,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy = PerLevelHierarchy(data, cls2idx)\n",
    "hierarchy.parent_of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_btMadIfe7A"
   },
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1635308304269,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "mIDVu-5Ffd6v"
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_fpath, model):\n",
    "    encoder, classifier = model\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    classifier.load_state_dict(checkpoint['state_dict'])\n",
    "    return (encoder, classifier)\n",
    "\n",
    "def save_checkpoint(state, is_best, checkpoint_path, best_model_path):\n",
    "    f_path = checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "We define hierarchical accuracy as simply the averaged accuracy over each level. Same for precision. With HMCN-F, we use the final output $P_F$.\n",
    "In addition to those, at the end of the testing phase we'll also compute the average area under the precision-recall curve (AU(PRC))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(outputs, targets, level_sizes, print_metrics=True):\n",
    "    offsets = [0] + level_sizes\n",
    "    level_codes = [ \n",
    "        np.argmax(outputs[:, offsets[level] : offsets[level + 1]], axis=1) + offsets[level] \n",
    "        for level in range(len(level_sizes))\n",
    "    ]\n",
    "    \n",
    "    target_codes = np.array([ np.nonzero(lst)[0] for lst in targets ], dtype=int)\n",
    "    \n",
    "    accuracies = [ metrics.accuracy_score(level_codes[level], target_codes[:, level]) for level in range(len(level_sizes)) ]\n",
    "    precisions = [ metrics.precision_score(level_codes[level], target_codes[:, level], average='weighted') for level in range(len(level_sizes)) ]\n",
    "    \n",
    "    global_accuracy = sum(accuracies)/len(accuracies)\n",
    "    global_precision = sum(precisions)/len(precisions)\n",
    "    \n",
    "    if print_metrics:\n",
    "        for i in range(len(level_sizes)):\n",
    "            print('Level {}:'.format(i))\n",
    "            print(\"Accuracy:\", accuracies[i])\n",
    "            # Model Precision: what percentage of positive tuples are labeled as such?\n",
    "            print(\"Precision:\", precisions[i],'\\n')\n",
    "        print('Path average:')\n",
    "        print('Accuracy:', global_accuracy)\n",
    "        print('Precision:', global_precision)\n",
    "    \n",
    "    return np.array([accuracies[-1], precisions[-1], global_accuracy, global_precision])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6K2Cm1Bq7Kl"
   },
   "source": [
    "# Data and model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRp5rd9W3rXm"
   },
   "source": [
    "## Installing DistilBERT\n",
    "Alternative to full-fat BERT, roughly matching its performance while being faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10456,
     "status": "ok",
     "timestamp": 1635308165267,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "jx5V1QzS3wRX",
    "outputId": "b3ca5363-5788-48e5-9c3d-2c03fc1049ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "if not INSTALL_DISTILBERT:\n",
    "    os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "else:\n",
    "    !pip install transformers\n",
    "    \n",
    "import transformers as ppb\n",
    "tokenizer = ppb.DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "base_encoder = ppb.DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "base_encoder_state = base_encoder.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vr1iQObJQOPB"
   },
   "source": [
    "## Define our dataset adapter class\n",
    "This wraps around our data and provides a PyTorch-compatible interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1635308165271,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "I8cdh6oiQTsq"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, df, hierarchy, tokenizer, max_len, text_col_name = TEXT_COL_NAME):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.text = df[text_col_name]\n",
    "    # Level sizes\n",
    "    self.levels = hierarchy.levels\n",
    "    self.labels = df.codes_b\n",
    "    self.level_offsets = hierarchy.level_offsets\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.text)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    text = str(self.text.iloc[index])\n",
    "    text = \" \".join(text.split())\n",
    "    inputs = self.tokenizer(\n",
    "      text,\n",
    "      None, # No text_pair\n",
    "      add_special_tokens=True, # CLS, SEP\n",
    "      max_length=self.max_len, # For us it's a hyperparam. See next cells.\n",
    "      padding='max_length',\n",
    "      truncation=True\n",
    "      # BERT tokenisers return attention masks by default\n",
    "    )\n",
    "\n",
    "    labels = torch.tensor(self.labels.loc[index], dtype=torch.long)\n",
    "\n",
    "    result = {\n",
    "      'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "      'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "      'labels': labels,\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZywhH4tS2Q0"
   },
   "source": [
    "Regarding that `max_len` hyperparameter, let's see the text lengths' distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 1200,
     "status": "ok",
     "timestamp": 1635308166461,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "LN-EM4dWS02O",
    "outputId": "c20c5dca-744d-4e14-bc99-679e8e68cb50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/dask/dataframe/core.py:3718: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('title', 'int64'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[TEXT_COL_NAME].apply(lambda s: len(s.split())).compute().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ33DAURTg3I"
   },
   "source": [
    "We prefer `max_len` to be a power of two that covers most of the strings. Here it seems 64 will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1635308388604,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "wpFTDAgDq_oV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘checkpoints-Arts_Crafts_and_Sewing.parquet’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### TUNING HYPERPARAMETERS?\n",
    "### Simply adjust here then run this cell and those below it. No need to run those above.\n",
    "###\n",
    "\n",
    "folder_name = 'checkpoints-' + DATASET_NAME\n",
    "!mkdir $folder_name\n",
    "CHECKPOINT_IDX = len(os.listdir(folder_name)) // 2\n",
    "CHECKPOINT_PATH = './{}/{}_current.pt'.format(folder_name, CHECKPOINT_IDX)\n",
    "BEST_CHECKPOINT_PATH = './{}/{}_best.pt'.format(folder_name, CHECKPOINT_IDX)\n",
    "\n",
    "config = {\n",
    "    'cls_lr': 1e-03,\n",
    "    'lambda_h': 0.7,\n",
    "    'epochs': 5,\n",
    "    'dropout': 0.25,\n",
    "    'global_hidden_sizes': [384] * len(hierarchy.levels),\n",
    "    'local_hidden_sizes': [384] * len(hierarchy.levels),\n",
    "    'global_weight': 0.5,\n",
    "    'hidden_nonlinear': 'relu'\n",
    "}\n",
    "\n",
    "### Don't change these if you need to compare with published results\n",
    "MAX_LEN = 64\n",
    "TRAIN_MINIBATCH_SIZE = 64\n",
    "VAL_TEST_MINIBATCH_SIZE = 64\n",
    "TRAIN_SET_RATIO = 0.8\n",
    "VAL_SET_RATIO = 0.1\n",
    "# The rest is test set\n",
    "RANDOM_SEED = 123\n",
    "# Flip to False for faster hyperparameter tuning. If False, only 5% of the full dataset is used. \n",
    "FULL_SET = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vRe05MEHZ9g"
   },
   "source": [
    "CV-split our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1211,
     "status": "ok",
     "timestamp": 1635308170890,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "8973_cElHYg2",
    "outputId": "db7e22e7-b868-43ec-a114-4294c462cda3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174176, 2)\n",
      "(21772, 2)\n",
      "(21772, 2)\n"
     ]
    }
   ],
   "source": [
    "small_data = None\n",
    "if not FULL_SET:\n",
    "    small_data = data.sample(frac = 0.05, random_state=RANDOM_SEED)\n",
    "\n",
    "train_set = None\n",
    "test_set = None\n",
    "\n",
    "COLUMNS = [TEXT_COL_NAME, 'codes_b']\n",
    "\n",
    "filtered = None\n",
    "if FULL_SET:\n",
    "    filtered = data[COLUMNS].compute()\n",
    "else:\n",
    "    filtered = small_data[COLUMNS].compute()\n",
    "\n",
    "train_set = filtered.sample(frac = TRAIN_SET_RATIO, random_state=RANDOM_SEED)\n",
    "val_test_set = filtered.drop(train_set.index)\n",
    "\n",
    "val_set = val_test_set.sample(frac = VAL_SET_RATIO / (1-TRAIN_SET_RATIO), random_state=RANDOM_SEED)\n",
    "test_set = val_test_set.drop(val_set.index)\n",
    "\n",
    "train_set = train_set.reset_index(drop=True)\n",
    "val_set = val_set.reset_index(drop=True)\n",
    "test_set = test_set.reset_index(drop=True)\n",
    "\n",
    "print(train_set.shape)\n",
    "print(val_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PXLfuJcV2aK"
   },
   "source": [
    "We can now wrap them in our Datasets, and then into PyTorch's DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451,
     "referenced_widgets": [
      "3bf6825b7c0a4d75a5b6340575af92b7",
      "d67011f140984c90bcb2e5897e9cfec7",
      "3be0b068814c4625a8a26aaae6246fc5",
      "e83112deff534d02b02dab80d89f4c13",
      "8b59a1c8120d400285775ab9c7bf5fd0",
      "bcfe3b9cc0a84a71a23fe066e9f91f50",
      "9cf4df1b32a641118d1ec674040af9b6",
      "ab35a23f71ec4614a8d08ff9e97af4fd",
      "f4e89f31eee747959dfb78c50fcc3f4b",
      "49c2b1ce77694e378d0fdb66b1c56404",
      "76ecfa0377a9483db59cf4f3f8210f77",
      "df715fedf06d47b89a781ab143c31366",
      "34e07de58f3a4b7ea2224d8a496e869e",
      "480f7683750f4c8da678a997d1b6fce0",
      "cd184a49854a492db0f7338ddf1f25e5",
      "1093cda242734ed68f90ef8113ed2382",
      "6302b6fb6b22452999336c113b677dc4",
      "ad1dc10ec89e4e4fb92c87e1d900ba98",
      "09d6a6951d0647dcb714bc95d13c7036",
      "b3fb0b54a4c749789f8778c797de2a74",
      "205ba318b331401e8f8d66e532caa13f",
      "83ff5a1fcc5e40b19dba8346d43e57e0",
      "ecf624390bc24aed86e39d326dd2ac3f",
      "06622e52beb544b7a2b464d1de0902a1",
      "5717f1f6da554c83863f1fd513c76dc0",
      "1b2acc83686d4baf9768c19e68e08d31",
      "c997c00148b642388a7dfc5d4cea405a",
      "41ca3ed1ee364d9fb3ef06cc54abb557",
      "5b86bf4432244410b98d9f9d6b5fc676",
      "4778017f533d4360bce2a5d6b8a5b6cc",
      "8d4e5e118a55491a919f21304ca2d551",
      "926d83822645446885e7c9a9f5278674",
      "7e4105fcbc1148dba4cfe534c7a8e075",
      "d7b9dd68692d45e79ebb462eb1e52ed2",
      "56946bff74cc485797ed6b3498203651",
      "e4129340688f43b29db0a0378544a7f9",
      "ebe54699564d4587ab8d74857d4e8872",
      "97335ef817574cd58a87168b62763437",
      "e704839651a943a395100bb5da14759c",
      "bd923a63531e47f7b256ed4408780ef9",
      "1582c4067b56485b9366b146d357f5e4",
      "6749900841aa464ebcf3f3d56a24e4f0",
      "c33f0c0889024dabb79f1cf4c5855fff",
      "11294eb27f9a44599f1943202d83d956"
     ]
    },
    "executionInfo": {
     "elapsed": 2959,
     "status": "ok",
     "timestamp": 1635308208440,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "_b1j_gNdV9Ux",
    "outputId": "96226c0d-346f-4133-cffa-d6198eaf79b8"
   },
   "outputs": [],
   "source": [
    "train_set_wrapped = CustomDataset(train_set, hierarchy, tokenizer, MAX_LEN)\n",
    "val_set_wrapped = CustomDataset(val_set, hierarchy, tokenizer, MAX_LEN)\n",
    "test_set_wrapped = CustomDataset(test_set, hierarchy, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set_wrapped, batch_size=TRAIN_MINIBATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set_wrapped, batch_size=VAL_TEST_MINIBATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set_wrapped, batch_size=VAL_TEST_MINIBATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-yMcdJ6oW40"
   },
   "source": [
    "Test-run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1635308219460,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "FH7BNY8foX_g",
    "outputId": "78a96f48-2230-455a-ec12-f2d7adb17a97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([[  101,  1031,  1018,  ...,     0,     0,     0],\n",
       "         [  101,  5394,  2840,  ...,     0,     0,     0],\n",
       "         [  101,  3782,  1011,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101, 13675, 28852,  ...,     0,     0,     0],\n",
       "         [  101, 13528, 11554,  ...,     0,     0,     0],\n",
       "         [  101,  2227,  3064,  ...,     0,     0,     0]]),\n",
       " 'mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch = next(iter(test_loader))\n",
    "test_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGLkaGimW285"
   },
   "source": [
    "## Prepare the model itself\n",
    "Here we use DistilBERT as the encoding layers, followed by our implementation of HMCN-F."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4yHw2BlRhLM"
   },
   "source": [
    "### HMCN-F\n",
    "HMCN-F is specifically designed for maximizing the learn-\n",
    "ing capacity regarding the hierarchical structure of the la-\n",
    "beled data.\n",
    "\n",
    "In this model, information flows in two ways:\n",
    "i) the main flow, which begins with the input layer and tra-\n",
    "verses all fully-connected (FC) layers until it reaches the\n",
    "global output; and ii) the local flows, which also begin in the\n",
    "input layer and pass by their respective global FC layers but\n",
    "also through specific local FC layers, finally ending at the\n",
    "corresponding local output. For generating the final prediction, all local outputs are then concatenated and pooled with\n",
    "the global output for a consensual prediction.\n",
    "\n",
    "Code2paper notation mapping:\n",
    "- `feature_size` = $|D|$\n",
    "- `global_hidden_sizes` = list of $|A^i_G|$ for i in $[1, |H|]$\n",
    "- `local_hidden_sizes` = list of $|A^i_L|$ for i in $[1, |H|]$\n",
    "- hierarchy:\n",
    "  - `len(hierarchy.levels)` = $|H|$\n",
    "  - `len(hierarchy.classes)` = $|C|$\n",
    "- `global_weight` = $\\beta$\n",
    "\n",
    "**One significant difference between our version and the one in the paper** is that we replace batch normalisation with layer normalisation, which doesn't wreack havoc on NLP tasks like ours.\n",
    "\n",
    "The FC (linear) layers comprise 384 ReLU\n",
    "neurons, followed by a batch normalization, residual connections, and dropout of 60%. Dropout is important given\n",
    "that these models could easily overfit the small training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1635308265777,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "hGFxM_q2RpkC"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class HMCNF(torch.nn.Module):\n",
    "  def __init__(\n",
    "      self, \n",
    "      input_dim, \n",
    "      hierarchy,\n",
    "      config,\n",
    "      ):\n",
    "    super(HMCNF, self).__init__()\n",
    "\n",
    "    # Back up some parameters for use in forward()\n",
    "    self.depth = len(hierarchy.levels)\n",
    "    self.global_weight = config['global_weight']\n",
    "\n",
    "    # Construct global layers (main flow)\n",
    "    global_layers = []\n",
    "    global_layer_norms = []\n",
    "    for i in range(len(hierarchy.levels)):\n",
    "      if i == 0:\n",
    "        global_layers.append(\n",
    "            torch.nn.Linear(input_dim, config['global_hidden_sizes'][0]))\n",
    "      else:\n",
    "        global_layers.append(\n",
    "            torch.nn.Linear(config['global_hidden_sizes'][i-1] + input_dim, config['global_hidden_sizes'][i]))\n",
    "      global_layer_norms.append(torch.nn.LayerNorm(config['global_hidden_sizes'][i]))\n",
    "    self.global_layers = torch.nn.ModuleList(global_layers)\n",
    "    self.global_layer_norms = torch.nn.ModuleList(global_layer_norms)\n",
    "    # Global prediction layer\n",
    "    self.global_prediction_layer = torch.nn.Linear(\n",
    "        config['global_hidden_sizes'][-1] + input_dim, \n",
    "        len(hierarchy.classes)\n",
    "        )\n",
    "    \n",
    "    # Construct local branches (local flow).\n",
    "    # Each local branch has two linear layers: a transition layer and a local\n",
    "    # classification layer \n",
    "    transition_layers = []\n",
    "    local_layer_norms = []\n",
    "    local_layers = []\n",
    "    \n",
    "    for i in range(len(hierarchy.levels)):\n",
    "      transition_layers.append(\n",
    "          torch.nn.Linear(config['global_hidden_sizes'][i], config['local_hidden_sizes'][i]),\n",
    "      )\n",
    "      local_layer_norms.append(\n",
    "          torch.nn.LayerNorm(config['local_hidden_sizes'][i])\n",
    "      )\n",
    "      local_layers.append(\n",
    "          torch.nn.Linear(config['local_hidden_sizes'][i], hierarchy.levels[i])\n",
    "      )\n",
    "    self.local_layer_norms = torch.nn.ModuleList(local_layer_norms)\n",
    "    self.transition_layers = torch.nn.ModuleList(transition_layers)\n",
    "    self.local_layers = torch.nn.ModuleList(local_layers)\n",
    "    \n",
    "    # Activation functions\n",
    "    self.hidden_nonlinear = torch.nn.ReLU() if config['hidden_nonlinear'] == 'relu' else torch.nn.Tanh()\n",
    "    self.output_nonlinear = torch.nn.Sigmoid()\n",
    "\n",
    "    # Dropout\n",
    "    self.dropout = torch.nn.Dropout(p=config['dropout'])\n",
    "\n",
    "  def forward(self, x):\n",
    "    # We have |D| hidden layers plus one global prediction layer\n",
    "    local_outputs = []\n",
    "    output = x # Would be global path output until the last step\n",
    "    for i in range(len(self.global_layers)):\n",
    "      # Global path\n",
    "      if i == 0:\n",
    "        # Don't concatenate x into the first layer's input\n",
    "        output = self.hidden_nonlinear(\n",
    "            self.global_layer_norms[i](\n",
    "                self.global_layers[i](output)\n",
    "                )\n",
    "            )\n",
    "      else:\n",
    "        output = self.hidden_nonlinear(self.global_layer_norms[i](\n",
    "                self.global_layers[i](torch.cat([output, x], dim=1))\n",
    "              )\n",
    "            )\n",
    "\n",
    "      # Local path. Note the dropout between the transition ReLU layer and the local layer.\n",
    "      local_output = self.dropout(\n",
    "          self.hidden_nonlinear(\n",
    "              self.local_layer_norms[i](self.transition_layers[i](output))\n",
    "              )\n",
    "            )\n",
    "      local_output = self.output_nonlinear(self.local_layers[i](local_output))\n",
    "      local_outputs.append(local_output)\n",
    "\n",
    "      # Dropout main flow for next layer\n",
    "      # TODO: investigate introducing layernorm here\n",
    "      output = self.dropout(output)\n",
    "\n",
    "    global_outputs = self.output_nonlinear(\n",
    "      self.global_prediction_layer(torch.cat([output, x], dim=1))\n",
    "      )\n",
    "    local_outputs_concat = torch.cat(local_outputs, dim=1)\n",
    "    output = self.global_weight * global_outputs + (1 - self.global_weight) * local_outputs_concat\n",
    "    return output, local_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0IX_h9gRqhO"
   },
   "source": [
    "### Entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659,
     "referenced_widgets": [
      "e6a9d50369b743e6ab9095e7cb09ba85",
      "37039050ba0d48498777046a7b5098bc",
      "71467b9c601b42caa956b933644df950",
      "73db3abf8a5c4a14bb9e3c857b0cd73a",
      "4ff872907c104e5da154a1980ebee4a8",
      "bb83648a87c3446c92bb5052ef6847f1",
      "883563031f904e81b0ccf7ebc20d912a",
      "ff63f13c42194f70ba8c6e04d907b11b",
      "57f935dcbcb047d787a6fe1e99cd51f2",
      "a4d30ceda14f47d6a3c05f9be708a3b9",
      "ef1169b0d36e4f37af27ddf2a3f2c69c"
     ]
    },
    "executionInfo": {
     "elapsed": 30046,
     "status": "ok",
     "timestamp": 1635308300463,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "n8ntCwCH89Nm",
    "outputId": "1748f834-205c-4a8a-cfbe-fc09fa1bc4bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HMCNF(\n",
       "  (global_layers): ModuleList(\n",
       "    (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (1): Linear(in_features=1152, out_features=384, bias=True)\n",
       "  )\n",
       "  (global_layer_norms): ModuleList(\n",
       "    (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (global_prediction_layer): Linear(in_features=1152, out_features=115, bias=True)\n",
       "  (local_layer_norms): ModuleList(\n",
       "    (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transition_layers): ModuleList(\n",
       "    (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (1): Linear(in_features=384, out_features=384, bias=True)\n",
       "  )\n",
       "  (local_layers): ModuleList(\n",
       "    (0): Linear(in_features=384, out_features=11, bias=True)\n",
       "    (1): Linear(in_features=384, out_features=104, bias=True)\n",
       "  )\n",
       "  (hidden_nonlinear): ReLU()\n",
       "  (output_nonlinear): Sigmoid()\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = base_encoder\n",
    "encoder.load_state_dict(base_encoder_state)\n",
    "encoder.to(device)\n",
    "\n",
    "depth = len(hierarchy.levels)\n",
    "classifier = HMCNF(\n",
    "  768, # DistilBERT outputs 768 values.\n",
    "  hierarchy,\n",
    "  config\n",
    ")\n",
    "\n",
    "classifier.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFA8W-4CvOH9"
   },
   "source": [
    "# Training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 725,
     "status": "ok",
     "timestamp": 1635308351885,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "ZxqdEcgMvPoV"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_model(config, train_loader, val_loader, model, hierarchy, checkpoint_path, best_checkpoint_path):\n",
    "  encoder, classifier = model\n",
    "\n",
    "  # TODO: Somehow do this on GPU\n",
    "  parent_of = torch.LongTensor(hierarchy.parent_of)\n",
    "\n",
    "  # Store validation metrics after each epoch\n",
    "  val_metrics = np.empty((4, 0), dtype=float)\n",
    "\n",
    "  # Keep min validation (test set) loss so we can separately back up our best-yet model\n",
    "  val_loss_min = np.Inf\n",
    "\n",
    "  criterion = torch.nn.BCELoss()\n",
    "  optimizer = torch.optim.Adam(params=classifier.parameters(), lr=config['cls_lr'])\n",
    "\n",
    "  # Hierarchical loss gain\n",
    "  lambda_h = config['lambda_h']\n",
    "  for epoch in range(1, config['epochs'] + 1):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    # Put model into training mode. Note that this call DOES NOT train it yet.\n",
    "    classifier.train()\n",
    "    print('Epoch {}: Training'.format(epoch))\n",
    "    for batch_idx, data in enumerate(tqdm(train_loader, total=train_minibatch_count)):\n",
    "      ids = data['ids'].to(device, dtype = torch.long)\n",
    "      mask = data['mask'].to(device, dtype = torch.long)\n",
    "      targets = data['labels'].to(device, dtype = torch.float)\n",
    "\n",
    "      features = encoder(ids, mask)[0][:,0,:]\n",
    "      output, local_outputs = classifier(features)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # We have three loss functions: (g)lobal, (l)ocal, and (h)ierarchical.\n",
    "      loss_g = criterion(output, targets)\n",
    "      loss_l = sum([ criterion(\n",
    "            local_outputs[level],\n",
    "            targets[:, hierarchy.level_offsets[level] : hierarchy.level_offsets[level + 1]]\n",
    "            ) for level in range(len(hierarchy.levels))])\n",
    "      output_cpu = output.cpu().detach()\n",
    "      loss_h = torch.sum(lambda_h * torch.clamp(torch.FloatTensor(\n",
    "        output_cpu - \n",
    "        output_cpu.index_select(1, parent_of)\n",
    "      ), min=0) ** 2)\n",
    "      loss = loss_g + loss_l + loss_h\n",
    "\n",
    "      # PyTorch defaults to accumulating gradients, but we don't need that here\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      train_loss = train_loss + (loss.item() - train_loss) / (batch_idx + 1)\n",
    "\n",
    "    print('Epoch {}: Testing'.format(epoch))\n",
    "    \n",
    "    \n",
    "    # Switch to evaluation (prediction) mode. Again, this doesn't evaluate anything.\n",
    "    classifier.eval()\n",
    "\n",
    "    val_targets = np.empty((0, len(hierarchy.classes)), dtype=bool)\n",
    "    val_outputs = np.empty((0, len(hierarchy.classes)), dtype=float)\n",
    "    local_val_outputs = np.empty((0, len(hierarchy.classes)), dtype=float)\n",
    "\n",
    "    # We're only testing here, so don't run the backward direction (no_grad).\n",
    "    with torch.no_grad():\n",
    "      total_loss_g = 0\n",
    "      total_loss_l = 0\n",
    "      total_loss_h = 0\n",
    "      for batch_idx, data in tqdm(enumerate(val_loader), total=val_minibatch_count):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['labels'].to(device, dtype = torch.float)\n",
    "\n",
    "        features = encoder(ids, mask)[0][:,0,:]\n",
    "        output, local_outputs = classifier(features)\n",
    "\n",
    "        loss_g = criterion(output, targets)\n",
    "        loss_l = sum([ criterion(\n",
    "              local_outputs[level],\n",
    "              targets[:, hierarchy.level_offsets[level] : hierarchy.level_offsets[level + 1]]\n",
    "              ) for level in range(len(hierarchy.levels))])\n",
    "        output_cpu = output.cpu().detach()\n",
    "        loss_h = torch.sum(lambda_h * torch.clamp(torch.FloatTensor(\n",
    "          output_cpu - \n",
    "          output_cpu.index_select(1, parent_of)\n",
    "        ), min=0) ** 2)\n",
    "        loss = loss_g + loss_l + loss_h\n",
    "\n",
    "        total_loss_g += loss_g\n",
    "        total_loss_l += loss_l\n",
    "        total_loss_h += loss_h\n",
    "\n",
    "        val_loss = val_loss + (loss.item() - val_loss) / (batch_idx + 1)\n",
    "\n",
    "        val_targets = np.concatenate([val_targets, targets.cpu().detach().numpy()])\n",
    "        val_outputs = np.concatenate([val_outputs, output_cpu.numpy()])\n",
    "        # Concatenate local test outputs\n",
    "        local_val_outputs_concat = np.concatenate([*map(lambda t: t.cpu().detach().numpy(), local_outputs)], axis=1)\n",
    "        local_val_outputs = np.concatenate([local_val_outputs, local_val_outputs_concat])\n",
    "\n",
    "      # calculate average losses\n",
    "      #print('before cal avg train loss', train_loss)\n",
    "      print('Average minibatch global loss:', total_loss_g / val_minibatch_count)\n",
    "      print('Average minibatch local loss:', total_loss_l / val_minibatch_count)\n",
    "      print('Average minibatch hierarchical loss:', total_loss_h / val_minibatch_count)\n",
    "    \n",
    "      val_metrics = np.concatenate(\n",
    "          [\n",
    "            val_metrics, \n",
    "            np.expand_dims(\n",
    "              get_metrics(val_outputs, val_targets, hierarchy.levels), \n",
    "              axis=1\n",
    "            )\n",
    "          ],\n",
    "          axis=1\n",
    "      )\n",
    "      train_loss = train_loss/train_minibatch_count\n",
    "      val_loss = val_loss/val_minibatch_count\n",
    "      # Print training/validation statistics \n",
    "      print('Avgerage training loss: {:.6f}\\nAverage validation loss: {:.6f}'.format( \n",
    "            train_loss,\n",
    "            val_loss\n",
    "            ))\n",
    "\n",
    "      # create checkpoint variable and add important data\n",
    "      checkpoint = {\n",
    "            'state_dict': classifier.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "      }\n",
    "\n",
    "      best_yet = False\n",
    "      if val_loss <= val_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(val_loss_min,val_loss))\n",
    "        # save checkpoint as best model\n",
    "        best_yet = True\n",
    "        val_loss_min = val_loss\n",
    "      save_checkpoint(checkpoint, best_yet, checkpoint_path, best_checkpoint_path)\n",
    "    print('Epoch {}: Done\\n'.format(epoch))\n",
    "  return (encoder, classifier), val_metrics\n",
    "\n",
    "# Alternative: just load from disk\n",
    "def run_model(model, loader, hierarchy, minibatch_count = None):\n",
    "  encoder, classifier = model\n",
    "  # Switch to evaluation (prediction) mode. Again, this doesn't evaluate anything.\n",
    "  classifier.eval()\n",
    "\n",
    "  all_targets = np.empty((0, len(hierarchy.classes)), dtype=bool)\n",
    "  all_outputs = np.empty((0, len(hierarchy.classes)), dtype=float)\n",
    "  all_local_outputs = np.empty((0, len(hierarchy.classes)), dtype=float)\n",
    "\n",
    "  # We're only testing here, so don't run the backward direction (no_grad).\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(tqdm(loader, total=minibatch_count)):\n",
    "      ids = data['ids'].to(device, dtype = torch.long)\n",
    "      mask = data['mask'].to(device, dtype = torch.long)\n",
    "      targets = data['labels']\n",
    "\n",
    "      features = encoder(ids, mask)[0][:,0,:]\n",
    "      output, local_outputs = classifier(features)\n",
    "\n",
    "      all_targets = np.concatenate([all_targets, targets.numpy()])\n",
    "      all_outputs = np.concatenate([all_outputs, output.cpu().detach().numpy()])\n",
    "      # Concatenate local test outputs\n",
    "      local_outputs_concat = np.concatenate([*map(lambda t: t.cpu().detach().numpy(), local_outputs)], axis=1)\n",
    "      all_local_outputs = np.concatenate([all_local_outputs, local_outputs_concat])\n",
    "  return {\n",
    "      'targets': all_targets,\n",
    "      'outputs': all_outputs,\n",
    "      'local_outputs': all_local_outputs,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "7512c7bbac2b4a8a86e6759f3bbbc2b8",
      "a36dc39df13c4fb6b06210e9f7d4e5cb",
      "bfa45769c90c4e50829b7bba9c673531",
      "56dbdd9ba90042a1a7ba7075226a6a44",
      "3ed89d90b8d042d2b62f8f24711000df",
      "5359a706b7d04c81b9919471f7f4e275",
      "255c8c0083c040a188e98fea8afed4e0",
      "a356d74e3e1e46d08524c177fdab0c42",
      "d456c732a7934f4780a4e26adebe5d82",
      "64b1d8be1d114100b7ae1cb42bcb3425",
      "ef35c644d0824d529a22bed78aac1ab6"
     ]
    },
    "id": "DcqgkF06fnkf",
    "outputId": "5d27ba2c-1e57-4d06-d696-790354f3a582"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for HMCNF:\n\tsize mismatch for global_prediction_layer.weight: copying a param with shape torch.Size([114, 1152]) from checkpoint, the shape in current model is torch.Size([115, 1152]).\n\tsize mismatch for global_prediction_layer.bias: copying a param with shape torch.Size([114]) from checkpoint, the shape in current model is torch.Size([115]).\n\tsize mismatch for local_layers.1.weight: copying a param with shape torch.Size([103, 384]) from checkpoint, the shape in current model is torch.Size([104, 384]).\n\tsize mismatch for local_layers.1.bias: copying a param with shape torch.Size([103]) from checkpoint, the shape in current model is torch.Size([104]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6092/2805586702.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mload_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}/{}_{}.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOAD_ITERATION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mLOAD_BEST\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'current'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6092/1712620070.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(checkpoint_fpath, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_fpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1483\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for HMCNF:\n\tsize mismatch for global_prediction_layer.weight: copying a param with shape torch.Size([114, 1152]) from checkpoint, the shape in current model is torch.Size([115, 1152]).\n\tsize mismatch for global_prediction_layer.bias: copying a param with shape torch.Size([114]) from checkpoint, the shape in current model is torch.Size([115]).\n\tsize mismatch for local_layers.1.weight: copying a param with shape torch.Size([103, 384]) from checkpoint, the shape in current model is torch.Size([104, 384]).\n\tsize mismatch for local_layers.1.bias: copying a param with shape torch.Size([103]) from checkpoint, the shape in current model is torch.Size([104])."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trained_model = None\n",
    "if TRAIN_FROM_SCRATCH:\n",
    "    trained_model, val_metrics = train_model(\n",
    "        config,\n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        (encoder, classifier),\n",
    "        hierarchy,\n",
    "        CHECKPOINT_PATH,\n",
    "        BEST_CHECKPOINT_PATH,\n",
    "    )\n",
    "    x = np.arange(config['epochs'])\n",
    "    fig, ax = plt.subplots()  # Create a figure and an axes.\n",
    "    ax.plot(x, val_metrics[0], label='leaf accuracy')\n",
    "    ax.plot(x, val_metrics[1], label='leaf precision')\n",
    "    ax.plot(x, val_metrics[2], label='average global accuracy')\n",
    "    ax.plot(x, val_metrics[3], label='average global precision')\n",
    "    ax.set_xlabel('epoch')  # Add an x-label to the axes.\n",
    "    ax.set_ylabel('score')  # Add a y-label to the axes.\n",
    "    ax.set_title(\"Accuracy/precision over epochs\")  # Add a title to the axes.\n",
    "    ax.legend()  # Add a legend.\n",
    "    fig.show()\n",
    "else:\n",
    "    load_path = '{}/{}_{}.pt'.format(folder_name, LOAD_ITERATION, 'best' if LOAD_BEST else 'current')\n",
    "    trained_model = load_checkpoint(load_path, (encoder, classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = CustomDataset(data_test, tokenizer, MAX_LEN)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=VAL_TEST_MINIBATCH_SIZE)\n",
    "test_result = run_model(trained_model, test_loader, hierarchy, test_minibatch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-ek2QWfe7SJ"
   },
   "source": [
    "# Evaluation\n",
    "We'll mainly use the leaf prediction in real-world applications to ensure 100% hierarchy matches. However, we'll still test with the global encoding just to see what we are getting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(test_result['outputs'], test_result['targets'], level_sizes)\n",
    "\n",
    "# Rectified leaf AU(PRC) due to an sklearn bug.\n",
    "# We add one artificial example that belongs to all classes at once and a corresponding prediction\n",
    "# full of true positives. This way each class has at least one true positive, even if the test set\n",
    "# does not contain enough examples to cover all classes.\n",
    "rectified_outputs = np.concatenate([test_result['outputs'][:, level_offsets[-2]:], np.ones((1, level_sizes[-1]))], axis=0)\n",
    "rectified_targets = np.concatenate([test_result['targets'][:, level_offsets[-2]:], np.ones((1, level_sizes[-1]), dtype=bool)], axis=0)\n",
    "\n",
    "print('\\n')\n",
    "print('Rectified leaf-level AU(PRC) score:', metrics.average_precision_score(rectified_targets, rectified_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical predictions\n",
    "Let's have another visual match-up, but this time for the entire hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_codes = np.concatenate([\n",
    "    np.expand_dims(\n",
    "        np.argmax(test_result['outputs'][:, hierarchy.level_offsets[level] : hierarchy.level_offsets[level + 1]], axis=1),\n",
    "        axis=1\n",
    "    ) for level in range(len(hierarchy.levels))],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "target_codes = np.array([ np.nonzero(lst)[0] - hierarchy.level_offsets[:-1] for lst in test_result['targets'] ], dtype=int)\n",
    "print(path_codes.shape)\n",
    "print(target_codes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = [retrieve_classes(row, idx2cls) for row in tqdm(path_codes)]\n",
    "actual_classes = [retrieve_classes(row, idx2cls) for row in tqdm(target_codes)]\n",
    "import pandas as pd\n",
    "comp_df = pd.DataFrame({ 'Hierarchical prediction': predicted_classes, 'Actual hierarchy': actual_classes})\n",
    "comp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJ3qX2ZaAJkT"
   },
   "source": [
    "# Past results\n",
    "- `_1`: Equal to `_9` in Walmart_Marketing. However, we now use 10% validation 10% test instead of 20% test.\n",
    "\n",
    "```\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Amazon_Electronics_BERT_HMCN-F_title_hierarchical.ipynb",
   "provenance": [
    {
     "file_id": "1XH71XbNfkOyYkVwthbl_Mnt9YN0hwUv2",
     "timestamp": 1633613457791
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06622e52beb544b7a2b464d1de0902a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09d6a6951d0647dcb714bc95d13c7036": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1093cda242734ed68f90ef8113ed2382": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83ff5a1fcc5e40b19dba8346d43e57e0",
      "placeholder": "​",
      "style": "IPY_MODEL_205ba318b331401e8f8d66e532caa13f",
      "value": " 455k/455k [00:00&lt;00:00, 1.09MB/s]"
     }
    },
    "11294eb27f9a44599f1943202d83d956": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1582c4067b56485b9366b146d357f5e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b2acc83686d4baf9768c19e68e08d31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d4e5e118a55491a919f21304ca2d551",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4778017f533d4360bce2a5d6b8a5b6cc",
      "value": 28
     }
    },
    "205ba318b331401e8f8d66e532caa13f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "255c8c0083c040a188e98fea8afed4e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34e07de58f3a4b7ea2224d8a496e869e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37039050ba0d48498777046a7b5098bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3be0b068814c4625a8a26aaae6246fc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cf4df1b32a641118d1ec674040af9b6",
      "placeholder": "​",
      "style": "IPY_MODEL_bcfe3b9cc0a84a71a23fe066e9f91f50",
      "value": "Downloading: 100%"
     }
    },
    "3bf6825b7c0a4d75a5b6340575af92b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3be0b068814c4625a8a26aaae6246fc5",
       "IPY_MODEL_e83112deff534d02b02dab80d89f4c13",
       "IPY_MODEL_8b59a1c8120d400285775ab9c7bf5fd0"
      ],
      "layout": "IPY_MODEL_d67011f140984c90bcb2e5897e9cfec7"
     }
    },
    "3ed89d90b8d042d2b62f8f24711000df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef35c644d0824d529a22bed78aac1ab6",
      "placeholder": "​",
      "style": "IPY_MODEL_64b1d8be1d114100b7ae1cb42bcb3425",
      "value": " 120406/120406 [2:07:24&lt;00:00, 15.76it/s]"
     }
    },
    "41ca3ed1ee364d9fb3ef06cc54abb557": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4778017f533d4360bce2a5d6b8a5b6cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "480f7683750f4c8da678a997d1b6fce0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad1dc10ec89e4e4fb92c87e1d900ba98",
      "placeholder": "​",
      "style": "IPY_MODEL_6302b6fb6b22452999336c113b677dc4",
      "value": "Downloading: 100%"
     }
    },
    "49c2b1ce77694e378d0fdb66b1c56404": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ff872907c104e5da154a1980ebee4a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef1169b0d36e4f37af27ddf2a3f2c69c",
      "placeholder": "​",
      "style": "IPY_MODEL_a4d30ceda14f47d6a3c05f9be708a3b9",
      "value": " 256M/256M [00:09&lt;00:00, 28.2MB/s]"
     }
    },
    "5359a706b7d04c81b9919471f7f4e275": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56946bff74cc485797ed6b3498203651": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56dbdd9ba90042a1a7ba7075226a6a44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d456c732a7934f4780a4e26adebe5d82",
      "max": 120406,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a356d74e3e1e46d08524c177fdab0c42",
      "value": 120406
     }
    },
    "5717f1f6da554c83863f1fd513c76dc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b86bf4432244410b98d9f9d6b5fc676",
      "placeholder": "​",
      "style": "IPY_MODEL_41ca3ed1ee364d9fb3ef06cc54abb557",
      "value": "Downloading: 100%"
     }
    },
    "57f935dcbcb047d787a6fe1e99cd51f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b86bf4432244410b98d9f9d6b5fc676": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6302b6fb6b22452999336c113b677dc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64b1d8be1d114100b7ae1cb42bcb3425": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6749900841aa464ebcf3f3d56a24e4f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71467b9c601b42caa956b933644df950": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_883563031f904e81b0ccf7ebc20d912a",
      "placeholder": "​",
      "style": "IPY_MODEL_bb83648a87c3446c92bb5052ef6847f1",
      "value": "Downloading: 100%"
     }
    },
    "73db3abf8a5c4a14bb9e3c857b0cd73a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57f935dcbcb047d787a6fe1e99cd51f2",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff63f13c42194f70ba8c6e04d907b11b",
      "value": 267967963
     }
    },
    "7512c7bbac2b4a8a86e6759f3bbbc2b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bfa45769c90c4e50829b7bba9c673531",
       "IPY_MODEL_56dbdd9ba90042a1a7ba7075226a6a44",
       "IPY_MODEL_3ed89d90b8d042d2b62f8f24711000df"
      ],
      "layout": "IPY_MODEL_a36dc39df13c4fb6b06210e9f7d4e5cb"
     }
    },
    "76ecfa0377a9483db59cf4f3f8210f77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e4105fcbc1148dba4cfe534c7a8e075": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83ff5a1fcc5e40b19dba8346d43e57e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "883563031f904e81b0ccf7ebc20d912a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b59a1c8120d400285775ab9c7bf5fd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76ecfa0377a9483db59cf4f3f8210f77",
      "placeholder": "​",
      "style": "IPY_MODEL_49c2b1ce77694e378d0fdb66b1c56404",
      "value": " 226k/226k [00:00&lt;00:00, 731kB/s]"
     }
    },
    "8d4e5e118a55491a919f21304ca2d551": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "926d83822645446885e7c9a9f5278674": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97335ef817574cd58a87168b62763437": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11294eb27f9a44599f1943202d83d956",
      "placeholder": "​",
      "style": "IPY_MODEL_c33f0c0889024dabb79f1cf4c5855fff",
      "value": " 483/483 [00:00&lt;00:00, 11.1kB/s]"
     }
    },
    "9cf4df1b32a641118d1ec674040af9b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a356d74e3e1e46d08524c177fdab0c42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a36dc39df13c4fb6b06210e9f7d4e5cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4d30ceda14f47d6a3c05f9be708a3b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab35a23f71ec4614a8d08ff9e97af4fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ad1dc10ec89e4e4fb92c87e1d900ba98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3fb0b54a4c749789f8778c797de2a74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb83648a87c3446c92bb5052ef6847f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bcfe3b9cc0a84a71a23fe066e9f91f50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd923a63531e47f7b256ed4408780ef9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfa45769c90c4e50829b7bba9c673531": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_255c8c0083c040a188e98fea8afed4e0",
      "placeholder": "​",
      "style": "IPY_MODEL_5359a706b7d04c81b9919471f7f4e275",
      "value": "100%"
     }
    },
    "c33f0c0889024dabb79f1cf4c5855fff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c997c00148b642388a7dfc5d4cea405a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e4105fcbc1148dba4cfe534c7a8e075",
      "placeholder": "​",
      "style": "IPY_MODEL_926d83822645446885e7c9a9f5278674",
      "value": " 28.0/28.0 [00:00&lt;00:00, 402B/s]"
     }
    },
    "cd184a49854a492db0f7338ddf1f25e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3fb0b54a4c749789f8778c797de2a74",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09d6a6951d0647dcb714bc95d13c7036",
      "value": 466062
     }
    },
    "d456c732a7934f4780a4e26adebe5d82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d67011f140984c90bcb2e5897e9cfec7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7b9dd68692d45e79ebb462eb1e52ed2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e4129340688f43b29db0a0378544a7f9",
       "IPY_MODEL_ebe54699564d4587ab8d74857d4e8872",
       "IPY_MODEL_97335ef817574cd58a87168b62763437"
      ],
      "layout": "IPY_MODEL_56946bff74cc485797ed6b3498203651"
     }
    },
    "df715fedf06d47b89a781ab143c31366": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_480f7683750f4c8da678a997d1b6fce0",
       "IPY_MODEL_cd184a49854a492db0f7338ddf1f25e5",
       "IPY_MODEL_1093cda242734ed68f90ef8113ed2382"
      ],
      "layout": "IPY_MODEL_34e07de58f3a4b7ea2224d8a496e869e"
     }
    },
    "e4129340688f43b29db0a0378544a7f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd923a63531e47f7b256ed4408780ef9",
      "placeholder": "​",
      "style": "IPY_MODEL_e704839651a943a395100bb5da14759c",
      "value": "Downloading: 100%"
     }
    },
    "e6a9d50369b743e6ab9095e7cb09ba85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_71467b9c601b42caa956b933644df950",
       "IPY_MODEL_73db3abf8a5c4a14bb9e3c857b0cd73a",
       "IPY_MODEL_4ff872907c104e5da154a1980ebee4a8"
      ],
      "layout": "IPY_MODEL_37039050ba0d48498777046a7b5098bc"
     }
    },
    "e704839651a943a395100bb5da14759c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e83112deff534d02b02dab80d89f4c13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4e89f31eee747959dfb78c50fcc3f4b",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ab35a23f71ec4614a8d08ff9e97af4fd",
      "value": 231508
     }
    },
    "ebe54699564d4587ab8d74857d4e8872": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6749900841aa464ebcf3f3d56a24e4f0",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1582c4067b56485b9366b146d357f5e4",
      "value": 483
     }
    },
    "ecf624390bc24aed86e39d326dd2ac3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5717f1f6da554c83863f1fd513c76dc0",
       "IPY_MODEL_1b2acc83686d4baf9768c19e68e08d31",
       "IPY_MODEL_c997c00148b642388a7dfc5d4cea405a"
      ],
      "layout": "IPY_MODEL_06622e52beb544b7a2b464d1de0902a1"
     }
    },
    "ef1169b0d36e4f37af27ddf2a3f2c69c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef35c644d0824d529a22bed78aac1ab6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4e89f31eee747959dfb78c50fcc3f4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff63f13c42194f70ba8c6e04d907b11b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
