{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37802,
     "status": "ok",
     "timestamp": 1635307768509,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "kzuN96GF0XuA",
    "outputId": "3888bf24-8177-496a-a316-b26e35e1bf70"
   },
   "outputs": [],
   "source": [
    "### Dataset configuration\n",
    "# The parquet folder. It should be located inside datasets/.\n",
    "DATASET_NAME   = 'Walmart_30k.parquet'\n",
    "# The input text column\n",
    "TEXT_COL_NAME  = 'title'\n",
    "# Which column to use as labelled classes. It should be a column of lists of strings.\n",
    "CLASS_COL_NAME = 'category'\n",
    "# How many hierarchical levels to work on. Note that the dataset must also have at least this many levels for every example.\n",
    "DEPTH = 2\n",
    "\n",
    "### Checkpoint configuration\n",
    "# Whether to train from scratch or to load a checkpoint\n",
    "TRAIN_FROM_SCRATCH=True\n",
    "# If training from scratch, train this many times before averaging test set results. Train/val/test split is kept static.\n",
    "TRAIN_REPEATS = 5\n",
    "# Checkpoint iteration to load if not training from scratch\n",
    "LOAD_ITERATION=1\n",
    "# Last or best results from that iteration?\n",
    "LOAD_BEST=True\n",
    "\n",
    "### System configuration\n",
    "# Will try to use your NVIDIA GPU if one is available. Set to False to force CPU computation\n",
    "PREFER_GPU         = True\n",
    "# If you don't have the huggingface transformers library installed, flip this to True.\n",
    "# You only need to do this once. Once DistilBERT has been downloaded, it will be cached in your system's default user cache folder.\n",
    "# Once it is cached, please set this to False to avoid redownloads.\n",
    "INSTALL_DISTILBERT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9r_iHMmx75DM"
   },
   "source": [
    "# Import common libraries\n",
    "And also set up a few things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "shaFdRkD74o1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set up GPU if available\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() and PREFER_GPU else 'cpu'\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import logging\n",
    "\n",
    "print('Using {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTb90c5tRJsf"
   },
   "source": [
    "# Import data\n",
    "Here we'll finally be using the randomly-sampled 750k-row subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13707,
     "status": "ok",
     "timestamp": 1635307806856,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "O8e3fhFSRPPw",
    "outputId": "f62876fc-11c1-4a35-8534-aa4e27db8d07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                                                        La Costena Chipotle Peppers, 7 OZ (Pack of 12)\n",
      "description    La Costena Chipotle Peppers, 7 OZ (Pack of 12) Easy open. Ready to serve! Product of Mexico.\n",
      "List Price                                                                                            31.93\n",
      "Sale Price                                                                                            31.93\n",
      "Brand                                                                                       La Costeï¿½ï¿½a\n",
      "category                            [Food, Meal Solutions, Grains & Pasta, Canned Goods, Canned Vegetables]\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_parquet('../../datasets/{}'.format(DATASET_NAME))\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    print (data.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96eLOv0hMvCv"
   },
   "source": [
    "# Categorical-encode the categories\n",
    "For this notebook, we'll have a slightly weird encoding scheme: categories are ordered by their levels too. That is, in the numerical order will be all categories on the first level, THEN those on the second, so on and so forth.\n",
    "\n",
    "The first step to achieving this would be to separate each level into their own column. Then, for categorical encoding to work, the columns themselves must be in pandas' `category` datatype, instead of the default `object` type for non-numerical columns.\n",
    "\n",
    "From this, we can easily generate one-hot encodings for each level, which when concatenated gives the n-hot encoding for all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 850,
     "status": "ok",
     "timestamp": 1635307918852,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "j8YYWA6NNUr4",
    "outputId": "44e296f1-93a6-448a-ea78-b124b62b3d2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Arts Crafts & Sewing': 0, 'Auto & Tires': 1, 'Baby': 2, 'Beauty': 3, 'Books': 4, 'Cell Phones': 5, 'Character Shop': 6, 'Clothing': 7, 'Collectibles': 8, 'Electronics': 9, 'Feature': 10, 'Food': 11, 'Health': 12, 'Home': 13, 'Home Improvement': 14, 'Household Essentials': 15, 'Industrial & Scientific': 16, 'Jewelry': 17, 'Music': 18, 'Musical Instruments': 19, 'Office Supplies': 20, 'Party & Occasions': 21, 'Patio & Garden': 22, 'Personal Care': 23, 'Pets': 24, 'Premium Beauty': 25, 'Seasonal': 26, 'Sports & Outdoors': 27, 'Toys': 28, 'Video Games': 29, 'Walmart for Business': 30}, {'2-in-1 Hair and Body Care': 0, '@ Manual Shelves - Beauty': 1, '@ Manual Shelves - Food': 2, 'ATV & Off-Road': 3, 'Acid Reflux': 4, 'Action Figures': 5, 'Advance Auto Parts Shop': 6, 'Air Fresheners': 7, 'All Industrial': 8, 'Allergy and Sinus': 9, 'Appliances': 10, 'Aromatherapy': 11, 'Art Supplies': 12, 'Arts & Crafts for Kids': 13, 'As Seen On TV': 14, 'Audio': 15, 'Auto Body': 16, 'Auto Detailing & Car Care': 17, 'Auto Detailing Paint and Paint Tools': 18, 'Auto Electronics': 19, 'Automotive Interior': 20, 'Automotive Replacement Parts': 21, 'Automotive Tools & Equipment': 22, 'Baby & Toddler Toys': 23, 'Baby Activities & Gear': 24, 'Baby Shower Gifts': 25, 'Back to College Beauty': 26, 'Back to School': 27, 'Back to School Health Essentials': 28, 'Bags & Accessories': 29, 'Baking': 30, 'Basketball Party Supplies': 31, 'Bath': 32, 'Bath & Body': 33, 'Bathroom': 34, 'Bathroom Renovation': 35, 'Batteries': 36, 'Beading & Jewelry Making': 37, 'Beauty Next Day': 38, 'Beauty Stock Up': 39, 'Beauty Wellness': 40, 'Beauty by Top Brands': 41, 'Beauty by Topic': 42, 'Bedding': 43, 'Bedroom Safety & Aids': 44, 'Beverages': 45, 'Big & Tall': 46, 'Bikes': 47, 'Body Jewelry': 48, 'Breakfast & Cereal': 49, 'Breakroom Supplies': 50, 'Business & Money Books': 51, 'Cake, Baking & Pastry Supplies': 52, 'Cameras & Camcorders': 53, 'Car Safety & Car Security': 54, 'Car Seats': 55, 'Caregiver': 56, 'Cats': 57, 'Cellphone Accessories': 58, 'Character Shop': 59, 'Childrens & Kids Books': 60, 'Childrens Health': 61, 'Childrens Health Shop': 62, 'Chocolate, Candy & Gum': 63, 'Christmas Trees & Christmas Decor': 64, 'Clean Living Bath & Body': 65, 'Clean Living Shop': 66, 'Cleaning Supplies': 67, 'Clearance on Health Beauty Wellness & Personal Care': 68, 'Coffee': 69, 'Cold Cough and Flu': 70, 'Computers': 71, 'Condiments, Sauces & Spices': 72, 'Cookbooks, Food & Wine': 73, 'DC Comics Characters': 74, 'Decor': 75, 'Deodorants & Antiperspirants': 76, 'Dermatologist Recommended': 77, 'Desk & Workspace Organizers': 78, 'Diabetes Care': 79, 'Diabetes Care Brands': 80, 'Diabetes Management': 81, 'Diabetes Shop': 82, 'Diapering': 83, 'Digestive Health': 84, 'Disney Characters': 85, 'Disney Toys': 86, 'Dog Bark Control': 87, 'Dogs': 88, 'Dolls & Dollhouses': 89, 'Drain & Septic Care': 90, 'Ear Care': 91, 'Electrical': 92, 'Electronics for Kids': 93, 'Emergency Prep': 94, 'Equate': 95, 'Exercise & Fitness': 96, 'Exterior Car Accessories': 97, 'Eye Care': 98, 'Family Planning': 99, 'Farm Animals': 100, 'Fashion Brands': 101, 'Fasteners': 102, 'Featured Shops': 103, 'Feeding': 104, 'Feminine Care': 105, 'Fiber Supplements': 106, 'First Aid': 107, 'Food Service Equipment & Supplies': 108, 'Foot Care': 109, 'Fragrance Best Sellers': 110, 'Fragrances': 111, 'Fresh Cut Flowers': 112, 'Fresh Food': 113, 'Frozen Foods': 114, 'Furniture': 115, 'GPS & Navigation': 116, 'Games & Puzzles': 117, 'Garden Center': 118, 'Gas Relief': 119, 'Gift Baskets': 120, 'Gift Wrap Supplies': 121, 'Gluten-Free Foods': 122, 'Grills & Outdoor Cooking': 123, 'HART Tools': 124, 'Hair Care': 125, 'Halloween': 126, 'Halloween Makeup and Hair': 127, 'Hardware': 128, 'Headaches': 129, 'Health & Safety': 130, 'Heart Health': 131, 'Heating, Cooling, & Air Quality': 132, 'Here for Every Beauty': 133, 'History Books': 134, 'Hobby & Collectibles': 135, 'Holiday Decor': 136, 'Home Health Care': 137, 'Home Safety': 138, 'Horses': 139, 'Hot Tubs & Saunas': 140, 'House, Home & Gardening Books': 141, 'Household Essentials by Brand': 142, 'Incontinence': 143, 'Instrument Accessories': 144, 'Iridescent Party Supplies': 145, 'Janitorial & Sanitation Supplies': 146, 'Jojo Siwa Party Supplies': 147, 'Juniors': 148, 'Keto Diet': 149, 'Kids Bikes & Riding Toys': 150, 'Kids Clothing': 151, 'Kids Jewelry & Watches': 152, 'Kids Rooms': 153, 'Kitchen & Dining': 154, 'Kosher Foods': 155, 'Language Arts & Disciplines Books': 156, 'Last Minute Gifts': 157, 'Laundry': 158, 'Laxatives': 159, 'Learning Toys': 160, 'Light Bulbs': 161, 'Lip Care': 162, 'Literature & Fiction Books': 163, 'Makeup': 164, 'Mardi Gras Party Supplies': 165, 'Massage': 166, 'Maternity Clothing': 167, 'Meal Solutions, Grains & Pasta': 168, 'Medical & Dental': 169, 'Medicine Cabinet': 170, 'Medicine Cabinet Must Haves': 171, 'Men': 172, 'Mens Clothing': 173, 'Mens Essentials': 174, 'Mens Personal Care': 175, 'Mothers Day': 176, 'Motion Sickness & Nausea': 177, 'Motorcycle': 178, 'New Arrivals': 179, 'New Year New You': 180, 'Nexxus': 181, 'Nickelodeon Characters': 182, 'Nursery & Decor': 183, 'Oils and Fluids': 184, 'Oral Care': 185, 'Organic Foods': 186, 'Outdoor Lighting': 187, 'Outdoor Play': 188, 'Outdoor Power Equipment': 189, 'Outdoor Sports': 190, 'Pain Relievers': 191, 'Paint': 192, 'Paper': 193, 'Paper & Plastic': 194, 'Party Supplies': 195, 'Patio & Outdoor Decor': 196, 'Patio Furniture': 197, 'Personalized Gifts': 198, 'Pest Control': 199, 'Pet Stain & Odor Remover': 200, 'Plant Based Nutrition': 201, 'Portable Audio': 202, 'Premium Bath & Body': 203, 'Premium Beauty': 204, 'Premium Beauty Tech & Skin Devices': 205, 'Premium Brands': 206, 'Premium Facial Skincare': 207, 'Premium Fragrance': 208, 'Premium Hair Care': 209, 'Premium Hair Care & Hair Tools': 210, 'Premium Hair Tools & Accessories': 211, 'Premium Makeup': 212, 'Premium Mens Grooming': 213, 'Pretend Play': 214, 'Probiotics': 215, 'Protein & Fitness': 216, 'Psychology & Social Science Books': 217, 'Quit Smoking': 218, 'RV Parts & Accessories': 219, 'Recreation': 220, 'Remote Control & Play Vehicles': 221, 'Reptiles': 222, 'Restock & Save On Hair Care': 223, 'Restock Beauty Essentials': 224, 'Restock Health Essentials': 225, 'Restock Wellness Essentials': 226, 'Restock on Baby Essentials': 227, 'Retro and Arcade Gaming Consoles, Accessories & Games': 228, 'Safety Equipment and Gear': 229, 'Scrapbooking': 230, 'Seasonal Clothing Shops': 231, 'Seasonal Grocery': 232, 'Self-Care & Pampering': 233, 'Sewing': 234, 'Sexual Wellness': 235, 'Sexual Wellness Top Brands': 236, 'Shaving': 237, 'Shoe Care & Repair': 238, 'Shoes': 239, 'Shop Musical Instruments By Brand': 240, 'Shop Toys by Age': 241, 'Shop Toys by Brand': 242, 'Shop Toys by Price': 243, 'Shop all Collectibles': 244, 'Shop by Skin Concern and Type': 245, 'Skin Care': 246, 'Sleep & Snoring Aids': 247, 'Sleepwear Shop': 248, 'Smart Home': 249, 'Snacks, Cookies & Chips': 250, 'Soups': 251, 'Sports': 252, 'Sports Fan Shop': 253, 'Sports Medicine & Injury Recovery Solution': 254, 'Sports Party Supplies': 255, 'Storage & Organization': 256, 'Strollers': 257, 'Stuffed Animals & Plush Toys': 258, 'Sun Care': 259, 'Super Bowl LII Starts Here': 260, 'Superfoods & Cleanses': 261, 'Surveillance Equipment': 262, 'Swim Shop': 263, 'TV & Video': 264, 'Teens Rooms': 265, 'The 80s Shop': 266, 'Tires': 267, 'Toddlers Room': 268, 'Tools': 269, 'Toys Character Shop': 270, 'Travel Size Beauty': 271, 'Travel Size Toiletries & Kits': 272, 'Trending Sellers': 273, 'Unicorn Shop': 274, 'Uniquely J': 275, 'Valentines Day Party Supplies': 276, 'Video Game Titles': 277, 'Vinyl Records': 278, 'Vitamins & Supplements': 279, 'WOW Items': 280, 'Walmart Exclusive Toys': 281, 'Watch Accessories': 282, 'Watches': 283, 'Water Purification': 284, 'Wedding Shop': 285, 'Weight Management': 286, 'Wellness': 287, 'Wilton Baking Supplies': 288, 'Womens Clothing': 289, 'Womens Jewelry & Watches': 290, 'Womens Plus': 291, 'iPad & Tablets': 292}]\n",
      "\n",
      "\n",
      "[['Arts Crafts & Sewing', 'Auto & Tires', 'Baby', 'Beauty', 'Books', 'Cell Phones', 'Character Shop', 'Clothing', 'Collectibles', 'Electronics', 'Feature', 'Food', 'Health', 'Home', 'Home Improvement', 'Household Essentials', 'Industrial & Scientific', 'Jewelry', 'Music', 'Musical Instruments', 'Office Supplies', 'Party & Occasions', 'Patio & Garden', 'Personal Care', 'Pets', 'Premium Beauty', 'Seasonal', 'Sports & Outdoors', 'Toys', 'Video Games', 'Walmart for Business'], ['2-in-1 Hair and Body Care', '@ Manual Shelves - Beauty', '@ Manual Shelves - Food', 'ATV & Off-Road', 'Acid Reflux', 'Action Figures', 'Advance Auto Parts Shop', 'Air Fresheners', 'All Industrial', 'Allergy and Sinus', 'Appliances', 'Aromatherapy', 'Art Supplies', 'Arts & Crafts for Kids', 'As Seen On TV', 'Audio', 'Auto Body', 'Auto Detailing & Car Care', 'Auto Detailing Paint and Paint Tools', 'Auto Electronics', 'Automotive Interior', 'Automotive Replacement Parts', 'Automotive Tools & Equipment', 'Baby & Toddler Toys', 'Baby Activities & Gear', 'Baby Shower Gifts', 'Back to College Beauty', 'Back to School', 'Back to School Health Essentials', 'Bags & Accessories', 'Baking', 'Basketball Party Supplies', 'Bath', 'Bath & Body', 'Bathroom', 'Bathroom Renovation', 'Batteries', 'Beading & Jewelry Making', 'Beauty Next Day', 'Beauty Stock Up', 'Beauty Wellness', 'Beauty by Top Brands', 'Beauty by Topic', 'Bedding', 'Bedroom Safety & Aids', 'Beverages', 'Big & Tall', 'Bikes', 'Body Jewelry', 'Breakfast & Cereal', 'Breakroom Supplies', 'Business & Money Books', 'Cake, Baking & Pastry Supplies', 'Cameras & Camcorders', 'Car Safety & Car Security', 'Car Seats', 'Caregiver', 'Cats', 'Cellphone Accessories', 'Character Shop', 'Childrens & Kids Books', 'Childrens Health', 'Childrens Health Shop', 'Chocolate, Candy & Gum', 'Christmas Trees & Christmas Decor', 'Clean Living Bath & Body', 'Clean Living Shop', 'Cleaning Supplies', 'Clearance on Health Beauty Wellness & Personal Care', 'Coffee', 'Cold Cough and Flu', 'Computers', 'Condiments, Sauces & Spices', 'Cookbooks, Food & Wine', 'DC Comics Characters', 'Decor', 'Deodorants & Antiperspirants', 'Dermatologist Recommended', 'Desk & Workspace Organizers', 'Diabetes Care', 'Diabetes Care Brands', 'Diabetes Management', 'Diabetes Shop', 'Diapering', 'Digestive Health', 'Disney Characters', 'Disney Toys', 'Dog Bark Control', 'Dogs', 'Dolls & Dollhouses', 'Drain & Septic Care', 'Ear Care', 'Electrical', 'Electronics for Kids', 'Emergency Prep', 'Equate', 'Exercise & Fitness', 'Exterior Car Accessories', 'Eye Care', 'Family Planning', 'Farm Animals', 'Fashion Brands', 'Fasteners', 'Featured Shops', 'Feeding', 'Feminine Care', 'Fiber Supplements', 'First Aid', 'Food Service Equipment & Supplies', 'Foot Care', 'Fragrance Best Sellers', 'Fragrances', 'Fresh Cut Flowers', 'Fresh Food', 'Frozen Foods', 'Furniture', 'GPS & Navigation', 'Games & Puzzles', 'Garden Center', 'Gas Relief', 'Gift Baskets', 'Gift Wrap Supplies', 'Gluten-Free Foods', 'Grills & Outdoor Cooking', 'HART Tools', 'Hair Care', 'Halloween', 'Halloween Makeup and Hair', 'Hardware', 'Headaches', 'Health & Safety', 'Heart Health', 'Heating, Cooling, & Air Quality', 'Here for Every Beauty', 'History Books', 'Hobby & Collectibles', 'Holiday Decor', 'Home Health Care', 'Home Safety', 'Horses', 'Hot Tubs & Saunas', 'House, Home & Gardening Books', 'Household Essentials by Brand', 'Incontinence', 'Instrument Accessories', 'Iridescent Party Supplies', 'Janitorial & Sanitation Supplies', 'Jojo Siwa Party Supplies', 'Juniors', 'Keto Diet', 'Kids Bikes & Riding Toys', 'Kids Clothing', 'Kids Jewelry & Watches', 'Kids Rooms', 'Kitchen & Dining', 'Kosher Foods', 'Language Arts & Disciplines Books', 'Last Minute Gifts', 'Laundry', 'Laxatives', 'Learning Toys', 'Light Bulbs', 'Lip Care', 'Literature & Fiction Books', 'Makeup', 'Mardi Gras Party Supplies', 'Massage', 'Maternity Clothing', 'Meal Solutions, Grains & Pasta', 'Medical & Dental', 'Medicine Cabinet', 'Medicine Cabinet Must Haves', 'Men', 'Mens Clothing', 'Mens Essentials', 'Mens Personal Care', 'Mothers Day', 'Motion Sickness & Nausea', 'Motorcycle', 'New Arrivals', 'New Year New You', 'Nexxus', 'Nickelodeon Characters', 'Nursery & Decor', 'Oils and Fluids', 'Oral Care', 'Organic Foods', 'Outdoor Lighting', 'Outdoor Play', 'Outdoor Power Equipment', 'Outdoor Sports', 'Pain Relievers', 'Paint', 'Paper', 'Paper & Plastic', 'Party Supplies', 'Patio & Outdoor Decor', 'Patio Furniture', 'Personalized Gifts', 'Pest Control', 'Pet Stain & Odor Remover', 'Plant Based Nutrition', 'Portable Audio', 'Premium Bath & Body', 'Premium Beauty', 'Premium Beauty Tech & Skin Devices', 'Premium Brands', 'Premium Facial Skincare', 'Premium Fragrance', 'Premium Hair Care', 'Premium Hair Care & Hair Tools', 'Premium Hair Tools & Accessories', 'Premium Makeup', 'Premium Mens Grooming', 'Pretend Play', 'Probiotics', 'Protein & Fitness', 'Psychology & Social Science Books', 'Quit Smoking', 'RV Parts & Accessories', 'Recreation', 'Remote Control & Play Vehicles', 'Reptiles', 'Restock & Save On Hair Care', 'Restock Beauty Essentials', 'Restock Health Essentials', 'Restock Wellness Essentials', 'Restock on Baby Essentials', 'Retro and Arcade Gaming Consoles, Accessories & Games', 'Safety Equipment and Gear', 'Scrapbooking', 'Seasonal Clothing Shops', 'Seasonal Grocery', 'Self-Care & Pampering', 'Sewing', 'Sexual Wellness', 'Sexual Wellness Top Brands', 'Shaving', 'Shoe Care & Repair', 'Shoes', 'Shop Musical Instruments By Brand', 'Shop Toys by Age', 'Shop Toys by Brand', 'Shop Toys by Price', 'Shop all Collectibles', 'Shop by Skin Concern and Type', 'Skin Care', 'Sleep & Snoring Aids', 'Sleepwear Shop', 'Smart Home', 'Snacks, Cookies & Chips', 'Soups', 'Sports', 'Sports Fan Shop', 'Sports Medicine & Injury Recovery Solution', 'Sports Party Supplies', 'Storage & Organization', 'Strollers', 'Stuffed Animals & Plush Toys', 'Sun Care', 'Super Bowl LII Starts Here', 'Superfoods & Cleanses', 'Surveillance Equipment', 'Swim Shop', 'TV & Video', 'Teens Rooms', 'The 80s Shop', 'Tires', 'Toddlers Room', 'Tools', 'Toys Character Shop', 'Travel Size Beauty', 'Travel Size Toiletries & Kits', 'Trending Sellers', 'Unicorn Shop', 'Uniquely J', 'Valentines Day Party Supplies', 'Video Game Titles', 'Vinyl Records', 'Vitamins & Supplements', 'WOW Items', 'Walmart Exclusive Toys', 'Watch Accessories', 'Watches', 'Water Purification', 'Wedding Shop', 'Weight Management', 'Wellness', 'Wilton Baking Supplies', 'Womens Clothing', 'Womens Jewelry & Watches', 'Womens Plus', 'iPad & Tablets']]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_classes(data, original_name, depth, verbose=False):\n",
    "    \"\"\"\n",
    "    Build a list of unique class names for each level and create bidirectional mappings.\n",
    "    \"\"\"\n",
    "    cls2idx = []\n",
    "    idx2cls = []\n",
    "    for i in range(depth): \n",
    "        category_li = data[original_name].apply(\n",
    "            lambda lst: lst[i]\n",
    "        ).astype('category')\n",
    "        if verbose:\n",
    "            print(category_li.cat.classes)\n",
    "        cls2idx.append(dict([\n",
    "            (category, index) \n",
    "            for (index, category) \n",
    "            in enumerate(category_li.cat.categories)\n",
    "        ]))\n",
    "        idx2cls.append(list(category_li.cat.categories))\n",
    "    return cls2idx, idx2cls\n",
    "\n",
    "cls2idx, idx2cls = preprocess_classes(data, CLASS_COL_NAME, DEPTH)    \n",
    "print(cls2idx)\n",
    "print('\\n')\n",
    "print(idx2cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1635307948128,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "AasvSxmA0HIu",
    "outputId": "003f50f4-43fa-4b55-d513-c8913ffebd24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>List Price</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Brand</th>\n",
       "      <th>category</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La Costena Chipotle Peppers, 7 OZ (Pack of 12)</td>\n",
       "      <td>La Costena Chipotle Peppers, 7 OZ (Pack of 12)...</td>\n",
       "      <td>31.93</td>\n",
       "      <td>31.93</td>\n",
       "      <td>La Costeï¿½ï¿½a</td>\n",
       "      <td>[Food, Meal Solutions, Grains &amp; Pasta, Canned ...</td>\n",
       "      <td>[11, 168]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Equate Triamcinolone Acetonide Nasal Allergy S...</td>\n",
       "      <td>Compare to Nasacort Allergy 24HR active ingred...</td>\n",
       "      <td>10.48</td>\n",
       "      <td>10.48</td>\n",
       "      <td>Equate</td>\n",
       "      <td>[Health, Equate, Equate Allergy, Equate Sinus ...</td>\n",
       "      <td>[12, 95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AduroSmart ERIA Soft White Smart A19 Light Bul...</td>\n",
       "      <td>The Soft White ERIA A19 bulb (2700K) can be co...</td>\n",
       "      <td>10.99</td>\n",
       "      <td>10.99</td>\n",
       "      <td>AduroSmart ERIA</td>\n",
       "      <td>[Electronics, Smart Home, Smart Energy and Lig...</td>\n",
       "      <td>[9, 249]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24\" Classic Adjustable Balloon Fender Set Chro...</td>\n",
       "      <td>Lowrider Fender Set 24\" Classic Adjustable Chr...</td>\n",
       "      <td>38.59</td>\n",
       "      <td>38.59</td>\n",
       "      <td>lowrider</td>\n",
       "      <td>[Sports &amp; Outdoors, Bikes, Bike Accessories, B...</td>\n",
       "      <td>[27, 47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elephant Shape Silicone Drinkware Portable Sil...</td>\n",
       "      <td>This is a kind of fine quality silicone cup l...</td>\n",
       "      <td>5.81</td>\n",
       "      <td>5.81</td>\n",
       "      <td>Anself</td>\n",
       "      <td>[Baby, Feeding, Sippy Cups: Alternatives to Pl...</td>\n",
       "      <td>[2, 104]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(6 Boxes) Twinings of London Nightly Calm Gree...</td>\n",
       "      <td>Enojy one of your favorite tea flavors with th...</td>\n",
       "      <td>17.99</td>\n",
       "      <td>17.99</td>\n",
       "      <td>Twinings</td>\n",
       "      <td>[Food, Beverages, Tea, All Tea]</td>\n",
       "      <td>[11, 45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Toytainer Shoe Box Play-N-Store, Boy</td>\n",
       "      <td>Toytainer Shoe Box Play-N-Store, Boy: Teach y...</td>\n",
       "      <td>11.52</td>\n",
       "      <td>11.52</td>\n",
       "      <td>Toytainer</td>\n",
       "      <td>[Home, Kids Rooms, Kids Storage]</td>\n",
       "      <td>[13, 153]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dometic D1112002 D Line 3 N 1 Bowl Cleaner and...</td>\n",
       "      <td>Dometic D Line 3 N 1 Cleaner and Tank Treatmen...</td>\n",
       "      <td>34.41</td>\n",
       "      <td>34.41</td>\n",
       "      <td>Dometic</td>\n",
       "      <td>[Household Essentials, Bathroom, Bathroom Clea...</td>\n",
       "      <td>[15, 34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tiny White Mighty Mints (16 oz, ZIN: 525424) -...</td>\n",
       "      <td>Tiny White Mighty Mints (16 oz, ZIN: 525424): ...</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.54</td>\n",
       "      <td>Larissa Veronica</td>\n",
       "      <td>[Food, Chocolate, Candy &amp; Gum, Mints, Shop All...</td>\n",
       "      <td>[11, 63]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetic Socks Small White - Item Number 11600...</td>\n",
       "      <td>Diabetic Socks Small White - Item Number 11600...</td>\n",
       "      <td>13.76</td>\n",
       "      <td>13.76</td>\n",
       "      <td>DJO</td>\n",
       "      <td>[Health, Diabetes Care, Diabetic Socks]</td>\n",
       "      <td>[12, 79]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0     La Costena Chipotle Peppers, 7 OZ (Pack of 12)   \n",
       "1  Equate Triamcinolone Acetonide Nasal Allergy S...   \n",
       "2  AduroSmart ERIA Soft White Smart A19 Light Bul...   \n",
       "3  24\" Classic Adjustable Balloon Fender Set Chro...   \n",
       "4  Elephant Shape Silicone Drinkware Portable Sil...   \n",
       "5  (6 Boxes) Twinings of London Nightly Calm Gree...   \n",
       "6               Toytainer Shoe Box Play-N-Store, Boy   \n",
       "7  Dometic D1112002 D Line 3 N 1 Bowl Cleaner and...   \n",
       "8  Tiny White Mighty Mints (16 oz, ZIN: 525424) -...   \n",
       "9  Diabetic Socks Small White - Item Number 11600...   \n",
       "\n",
       "                                         description  List Price  Sale Price  \\\n",
       "0  La Costena Chipotle Peppers, 7 OZ (Pack of 12)...       31.93       31.93   \n",
       "1  Compare to Nasacort Allergy 24HR active ingred...       10.48       10.48   \n",
       "2  The Soft White ERIA A19 bulb (2700K) can be co...       10.99       10.99   \n",
       "3  Lowrider Fender Set 24\" Classic Adjustable Chr...       38.59       38.59   \n",
       "4   This is a kind of fine quality silicone cup l...        5.81        5.81   \n",
       "5  Enojy one of your favorite tea flavors with th...       17.99       17.99   \n",
       "6   Toytainer Shoe Box Play-N-Store, Boy: Teach y...       11.52       11.52   \n",
       "7  Dometic D Line 3 N 1 Cleaner and Tank Treatmen...       34.41       34.41   \n",
       "8  Tiny White Mighty Mints (16 oz, ZIN: 525424): ...       16.54       16.54   \n",
       "9  Diabetic Socks Small White - Item Number 11600...       13.76       13.76   \n",
       "\n",
       "              Brand                                           category  \\\n",
       "0   La Costeï¿½ï¿½a  [Food, Meal Solutions, Grains & Pasta, Canned ...   \n",
       "1            Equate  [Health, Equate, Equate Allergy, Equate Sinus ...   \n",
       "2   AduroSmart ERIA  [Electronics, Smart Home, Smart Energy and Lig...   \n",
       "3          lowrider  [Sports & Outdoors, Bikes, Bike Accessories, B...   \n",
       "4            Anself  [Baby, Feeding, Sippy Cups: Alternatives to Pl...   \n",
       "5          Twinings                    [Food, Beverages, Tea, All Tea]   \n",
       "6         Toytainer                   [Home, Kids Rooms, Kids Storage]   \n",
       "7           Dometic  [Household Essentials, Bathroom, Bathroom Clea...   \n",
       "8  Larissa Veronica  [Food, Chocolate, Candy & Gum, Mints, Shop All...   \n",
       "9               DJO            [Health, Diabetes Care, Diabetic Socks]   \n",
       "\n",
       "       codes  \n",
       "0  [11, 168]  \n",
       "1   [12, 95]  \n",
       "2   [9, 249]  \n",
       "3   [27, 47]  \n",
       "4   [2, 104]  \n",
       "5   [11, 45]  \n",
       "6  [13, 153]  \n",
       "7   [15, 34]  \n",
       "8   [11, 63]  \n",
       "9   [12, 79]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def class_to_index(data, original_name, cls2idx, depth):\n",
    "    data['codes'] = data[original_name].apply(\n",
    "        lambda lst: [\n",
    "            cls2idx[i][cat] \n",
    "            for (i, cat) \n",
    "            in enumerate(lst[:depth])\n",
    "        ]\n",
    "    ).astype('object')\n",
    "\n",
    "class_to_index(data, CLASS_COL_NAME, cls2idx, DEPTH)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyrIcY8O3Pjl"
   },
   "source": [
    "We can try recovering category names from this encoding to ensure consistency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1635308025470,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "_-Pvksp33XHj",
    "outputId": "b6f190b6-d420-4ba1-9688-9e1e2d4e1dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['Sports & Outdoors' 'Bikes']\n",
      "Retrieved: ['Sports & Outdoors', 'Bikes']\n"
     ]
    }
   ],
   "source": [
    "def retrieve_classes(codes, idx2cls):\n",
    "    return [ idx2cls[i][code] for (i, code) in enumerate(codes) ]\n",
    "\n",
    "print('Original:', data.iloc[3]['category'][0:DEPTH])\n",
    "\n",
    "print('Retrieved:', retrieve_classes(data['codes'].iloc[3], idx2cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Smg58QeJ6jK-"
   },
   "source": [
    "# Hierarchy generation\n",
    "In this model, the hierarchical error penalty is simply $L_H = \\lambda \\times max(0,Y_{child} - Y_{parent})$. As such, we need to keep track of each node's parent and vectorise the calculation.\n",
    "\n",
    "For now I'll be implementing this as simple arrays of category codes (in the global categorical space). We can then use these arrays of codes as vectorised indices to pull out $Y_{parent}$s and have our loss function somewhat vectorised too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nDMbz01-BORD"
   },
   "outputs": [],
   "source": [
    "# TODO: Bring the above code into this thing's constructor entirely.\n",
    "from functools import reduce\n",
    "class PerLevelHierarchy:\n",
    "    # level_sizes is a list of (distinct) class counts per hierarchical level.\n",
    "    #   Its length dictates the maximum hierarchy construction depth.\n",
    "    #   (that is, our above code)\n",
    "    # classes is the list of distinct classes, in the order we have assembled.\n",
    "    def __init__(self, data, cls2idx):\n",
    "        self.levels = [ len(d.keys()) for d in cls2idx ] # TODO: Rename to level_sizes\n",
    "        self.classes = reduce(lambda acc, elem: acc + elem, [ list(d.keys()) for d in cls2idx ], [])\n",
    "        # Where each level starts in a global n-hot category vector\n",
    "        # Its last element is coincidentally the length, which also allows us\n",
    "        # to simplify the slicing code by blindly doing [offset[i] : offset[i+1]]\n",
    "        self.level_offsets = reduce(lambda acc, elem: acc + [acc[len(acc) - 1] + elem], self.levels, [0])\n",
    "        # Use -1 to indicate 'undiscovered'\n",
    "        parent_of = [[-1] * level_size for level_size in self.levels] \n",
    "        for lst in data['codes']:\n",
    "            # First-level classes' parent is root, but here we set them to themselves.\n",
    "            # This effectively zeroes out the hierarchical loss for this level.\n",
    "            parent_of[0][lst[0]] = lst[0]\n",
    "            for i in range(1, len(self.levels)):\n",
    "                child_idx = lst[i]\n",
    "                parent_idx = lst[i-1]\n",
    "                if parent_of[i][child_idx] == -1:\n",
    "                    parent_of[i][child_idx] = parent_idx\n",
    "            self.parent_of = []\n",
    "            for parent_lst in parent_of:\n",
    "                self.parent_of.append(torch.LongTensor(parent_lst).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1635308149130,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "zSI6Ket7Gj8v",
    "outputId": "58a86d5f-6ac5-40e8-dc63-024ebb6f64a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], device='cuda:0'),\n",
       " tensor([23,  3, 11,  1, 12, 28,  1, 15, 16, 12, 13, 12,  0, 28, 15,  9,  1,  1,\n",
       "          1,  1,  1,  1,  1,  2,  2,  2,  3, 26, 12,  7, 11, 21, 13, 23, 15, 14,\n",
       "         15,  0,  3,  3,  3,  3,  3, 13, 12, 11,  7, 27, 17, 11, 30,  4, 21,  9,\n",
       "          1,  2, 12, 24,  5,  7,  4, 12, 12, 11, 21, 23, 26, 15,  3, 11, 12,  9,\n",
       "         11,  4,  6, 13, 23,  3, 20, 12, 12, 12, 12,  2, 12,  6, 28, 24, 24, 28,\n",
       "         15, 12, 14, 28, 14, 12, 27,  1, 12, 12, 24,  7, 16, 13,  2, 23, 12, 12,\n",
       "         16, 12,  3,  3, 11, 11, 11, 13,  9, 28, 22, 12, 11, 21, 11, 22, 14,  3,\n",
       "         21,  3, 14, 12,  2, 12, 14,  3,  4, 28, 13, 12, 14, 24, 22,  4, 15, 23,\n",
       "         19, 21, 16, 21,  7, 12, 28,  7, 17, 13, 13, 11,  4, 26, 15, 12, 28, 15,\n",
       "         12,  4,  3, 21, 12,  7, 11, 16, 12, 12,  7,  7, 23, 23,  3, 12,  1,  3,\n",
       "          7, 10,  6,  2,  1, 23, 11, 22, 28, 22, 27, 12, 14, 20, 15, 21, 22, 22,\n",
       "         13, 15, 24, 12,  9, 25,  3, 25,  7, 25, 25, 25, 25, 25, 25, 25, 28, 12,\n",
       "         12,  4, 12,  1, 27, 28, 24, 23,  3, 12, 12,  2, 29, 14,  0,  7, 11,  3,\n",
       "          0, 12, 12, 23, 15,  7, 19, 28, 28, 28,  8,  3,  3, 12,  7,  9, 11, 11,\n",
       "         27, 27, 12, 21, 13,  2, 28, 23, 11, 12,  9,  7,  9, 13, 10,  1,  2, 14,\n",
       "         28,  3, 23, 26, 10, 11, 21, 29, 18, 12, 10, 28, 17, 17, 14, 21, 12, 26,\n",
       "         21,  7, 17,  7,  9], device='cuda:0')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy = PerLevelHierarchy(data, cls2idx)\n",
    "hierarchy.parent_of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6K2Cm1Bq7Kl"
   },
   "source": [
    "# Data and model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRp5rd9W3rXm"
   },
   "source": [
    "## Installing DistilBERT\n",
    "Alternative to full-fat BERT, roughly matching its performance while being faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jx5V1QzS3wRX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "if not INSTALL_DISTILBERT:\n",
    "    os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "else:\n",
    "    !pip install transformers\n",
    "    \n",
    "import transformers as ppb\n",
    "tokenizer = ppb.DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "base_encoder = ppb.DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "base_encoder_state = base_encoder.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vr1iQObJQOPB"
   },
   "source": [
    "## Define our dataset adapter class\n",
    "This wraps around our data and provides a PyTorch-compatible interface.\n",
    "\n",
    "One point of interest is how we do not explicitly store per-level one-hot encodings. Here we simply store one global copy (n-hot-encoded) then slice from it when requested, saving a bit of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "I8cdh6oiQTsq"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, df, hierarchy, tokenizer, max_len, text_col_name = TEXT_COL_NAME):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.text = df[text_col_name]\n",
    "    # Level sizes\n",
    "    self.levels = hierarchy.levels\n",
    "    self.labels = df.codes\n",
    "    self.level_offsets = hierarchy.level_offsets\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.text)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    text = str(self.text.iloc[index])\n",
    "    text = \" \".join(text.split())\n",
    "    inputs = self.tokenizer(\n",
    "      text,\n",
    "      None, # No text_pair\n",
    "      add_special_tokens=True, # CLS, SEP\n",
    "      max_length=self.max_len, # For us it's a hyperparam. See next cells.\n",
    "      padding='max_length',\n",
    "      truncation=True\n",
    "      # BERT tokenisers return attention masks by default\n",
    "    )\n",
    "\n",
    "    labels = torch.tensor(self.labels.loc[index], dtype=torch.long)\n",
    "\n",
    "    result = {\n",
    "      'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "      'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "      'labels': labels,\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZywhH4tS2Q0"
   },
   "source": [
    "Regarding that `max_len` hyperparameter, let's see the distribution of title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 1200,
     "status": "ok",
     "timestamp": 1635308166461,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "LN-EM4dWS02O",
    "outputId": "c20c5dca-744d-4e14-bc99-679e8e68cb50",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['title_len'] = data['title'].apply(lambda s: len(s.split()))\n",
    "data['title_len'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ33DAURTg3I"
   },
   "source": [
    "We prefer `max_len` to be a power of two that covers most of the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1635308388604,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "wpFTDAgDq_oV",
    "outputId": "ca0d543e-98ae-4126-c716-a1a3c056dfab"
   },
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 64\n",
    "LINEAR_DROPOUT_RATE = 0.3\n",
    "TRAIN_MINIBATCH_SIZE = 16\n",
    "VAL_TEST_MINIBATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "ENCODER_LEARNING_RATE = 3e-05\n",
    "CLASSIFIER_LEARNING_RATE = 3e-03\n",
    "TRAIN_SET_RATIO = 0.8\n",
    "VAL_SET_RATIO = 0.1\n",
    "# The rest is test set\n",
    "# Don't change this if you want a consistent sampling for easier comparisons\n",
    "RANDOM_SEED = 123\n",
    "\n",
    "FULL_SET = False\n",
    "PARTIAL_SET_FRAC = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vRe05MEHZ9g"
   },
   "source": [
    "CV-split our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1211,
     "status": "ok",
     "timestamp": 1635308170890,
     "user": {
      "displayName": "Khiêm Huỳnh Thiện",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiKsMYrfMtAzOaIk6G51GUQwDS0P6dMkGSwN9B_aA=s64",
      "userId": "01825679077701569078"
     },
     "user_tz": -420
    },
    "id": "8973_cElHYg2",
    "outputId": "db7e22e7-b868-43ec-a114-4294c462cda3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2337, 2)\n",
      "(292, 2)\n",
      "(292, 2)\n"
     ]
    }
   ],
   "source": [
    "small_data = None\n",
    "if not FULL_SET:\n",
    "    small_data = data.sample(frac = PARTIAL_SET_FRAC, random_state=RANDOM_SEED)\n",
    "\n",
    "train_set = None\n",
    "test_set = None\n",
    "\n",
    "COLUMNS = [TEXT_COL_NAME, 'codes']\n",
    "\n",
    "filtered = None\n",
    "if FULL_SET:\n",
    "    filtered = data[COLUMNS]\n",
    "else:\n",
    "    filtered = small_data[COLUMNS]\n",
    "\n",
    "train_set = filtered.sample(frac = TRAIN_SET_RATIO, random_state=RANDOM_SEED)\n",
    "val_test_set = filtered.drop(train_set.index)\n",
    "\n",
    "val_set = val_test_set.sample(frac = VAL_SET_RATIO / (1-TRAIN_SET_RATIO), random_state=RANDOM_SEED)\n",
    "test_set = val_test_set.drop(val_set.index)\n",
    "\n",
    "train_set = train_set.reset_index(drop=True)\n",
    "val_set = val_set.reset_index(drop=True)\n",
    "test_set = test_set.reset_index(drop=True)\n",
    "\n",
    "print(train_set.shape)\n",
    "print(val_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PXLfuJcV2aK"
   },
   "source": [
    "We can now wrap them in our Datasets, and then into PyTorch's DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_b1j_gNdV9Ux"
   },
   "outputs": [],
   "source": [
    "train_set_wrapped = CustomDataset(train_set, hierarchy, tokenizer, MAX_LEN)\n",
    "val_set_wrapped = CustomDataset(val_set, hierarchy, tokenizer, MAX_LEN)\n",
    "test_set_wrapped = CustomDataset(test_set, hierarchy, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set_wrapped, batch_size=TRAIN_MINIBATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set_wrapped, batch_size=VAL_TEST_MINIBATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set_wrapped, batch_size=VAL_TEST_MINIBATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGLkaGimW285"
   },
   "source": [
    "## Prepare the model itself\n",
    "Here we use DistilBERT as the encoding layers, followed by our implementation of HMCN-F."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4yHw2BlRhLM"
   },
   "source": [
    "### DB-FBHCN\n",
    "This is our hybrid between HMCN-F and our simpler BERT-linear model.\n",
    "\n",
    "The idea is simple: one layer per hierarchical level. First layer takes in 768 BERT features (we might want to pool it later) and output $h_1$ values corresponding to scores for all categories at the first level. The second layer takes in this prediction, plus 768 original BERT features, and output $h_2$ values corresponding to scores for all categories on the second level, and so on.\n",
    "\n",
    "The final hierarchical prediction is simply the concatenation of predictions from each level, from first to last. Each would have already been through a sigmoid function before being concatenated, but that would be done outside of the model for performance reasons.\n",
    "\n",
    "Right now the global loss calculation is simply the sum of losses of each level. For this reason we make the model output each level separately. That way we can also easily argmax on each level to get the category names.\n",
    "\n",
    "We'll keep the hierarchical loss, as it is important in keeping the levels in sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hGFxM_q2RpkC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class DBFBHCN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        feature_size, \n",
    "        dropout_rate, # after every linear layer\n",
    "        hierarchy,\n",
    "        hidden_nonlinear='relu'\n",
    "    ):\n",
    "        super(DBFBHCN, self).__init__()\n",
    "\n",
    "        # Back up some parameters for use in forward()\n",
    "        self.depth = len(hierarchy.levels)\n",
    "\n",
    "        # First layer only takes in BERT encodings\n",
    "        self.fc_layers = torch.nn.ModuleList([ \n",
    "            torch.nn.Linear(feature_size, hierarchy.levels[0])\n",
    "        ])\n",
    "        torch.nn.init.xavier_uniform_(self.fc_layers[0].weight)\n",
    "        self.norms = torch.nn.ModuleList([])\n",
    "        for i in range(1, self.depth):\n",
    "            self.fc_layers.extend([ \n",
    "                torch.nn.Linear(feature_size + hierarchy.levels[i-1], hierarchy.levels[i]) \n",
    "            ])\n",
    "            torch.nn.init.xavier_uniform_(self.fc_layers[i].weight)\n",
    "            self.norms.extend([torch.nn.LayerNorm(hierarchy.levels[i-1], elementwise_affine=False)])\n",
    "        # Activation functions\n",
    "        self.hidden_nonlinear = torch.nn.ReLU() if hidden_nonlinear == 'relu' else torch.nn.Tanh()\n",
    "        self.output_nonlinear = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # We have |D| of these\n",
    "        local_outputs = []\n",
    "        output_l1 = self.fc_layers[0](self.dropout(x))\n",
    "        local_outputs.append(self.output_nonlinear(output_l1))\n",
    "\n",
    "        prev_output = self.hidden_nonlinear(output_l1)\n",
    "        for i in range(1, self.depth):\n",
    "            output_li = self.fc_layers[i](torch.cat([self.dropout(self.norms[i-1](prev_output)), x], dim=1))\n",
    "            local_outputs.append(self.output_nonlinear(output_li))\n",
    "            prev_output = self.hidden_nonlinear(output_li)\n",
    "\n",
    "        return local_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_btMadIfe7A"
   },
   "source": [
    "## Checkpoints\n",
    "PyTorch allows us to save the best-performing model automatically so we can restart from that instead of the beginning. No reason not to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mIDVu-5Ffd6v"
   },
   "outputs": [],
   "source": [
    "import shutil, sys\n",
    "def load_checkpoint(checkpoint_fpath, model):\n",
    "    \"\"\"\n",
    "    checkpoint_fpath: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder, classifier = model\n",
    "    \n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    classifier.load_state_dict(checkpoint['classifier_state_dict'])\n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return (encoder, classifier)\n",
    "\n",
    "def save_checkpoint(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint we want to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model (min validation lost)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFA8W-4CvOH9"
   },
   "source": [
    "# Training time\n",
    "## Metrics\n",
    "We define hierarchical accuracy as simply the averaged accuracy over each level. Same for precision.\n",
    "This is a big TODO item: get something more representative for metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "r287BexWv69M"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def get_metrics(local_outputs, targets, log_metrics = False, get_auprc = False):\n",
    "    leaf_size = local_outputs[-1].shape[1]\n",
    "    def generate_one_hot(idx):\n",
    "        b = np.zeros(leaf_size, dtype=bool)\n",
    "        b[idx] = 1\n",
    "        return b\n",
    "\n",
    "    level_codes = [ \n",
    "        np.argmax(local_outputs[level], axis=1) \n",
    "        for level in range(len(local_outputs)) \n",
    "    ]\n",
    "    \n",
    "    accuracies = [ metrics.accuracy_score(level_codes[level], targets[:, level]) for level in range(len(hierarchy.levels)) ]\n",
    "    precisions = [ metrics.precision_score(level_codes[level], targets[:, level], average='weighted', zero_division=0) for level in range(len(local_outputs)) ]\n",
    "    \n",
    "    global_accuracy = sum(accuracies)/len(accuracies)\n",
    "    global_precision = sum(precisions)/len(precisions)\n",
    "    \n",
    "    if log_metrics:\n",
    "        logging.info('Leaf level:')\n",
    "        logging.info(\"Accuracy: {}\".format(accuracies[-1]))\n",
    "        # Model Precision: what percentage of positive tuples are labeled as such?\n",
    "        logging.info(\"Precision: {}\".format(precisions[-1]))\n",
    "\n",
    "        logging.info('Global level:')\n",
    "        logging.info(\"Accuracy: {}\".format(global_accuracy))\n",
    "        # Model Precision: what percentage of positive tuples are labeled as such?\n",
    "        logging.info(\"Precision: {}\".format(global_precision))\n",
    "    \n",
    "    if get_auprc:\n",
    "        binarised_targets = np.array([generate_one_hot(lst[-1]) for lst in test_result['targets']])\n",
    "\n",
    "        # Rectified leaf AU(PRC) due to an sklearn bug.\n",
    "        # We add one artificial example that belongs to all classes at once and a corresponding prediction\n",
    "        # full of true positives. This way each class has at least one true positive, even if the test set\n",
    "        # does not contain enough examples to cover all classes.\n",
    "        rectified_outputs = np.concatenate([test_result['outputs'][-1], np.ones((1, leaf_size))], axis=0)\n",
    "        rectified_targets = np.concatenate([binarised_targets, np.ones((1, leaf_size), dtype=bool)], axis=0)\n",
    "        auprc = metrics.average_precision_score(rectified_targets, rectified_outputs)\n",
    "        if log_metrics:\n",
    "            logging.info('Rectified leaf-level AU(PRC) score: {}'.format(auprc))\n",
    "    \n",
    "        return np.array([accuracies[-1], precisions[-1], global_accuracy, global_precision, auprc])\n",
    "    return np.array([accuracies[-1], precisions[-1], global_accuracy, global_precision])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgdVf_dMv69N"
   },
   "source": [
    "## Training script\n",
    "\n",
    "Now we define the loss function that we will use to fine-tune our model (DistilBERT included).\n",
    "\n",
    "For now we'll stick with one of the provided loss functions instead of building anything radical. As we are performing multiclass classification here, we should use Cross Entropy Loss (the normal one for multiclass, not BCE for binary). The way we use them however, is a bit different. We'll have two types of loss values:\n",
    "- A leaf-level loss value, that is, $L_L = NLL(y_{leaf}, \\bar{y}_{leaf})$, and\n",
    "- A hierarchical loss value $L_H = NLL(y_{parent}, \\bar{y}_{parent})$ for every level except leaf, summed up. That is, we will enforce that each level must predict the parent of whatever the next level predicted, even if they are wrong, creating a bottom-up hierarchy tracing strategy. This will be kept at a lower significance than the leaf-level loss due to its tendency to explode and knocking our gradient descent out of a good path.\n",
    "\n",
    "The final loss is then defined as $L = \\lambda_L L_L + \\lambda_H L_H$ where $\\lambda_H$ is likely to be smaller than $\\lambda_L$.\n",
    "\n",
    "We also construct our optimiser here, which is Adam with different learning rates for DistilBERT and our model.\n",
    "\n",
    "All of these are put inside a `train_model` function for brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZxqdEcgMvPoV"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_model(checkpoint_path, best_model_path, start_epochs, n_epochs, val_loss_min_input, \n",
    "                training_loader, val_loader, model, hierarchy, lambda_L, lambda_H, gamma_L, verbose=False\n",
    "                ):\n",
    "    encoder, classifier = model\n",
    "    \n",
    "    depth = len(hierarchy.levels)\n",
    "    \n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    criterion_h = torch.nn.NLLLoss(reduction='none')\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [\n",
    "            {'params': encoder.parameters(), 'lr': ENCODER_LEARNING_RATE},\n",
    "            {'params': classifier.parameters(), 'lr': CLASSIFIER_LEARNING_RATE}\n",
    "        ], \n",
    "    )\n",
    "    \n",
    "    deviations = np.linspace(-gamma_L, gamma_L, depth)\n",
    "    loss_L_weights = [1] * depth\n",
    "    loss_L_weights -= deviations\n",
    "    print('Using level weights', loss_L_weights, 'for local loss.')\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [\n",
    "            {'params': encoder.parameters(), 'lr': ENCODER_LEARNING_RATE,},\n",
    "            {'params': classifier.parameters(), 'lr': CLASSIFIER_LEARNING_RATE}\n",
    "        ], \n",
    "    )\n",
    "\n",
    "    # Keep min validation loss so we can separately back up our best-yet model\n",
    "    val_loss_min = val_loss_min_input\n",
    "    \n",
    "    # Store validation metrics after each epoch\n",
    "    val_metrics = np.empty((4, 0), dtype=float)\n",
    "    \n",
    "    for epoch in range(start_epochs, n_epochs+1):\n",
    "        train_loss = 0\n",
    "        # Put model into training mode. Note that this call DOES NOT train it yet.\n",
    "        encoder.train()\n",
    "        classifier.train()\n",
    "        print('Epoch {}: Training'.format(epoch))\n",
    "        for batch_idx, data in enumerate(tqdm(training_loader)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            targets = data['labels']#.to(device, dtype = torch.long)\n",
    "\n",
    "            features = encoder(ids, mask)[0][:,0,:]\n",
    "            local_outputs = classifier(features)\n",
    "\n",
    "            # We have two loss functions: (l)ocal (per-level), and (h)ierarchical.\n",
    "            loss_l = lambda_L * sum([ criterion(\n",
    "                local_outputs[level].cpu(),\n",
    "                targets[:, level]\n",
    "            ) * loss_L_weights[level] for level in range(depth) ])\n",
    "            \n",
    "            # Hierarchically penalise less (or don't at all) if the prediction itself is wrong at the child level.\n",
    "            loss_h_levels = []\n",
    "            for level in range(depth-1):\n",
    "                target_child_indices = torch.unsqueeze(targets[:, level + 1], 1).to(device)\n",
    "                transformed = local_outputs[level + 1] * -1\n",
    "                transformed -= transformed.min(1, keepdim=True)[0]\n",
    "                transformed /= transformed.max(1, keepdim=True)[0]\n",
    "                loss_factors = 1 - torch.squeeze(transformed.gather(1, target_child_indices), 1)\n",
    "                loss_h_levels.append(\n",
    "                    torch.mean(criterion_h(\n",
    "                        local_outputs[level], \n",
    "                        torch.index_select(\n",
    "                            hierarchy.parent_of[level + 1],\n",
    "                            0, \n",
    "                            torch.argmax(local_outputs[level + 1], dim=1)\n",
    "                        )\n",
    "                    ) * loss_factors)\n",
    "                )\n",
    "            loss_h = lambda_H * sum(loss_h_levels)\n",
    "            loss = loss_l + loss_h\n",
    "\n",
    "            # PyTorch defaults to accumulating gradients, but we don't need that here\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss = train_loss + (loss.item() - train_loss) / (batch_idx + 1)\n",
    "\n",
    "        print('Epoch {}: Validating'.format(epoch))\n",
    "\n",
    "\n",
    "        # Switch to evaluation (prediction) mode. Again, this doesn't evaluate anything.\n",
    "        encoder.eval()\n",
    "        classifier.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        val_targets = np.empty((0, len(hierarchy.levels)), dtype=bool)\n",
    "        val_outputs = [np.empty((0, hierarchy.levels[level]), dtype=float) for level in range(len(hierarchy.levels))]\n",
    "\n",
    "        # We're only testing here, so don't run the backward direction (no_grad).\n",
    "        with torch.no_grad():\n",
    "            total_loss_l = 0\n",
    "            total_loss_h = 0\n",
    "            for batch_idx, data in enumerate(tqdm(val_loader)):\n",
    "                ids = data['ids'].to(device, dtype = torch.long)\n",
    "                mask = data['mask'].to(device, dtype = torch.long)\n",
    "                targets = data['labels']#.to(device, dtype = torch.long)\n",
    "\n",
    "                features = encoder(ids, mask)[0][:,0,:]\n",
    "                local_outputs = classifier(features)\n",
    "\n",
    "                # We have two loss functions: (l)ocal (per-level), and (h)ierarchical.\n",
    "                loss_l = lambda_L * sum([ criterion(\n",
    "                    local_outputs[level].cpu(),\n",
    "                    targets[:, level]\n",
    "                ) * loss_L_weights[level] for level in range(depth) ])\n",
    "\n",
    "                # Hierarchically penalise less (or don't at all) if the prediction itself is wrong at the child level.\n",
    "                loss_h_levels = []\n",
    "                for level in range(depth-1):\n",
    "                    target_child_indices = torch.unsqueeze(targets[:, level + 1], 1).to(device)\n",
    "                    transformed = local_outputs[level + 1] * -1\n",
    "                    transformed -= transformed.min(1, keepdim=True)[0]\n",
    "                    transformed /= transformed.max(1, keepdim=True)[0]\n",
    "                    loss_factors = 1 - torch.squeeze(transformed.gather(1, target_child_indices), 1)\n",
    "                    loss_h_levels.append(\n",
    "                        torch.mean(criterion_h(\n",
    "                            local_outputs[level], \n",
    "                            torch.index_select(\n",
    "                                hierarchy.parent_of[level + 1],\n",
    "                                0, \n",
    "                                torch.argmax(local_outputs[level + 1], dim=1)\n",
    "                            )\n",
    "                        ) * loss_factors)\n",
    "                    )\n",
    "                loss_h = lambda_H * sum(loss_h_levels)\n",
    "                loss = loss_l + loss_h\n",
    "                \n",
    "                total_loss_l += loss_l\n",
    "                total_loss_h += loss_h\n",
    "\n",
    "                val_loss = val_loss + (loss.item() - val_loss) / (batch_idx + 1)\n",
    "\n",
    "                val_targets = np.concatenate([val_targets, targets.cpu().detach().numpy()])\n",
    "                \n",
    "                for i in range(len(val_outputs)):\n",
    "                    val_outputs[i] = np.concatenate([val_outputs[i], local_outputs[i].cpu().detach().numpy()])\n",
    "\n",
    "        val_metrics = np.concatenate([val_metrics, \n",
    "            np.expand_dims(\n",
    "                get_metrics(val_outputs, val_targets), axis=1\n",
    "            )],\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        train_loss = train_loss/len(training_loader)\n",
    "        val_loss = val_loss/len(val_loader)\n",
    "        \n",
    "        if verbose:\n",
    "            # Calculate average losses\n",
    "            print('Average minibatch local loss:', total_loss_l / len(val_loader))\n",
    "            print('Average minibatch hierarchical loss:', total_loss_h / len(val_loader))\n",
    "\n",
    "            # Print training/validation statistics\n",
    "            print('Avgerage training loss: {:.6f}\\nAverage validation loss: {:.6f}'.format( \n",
    "                train_loss,\n",
    "                val_loss\n",
    "            ))\n",
    "\n",
    "        # create checkpoint variable and add important data\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'val_loss_min': val_loss,\n",
    "            'encoder_state_dict': encoder.state_dict(),\n",
    "            'classifier_state_dict': classifier.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        best_yet = False\n",
    "        if val_loss <= val_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(val_loss_min,val_loss))\n",
    "            # save checkpoint as best model\n",
    "            best_yet = True\n",
    "            val_loss_min = val_loss\n",
    "        save_checkpoint(checkpoint, best_yet, checkpoint_path, best_model_path)\n",
    "        print('Epoch {}: Done\\n'.format(epoch))\n",
    "    return (encoder, classifier), val_metrics\n",
    "\n",
    "# Alternative: just load from disk\n",
    "def run_model(model, loader, hierarchy):\n",
    "  encoder, classifier = model\n",
    "  # Switch to evaluation (prediction) mode. Again, this doesn't evaluate anything.\n",
    "  encoder.eval()\n",
    "  classifier.eval()\n",
    "\n",
    "  all_targets = np.empty((0, len(hierarchy.levels)), dtype=bool)\n",
    "  all_outputs = [np.empty((0, hierarchy.levels[level]), dtype=float) for level in range(len(hierarchy.levels))]\n",
    "\n",
    "  # We're only testing here, so don't run the backward direction (no_grad).\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(tqdm(loader)):\n",
    "      ids = data['ids'].to(device, dtype = torch.long)\n",
    "      mask = data['mask'].to(device, dtype = torch.long)\n",
    "      targets = data['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "      features = encoder(ids, mask)[0][:,0,:]\n",
    "      local_outputs = classifier(features)\n",
    "\n",
    "      all_targets = np.concatenate([all_targets, targets.cpu().detach().numpy()])\n",
    "      for i in range(len(all_outputs)):\n",
    "        all_outputs[i] = np.concatenate([all_outputs[i], local_outputs[i].cpu().detach().numpy()])\n",
    "\n",
    "  return {\n",
    "      'targets': all_targets,\n",
    "      'outputs': all_outputs,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DcqgkF06fnkf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘checkpoints-avg-Walmart_30k.parquet’: File exists\n",
      "--- RUN 0 ---\n",
      "Using level weights [0.75 1.25] for local loss.\n",
      "Epoch 1: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2345a408d1cc4c27b3102c6d647636da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0615673b1c71414181f9912572de23a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch local loss: tensor(3.2426)\n",
      "Average minibatch hierarchical loss: tensor(0.2786, device='cuda:0')\n",
      "Avgerage training loss: 0.034358\n",
      "Average validation loss: 0.704234\n",
      "Validation loss decreased (inf --> 0.704234).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Done\n",
      "\n",
      "Epoch 2: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdbec5d5bc84ea3a3028de11c6f74b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc8628a5b4f414f9f25ba19f4f57be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch local loss: tensor(2.9858)\n",
      "Average minibatch hierarchical loss: tensor(0.1664, device='cuda:0')\n",
      "Avgerage training loss: 0.016670\n",
      "Average validation loss: 0.630434\n",
      "Validation loss decreased (0.704234 --> 0.630434).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Done\n",
      "\n",
      "Epoch 3: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6d749fef6f44c883f314feb3cf9fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d6195928fe4bd88ce23f1745ff20e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch local loss: tensor(3.2912)\n",
      "Average minibatch hierarchical loss: tensor(0.1221, device='cuda:0')\n",
      "Avgerage training loss: 0.009286\n",
      "Average validation loss: 0.682671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Done\n",
      "\n",
      "Epoch 4: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfc0d3d4f1143cb973da380b59de9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16d101d48e2458da95b3c0fb9d5afaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch local loss: tensor(3.3898)\n",
      "Average minibatch hierarchical loss: tensor(0.1914, device='cuda:0')\n",
      "Avgerage training loss: 0.005254\n",
      "Average validation loss: 0.716224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Done\n",
      "\n",
      "Epoch 5: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcb114c3699491cb5bce27507c6d41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3534a001a3a4334a6b304c37d1b7ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch local loss: tensor(3.8629)\n",
      "Average minibatch hierarchical loss: tensor(0.2088, device='cuda:0')\n",
      "Avgerage training loss: 0.002652\n",
      "Average validation loss: 0.814348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Done\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abb94f32c354869a4f66076f564fc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectified leaf-level AU(PRC) score: 0.9378611757998514\n",
      "--- RUN 1 ---\n",
      "Using level weights [0.75 1.25] for local loss.\n",
      "Epoch 1: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01648fa3f17472fb78a04cbce620f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f596f4f6a9f74baa80be087d87039e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch local loss: tensor(3.1726)\n",
      "Average minibatch hierarchical loss: tensor(0.2358, device='cuda:0')\n",
      "Avgerage training loss: 0.033613\n",
      "Average validation loss: 0.681686\n",
      "Validation loss decreased (inf --> 0.681686).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Done\n",
      "\n",
      "Epoch 2: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2da4548bce475088d3e4ac237537c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919ed65151b2474f9c5b6a620372e9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch local loss: tensor(2.7769)\n",
      "Average minibatch hierarchical loss: tensor(0.2084, device='cuda:0')\n",
      "Avgerage training loss: 0.016257\n",
      "Average validation loss: 0.597061\n",
      "Validation loss decreased (0.681686 --> 0.597061).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Done\n",
      "\n",
      "Epoch 3: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc09b54c33848e8acdd11fb7250e846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e771996d56b4ac2ab1c477a1efc73d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch local loss: tensor(3.0405)\n",
      "Average minibatch hierarchical loss: tensor(0.1965, device='cuda:0')\n",
      "Avgerage training loss: 0.009108\n",
      "Average validation loss: 0.647395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Done\n",
      "\n",
      "Epoch 4: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40837ddd49bf4dfe97fce1b56dd2f335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95de6290c34240d1a9a7a5d34651b9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch local loss: tensor(3.5531)\n",
      "Average minibatch hierarchical loss: tensor(0.2386, device='cuda:0')\n",
      "Avgerage training loss: 0.004226\n",
      "Average validation loss: 0.758339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Done\n",
      "\n",
      "Epoch 5: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f825793ff1548ef86059baa743b5cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30e2a294d984dc1859028b54488e584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch local loss: tensor(4.0517)\n",
      "Average minibatch hierarchical loss: tensor(0.1667, device='cuda:0')\n",
      "Avgerage training loss: 0.002087\n",
      "Average validation loss: 0.843683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Done\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d31924252fe4670bcac7b56f7c6303d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectified leaf-level AU(PRC) score: 0.9371504887974739\n",
      "--- RUN 2 ---\n",
      "Using level weights [0.75 1.25] for local loss.\n",
      "Epoch 1: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25bddbd45ca4098aaa8f0f62f773b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44855fb7a5445628572e417ec673b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch local loss: tensor(3.3144)\n",
      "Average minibatch hierarchical loss: tensor(0.2028, device='cuda:0')\n",
      "Avgerage training loss: 0.033709\n",
      "Average validation loss: 0.703439\n",
      "Validation loss decreased (inf --> 0.703439).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Done\n",
      "\n",
      "Epoch 2: Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75326ccba2a4e2284c6a59a67788a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2381/4191646814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mCHECKPOINT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./{}/{}_{}_current.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHECKPOINT_IDX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mBEST_CHECKPOINT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./{}/{}_{}_best.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHECKPOINT_IDX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         trained_model, val_metrics = train_model(\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mCHECKPOINT_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mBEST_CHECKPOINT_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2381/3297883131.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(checkpoint_path, best_model_path, start_epochs, n_epochs, val_loss_min_input, training_loader, val_loader, model, hierarchy, lambda_L, lambda_H, gamma_L)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {}: Validating'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder_name = 'checkpoints-avg-' + DATASET_NAME\n",
    "!mkdir $folder_name\n",
    "checkpoint_idx_path = \"{}/last_idx\".format(folder_name)\n",
    "\n",
    "# Set up current checkpoint index\n",
    "CHECKPOINT_IDX = 0\n",
    "if os.path.exists(checkpoint_idx_path):\n",
    "    idx_file = open(checkpoint_idx_path, 'r')\n",
    "    CHECKPOINT_IDX = int(idx_file.read()) + 1\n",
    "    idx_file.close()\n",
    "idx_file = open(checkpoint_idx_path, 'w')\n",
    "idx_file.write(str(CHECKPOINT_IDX))\n",
    "idx_file.close()\n",
    "\n",
    "logging.basicConfig(filename=\"{}/{}.log\".format(folder_name, CHECKPOINT_IDX), level=logging.INFO)\n",
    "\n",
    "all_test_metrics = np.zeros((TRAIN_REPEATS, 5), dtype=float)\n",
    "\n",
    "trained_model = None\n",
    "if TRAIN_FROM_SCRATCH:\n",
    "    for i in range(TRAIN_REPEATS):\n",
    "        run_header = \"--- RUN {} ---\".format(i)\n",
    "        print(run_header)\n",
    "        logging.info(run_header)\n",
    "        # Reinitialise weights\n",
    "        encoder = base_encoder\n",
    "        encoder.load_state_dict(base_encoder_state)\n",
    "        encoder.to(device)\n",
    "        classifier = DBFBHCN(\n",
    "            768, # DistilBERT outputs 768 values.\n",
    "            dropout_rate = LINEAR_DROPOUT_RATE,\n",
    "            hierarchy=hierarchy,\n",
    "            hidden_nonlinear='relu',\n",
    "        )\n",
    "        classifier.to(device)\n",
    "        \n",
    "        # Train/validate\n",
    "        CHECKPOINT_PATH = './{}/{}_{}_current.pt'.format(folder_name, CHECKPOINT_IDX, i)\n",
    "        BEST_CHECKPOINT_PATH = './{}/{}_{}_best.pt'.format(folder_name, CHECKPOINT_IDX, i)\n",
    "        trained_model, val_metrics = train_model(\n",
    "            CHECKPOINT_PATH,\n",
    "            BEST_CHECKPOINT_PATH,\n",
    "            1, # Count from one\n",
    "            EPOCHS,\n",
    "            np.Inf, \n",
    "            train_loader, \n",
    "            val_loader, \n",
    "            (encoder, classifier), \n",
    "            hierarchy,\n",
    "            1.0, # lambda_L\n",
    "            0.7, # lambda_H\n",
    "            -0.25 # gamma_L\n",
    "        )\n",
    "        \n",
    "        # Test\n",
    "        test_result = run_model(trained_model, test_loader, hierarchy)\n",
    "        test_metrics = get_metrics(test_result['outputs'], test_result['targets'], True, True)\n",
    "        all_test_metrics[i, :] = test_metrics\n",
    "    averaged = np.average(all_test_metrics, axis = 0)\n",
    "    averaged_display = '--- Average of {} runs:\\nLeaf accuracy: {}\\nLeaf precision: {}\\nPath accuracy: {}\\nPath precision: {}\\nLeaf AU(PRC): {}'.format(\n",
    "        TRAIN_REPEATS, averaged[0], averaged[1], averaged[2], averaged[3], averaged[4])\n",
    "    print(averaged_display)\n",
    "    logging.info(averaged_display)\n",
    "else:\n",
    "    load_path = '{}/{}_{}_{}.pt'.format(folder_name, LOAD_ITERATION, TRAIN_REPEATS - 1, 'best' if LOAD_BEST else 'current')\n",
    "    trained_model, _ = load_checkpoint(load_path, (encoder, classifier))\n",
    "    # Test\n",
    "    test_result = run_model(trained_model, test_loader, hierarchy)\n",
    "    get_metrics(test_result['outputs'], test_result['targets'], True, True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DB-FBHCN",
   "provenance": [
    {
     "file_id": "1XH71XbNfkOyYkVwthbl_Mnt9YN0hwUv2",
     "timestamp": 1633613457791
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
